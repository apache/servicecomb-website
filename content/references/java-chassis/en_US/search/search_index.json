{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Overview","text":"<p>Apache ServiceComb Java Chassis provides developers with a Java SDK to quickly build microservices. It contains the following features:</p> <ul> <li>Multiple development styles, REST (JAX-RS, Spring MVC) and RPC</li> <li>Multiple communication protocols, HTTP over Vert.x, Http Over Servlet, Highway, etc.</li> <li>Uniform service providers, service consumer handler, and contract-based out-of-the-box service governance capabilities</li> </ul> <p>For other versions, please check the following table.</p> Version Release Version Preview Version 3.x.x \u4e2d\u6587, English \u4e2d\u6587, English 2.8.x \u4e2d\u6587, English \u4e2d\u6587, English 1.3.x \u4e2d\u6587, English \u4e2d\u6587, English"},{"location":"build-consumer/circuit-breaker/","title":"Circuit breaker","text":""},{"location":"build-consumer/circuit-breaker/#circuit-break-policy","title":"Circuit Break Policy","text":""},{"location":"build-consumer/circuit-breaker/#scenario","title":"Scenario","text":"<p>Circuit brake policy can configure ServiceComb fallback capability, you can configure conditions under which service will stop send request after circuit break policy configured.</p>"},{"location":"build-consumer/circuit-breaker/#configuration","title":"Configuration","text":"<p>Circuit break is part of fallback policy when a service request is abnormal, relevant concept such as isolation and fault tolerance please refer to fallback policy\u3002</p>"},{"location":"build-consumer/code-first/","title":"Code first","text":""},{"location":"build-consumer/code-first/#scene-description","title":"Scene Description","text":"<p>Service consumers can store contracts in the project directory without having to explicitly do so, and when the program starts, the ServiceComb framework automatically pulls the contract information from the service center based on the microservice name and version number of the service provider configured in the microservice.yaml file.</p>"},{"location":"build-consumer/code-first/#involving-api","title":"Involving API","text":"<p>The use of implicit contracts can be used for both RestTemplate and transparent RPC service development models. For the development method using RestTemplate, see 4.3 Developing Service Consumers with RestTemplate.</p>"},{"location":"build-consumer/code-first/#sample-code","title":"Sample Code","text":"<p>This section shows how to develop service consumers using implicit contracts, using transparent RPC development patterns as an example.</p> <p>The sample code for the service consumer is as follows:</p> <pre><code>import org.springframework.stereotype.Component;\nimport org.apache.servicecomb.foundation.common.utils.BeanUtils;\nimport org.apache.servicecomb.foundation.common.utils.Log4jUtils;\nimport org.apache.servicecomb.provider.pojo.RpcReference;\nimport org.apache.servicecomb.samples.common.schema.Hello;\nimport org.apache.servicecomb.samples.common.schema.models.Person;\n\n@Component\npublic class CodeFirstConsumerMain {\n  @RpcReference(microserviceName = \"codefirst\", schemaId = \"codeFirstHello\")\n  private static Hello hello;\n\n  public static void main(String[] args) throws Exception {\n    init();\n    System.out.println(hello.sayHi(\"Java Chassis\"));\n    Person person = new Person();\n    person.setName(\"ServiceComb/Java Chassis\");\n    System.out.println(hello.sayHello(person));\n  }\n\n  public static void init() throws Exception {\n    Log4jUtils.init();\n    BeanUtils.init();\n  }\n}\n</code></pre> <p>In the code above, the service consumer has taken the service interface Hello of the service provider and declared a Hello type member in the code. By using the RPCReference annotation on hello to specify the microservice name and schemaId, the ServiceComb framework can be in When the program starts, the corresponding service provider instance information is obtained from the service center and a proxy is generated to be injected into the hello. The user can invoke the remote service as if it were a local class.</p>"},{"location":"build-consumer/common-configuration/","title":"Consumer's common configuration","text":"<ul> <li>Request timed out  </li> <li>Configuration     servicecomb.request.timeout  </li> <li>Default     30000\uff0cunit is milliseconds    </li> <li>Description     When the Consumer transport layer starts transmitting, it starts timing. If the response is not received within the specified time, the processing is timeout.    </li> <li>Designated transmission channel  </li> <li>Configuration     servicecomb.references.${target microservice name}.transport     servicecomb.references.transport     Supports both global and micro-service level two-level control</li> <li>Default     none</li> <li>Description     If the target micro-service simultaneously opens the access capabilities of multiple transports, and the Consumer also deploys multiple transports at the same time, when the Consumer invokes the micro-service as a Consumer, you only want to use one of the transports, you can specify this configuration     If not configured, use multiple transports in turn  </li> <li>Specify the version rule for the target instance</li> <li>Configuration     servicecomb.references.${target microservice name}.version-rule     servicecomb.references.version-rule     Supports both global and micro-service level two-level control  </li> <li>Default     latest</li> <li>Description     The version rule for the target instance supports the following rules:  <ul> <li>The latest version of\uff1a latest  </li> <li>Greater than the specified version, for example: 1.0.0+</li> <li>Specify the version range, for example: 1.0.0-2.0.0, which means greater than or equal to version 1.0.0 and less than version 2.0.0</li> <li>Exact version, for example: 1.0.0</li> </ul> </li> </ul>"},{"location":"build-consumer/develop-consumer-using-rpc/","title":"Develop consumer with transparent RPC","text":""},{"location":"build-consumer/develop-consumer-using-rpc/#concepts","title":"Concepts","text":"<p>The transparent RPC allows user to access services like a local call through a simple java interface. Transparent RPC is just a development mode:</p> <ul> <li>Not associated with highway or RESTful transport</li> <li>The RPC does not rely on producers' development mode(transparent RPC/Jax-RS or SpringMVC)</li> <li>The RPC works even if the producer doesn't implement the interface.</li> </ul> <p>The transparent RPC is similar to spring cloud's feign, but simpler because there is no need to add any RESTful annotations in interface.</p>"},{"location":"build-consumer/develop-consumer-using-rpc/#declare-prc-by-rpcreference-in-spring-bean","title":"Declare PRC by @RpcReference in spring bean","text":"<pre><code>@Component\npublic class SomeBean {\n  ......\n\n  @RpcReference(microserviceName = \"helloService\", schemaId = \"helloSchema\")\n  private Hello hello;\n\n  ......\n}\n</code></pre>"},{"location":"build-consumer/develop-consumer-using-rpc/#declare-by-api-without-spring-bean","title":"Declare by API without spring bean","text":"<pre><code>Hello hello = Invoker.createProxy(\"helloService\", \"helloSchema\", Hello.class);\n</code></pre>"},{"location":"build-consumer/develop-consumer-using-rpc/#reactive","title":"reactive","text":"<p>Just use jdk's CompletableFuture to wrap the return value:</p> <pre><code>interface Hello {\n  CompletableFuture&lt;String&gt; sayHi(String name);\n}\n</code></pre> <p>In the same interface, you can declare both the reactive and synchronous prototypes of the same method. It is illegal in java that the method name is the same with the operationId in the contract while the return value type is different, so you need to modify the method name and declare the real operationId through the swagger annotation.</p> <pre><code>interface Hello {\n  String sayHi(String name);\n\n  @ApiOperation(nickname = \"sayHi\", value = \"reactive method for sayHi\")\n  CompletableFuture&lt;String&gt; asyncSayHi(String name);\n}\n</code></pre>"},{"location":"build-consumer/fault-injection/","title":"Fault Injection","text":""},{"location":"build-consumer/fault-injection/#fault-injection","title":"Fault Injection","text":""},{"location":"build-consumer/fault-injection/#scenario","title":"Scenario","text":"<p>The user via fault injection on the consumer side to set the delay and error of the request to the specified microservice and its trigger probability.</p>"},{"location":"build-consumer/fault-injection/#precautions","title":"Precautions","text":"<p>The delay time for delay injection requests is unified to the millisecond level.</p>"},{"location":"build-consumer/fault-injection/#configuration-instructions","title":"Configuration instructions","text":"<p>The fault injection configuration is in the microservice.yaml file. The related configuration items are shown in the following table. To enable fault injection in the service consumer, you need to configure the consumer fault injection handler in the processing chain. The configuration example is as follows:</p> <pre><code>servicecomb:\n  handler:\n    chain:\n      Consumer:\n        default: loadbalance,fault-injection-consumer\n</code></pre> <p>Fault injection configuration item description</p> <p>[scope] represents the effective scope of the fault injection. The configurable value includes the global configuration _global or the service name of the microservice [ServiceName].</p> <p>[protocol] represents the communication protocol used, and configurable values \u200b\u200binclude rest or highway.</p> <p>| Configuration Item | Default Value | Range of Value | Required | Meaning | | :--- | :--- | :--- | :--- | :--- | :--- | | servicecomb.governance.Consumer.[scope].policy.fault.protocols.[protocol].delay.fixedDelay | None | (0,9223372036854775807], Long Shaping | No | Consumer Send Delay Injection Request Delay time | current time unit is milliseconds | | servicecomb.governance.Consumer.[scope].policy.fault.protocols.[protocol].delay.percent | 100 | (0,100], Shaping | No | Trigger Probability of Sending Delay Injection Requests by Consumers | | | servicecomb.governance.Consumer.[ServiceName].schemas.[schema].policy.fault.protocols.[protocol].delay.fixedDelay | None | (0,9223372036854775807], Long Shaping| No | Delay time for delay injection request sent by the consumer to the corresponding schema | Support for schema level configuration | | servicecomb.governance.Consumer.[ServiceName].schemas.[schema].policy.fault.protocols.[protocol].delay.percent | 100 | (0,100],Plastic| No| Consumer Trigger probability of a delayed injection request sent by the end to the corresponding schema | Support for schema level configuration | | servicecomb.governance.Consumer.[ServiceName].schemas.[schema].operations.[operation].policy.fault.protocols.[protocol].delay.fixedDelay | None | (0 ,9223372036854775807],long shaping| no|delay time of delay injection request sent by the consumer to the corresponding operation | support operation level configuration | | servicecomb.governance.Consumer.[ServiceName].schemas.[schema].operations.[operation].policy.fault.protocols.[protocol].delay.percent | 100 | (0,100 ], shaping|no| trigger probability of delay injection request sent by the consumer to the corresponding operation | support operation level configuration | | servicecomb.governance.Consumer.[scope].policy.fault.protocols.[protocol].abort.httpStatus | None | (100,999], Shaping | No | The http error sent by the Consumer to send an error injection request Code| | | servicecomb.governance.Consumer.[scope].policy.fault.protocols.[protocol].abort.percent | 100 | (0,100], Shaping | No | Trigger Probability of Sending Error Injection Requests by Consumers | | | servicecomb.governance.Consumer.[ServiceName].schemas.[schema].policy.fault.protocols.[protocol].abort.httpStatus | None | (100,999],Plastic| No| Consumer Http error code sent by the end to the corresponding schema error injection request | Support schema level configuration | | servicecomb.governance.Consumer.[ServiceName].schemas.[schema].policy.fault.protocols.[protocol].abort.percent | 100 | (0,100],Plastic| No| Consumer Trigger probability of error injection request sent by the end to the corresponding schema | Support schema level configuration | | servicecomb.governance.Consumer.[ServiceName].schemas.[schema].operations.[operation].policy.fault.protocols.[protocol].abort.httpStatus | None | (100,999 ], shaping | No | http error code sent by the consumer to the error injection request of the corresponding operation | Support operation level configuration | | servicecomb.governance.Consumer.[ServiceName].schemas.[schema].operations.[operation].policy.fault.protocols.[protocol].abort.percent | 100 | (0,100 ], shaping | No | Trigger probability of error injection request sent by the consumer to the corresponding operation | Support operation level configuration |</p>"},{"location":"build-consumer/fault-injection/#sample-code","title":"Sample Code","text":"<pre><code>servicecomb:\n  governance:\n    Consumer:\n      _global:\n        policy:\n          fault:\n            protocols:\n              rest:\n                delay:\n                  fixedDelay: 5000\n                  percent: 10\n</code></pre> <pre><code>servicecomb:\n  governance:\n    Consumer:\n      ServerFaultTest:\n        schemas:\n          schema:\n            operations:\n              operation:\n                policy:\n                  fault:\n                    protocols:\n                      rest:\n                        abort:\n                          httpStatus: 421\n                          percent: 100\n</code></pre>"},{"location":"build-consumer/flow-control/","title":"Flow Control","text":""},{"location":"build-consumer/flow-control/#flow-control-policy","title":"Flow Control Policy","text":""},{"location":"build-consumer/flow-control/#scenario","title":"Scenario","text":"<p>You can limit the frequency of request send to specific microservice when flow control was enables in consumer service. </p>"},{"location":"build-consumer/flow-control/#precaution","title":"Precaution","text":"<p>See detail info at Service Configurations\u3002</p>"},{"location":"build-consumer/flow-control/#configuration","title":"Configuration","text":"<p>Flow control policy configuration is in microservice.yaml file. You need to configure consumer handler in chain of service. See example blow:</p> <pre><code>servicecomb:\n  handler:\n    chain:\n      Consumer:\n        default: qps-flowcontrol-consumer\n</code></pre> <p>Configuration items of QPS:</p> Configuration Item Default Value Value Range Mandatory Description Remark servicecomb.flowcontrol.Consumer.qps.enabled true Boolean No Specifies whether consumers flowcontrol enables. - servicecomb.flowcontrol.Consumer.qps.limit.[ServiceName].[Schema].[operation] 2147483647  (max int) (0,2147483647], Integer No Specifies number of requests per second. Support three level configurations: microservice\u3001schema\u3001operation."},{"location":"build-consumer/invoke-control/","title":"Invoke control","text":""},{"location":"build-consumer/invoke-control/#circuit-break-policy","title":"Circuit Break Policy","text":"<p>Circuit brake policy can configure ServiceComb fallback capability, you can configure conditions under which service will stop send request after circuit break policy configured.</p>"},{"location":"build-consumer/invoke-control/#flow-control-policy","title":"Flow Control Policy","text":"<p>You can limit the frequency of request send to specific microservice when flow control was enables in consumer service. </p>"},{"location":"build-consumer/invoke-control/#fault-injection","title":"Fault Injection","text":"<p>The user via fault injection on the consumer side to set the delay and error of the request to the specified microservice and its trigger probability.</p>"},{"location":"build-consumer/using-AsyncRestTemplate/","title":"Develop consumer with AsyncRestTemplate","text":""},{"location":"build-consumer/using-AsyncRestTemplate/#concepts","title":"Concepts","text":"<p>AsyncRestTemplate allows users to make asynchronous service calls. The logic is similar to restTemplate, except that the service is called asynchronously.</p>"},{"location":"build-consumer/using-AsyncRestTemplate/#sample-code","title":"Sample code","text":"<p>The AsyncRestTemplate instance is created and retrieved via <code>new CseAsyncRestTemplate()</code>, which is then used to make service calls through a custom URL.</p> <ul> <li>Spring MVC client sample code</li> </ul> <pre><code>\n@Component\npublic class SpringmvcConsumerMain {\n  private static final Logger LOG = LoggerFactory.getLogger(SpringmvcConsumerMain.class);\n\n  public static void main(String[] args) throws Exception {\n    init();\n    Person person = new Person();\n    person.setName(\"ServiceComb/Java Chassis\");\n    //AsyncRestTemplate Consumer\n    CseAsyncRestTemplate cseAsyncRestTemplate = new CseAsyncRestTemplate();\n    ListenableFuture&lt;ResponseEntity&lt;String&gt;&gt; responseEntityListenableFuture = cseAsyncRestTemplate\n        .postForEntity(\"cse://springmvc/springmvchello/sayhi?name=Java Chassis\", null, String.class);\n    ResponseEntity&lt;String&gt; responseEntity = responseEntityListenableFuture.get();\n    System.out.println(\"AsyncRestTemplate Consumer sayHi services: \" + responseEntity.getBody());\n\n    HttpEntity&lt;Person&gt; entity = new HttpEntity&lt;&gt;(person);\n    ListenableFuture&lt;ResponseEntity&lt;String&gt;&gt; listenableFuture = cseAsyncRestTemplate\n        .exchange(\"cse://springmvc/springmvchello/sayhello\", HttpMethod.POST, entity, String.class);\n    //    ResponseEntity&lt;String&gt; responseEntity1 = listenableFuture.get();\n    //    System.out.println(\"AsyncRestTemplate Consumer sayHello services: \" + responseEntity1.getBody());\n    // Set the callback function\n    listenableFuture.addCallback(\n        new ListenableFutureCallback&lt;ResponseEntity&lt;String&gt;&gt;() {\n          @Override\n          public void onFailure(Throwable ex) {\n            LOG.error(\"AsyncResTemplate Consumer catched exception when sayHello, \", ex);\n          }\n\n          @Override\n          public void onSuccess(ResponseEntity&lt;String&gt; result) {\n            System.out.println(\"AsyncRestTemplate Consumer sayHello services: \" + result.getBody());\n          }\n        });\n  }\n\n  public static void init() throws Exception {\n    Log4jUtils.init();\n    BeanUtils.init();\n  }\n}\n\n</code></pre> <p>Note</p> <ul> <li>The URL format is the same with RestTemplate, refer to restTemplate for details</li> <li>The custom ListenableFuture class is the placeholder to get the results from the remote call. Users can also customize the callback function to process the return results in batches.</li> </ul>"},{"location":"build-consumer/using-resttemplate/","title":"Develop consumer with Rest Template","text":""},{"location":"build-consumer/using-resttemplate/#concepts","title":"Concepts","text":"<p>Rest Template is a RESTful API provided by the Spring framework.  ServiceComb provides the implementation class for service calling</p>"},{"location":"build-consumer/using-resttemplate/#scenario","title":"Scenario","text":"<p>With ServiceComb's RestTemplate instance, users can call the service with a customized URL without knowing the service's address.</p>"},{"location":"build-consumer/using-resttemplate/#sample-code","title":"Sample Code","text":"<p>The RestTemplate instance is created by the static method  <code>RestTemplateBuilder.create()</code>. Then, users can call the microservices with the instance and the customized URL. The code is as follows:</p> <ul> <li>Sample code for Sprint MVC consumer</li> </ul> <pre><code>import org.springframework.stereotype.Component;\nimport org.springframework.web.client.RestTemplate;\n\nimport org.apache.servicecomb.foundation.common.utils.BeanUtils;\nimport org.apache.servicecomb.foundation.common.utils.Log4jUtils;\nimport org.apache.servicecomb.provider.springmvc.reference.RestTemplateBuilder;\nimport org.apache.servicecomb.samples.common.schema.models.Person;\n\n@Component\npublic class SpringmvcConsumerMain {\n    private static RestTemplate restTemplate = RestTemplateBuilder.create();\n\n    public static void main(String[] args) throws Exception {\n        init();\n        Person person = new Person();\n        person.setName(\"ServiceComb/Java Chassis\");\n        String sayHiResult = restTemplate\n                .postForObject(\"cse://springmvc/springmvchello/sayhi?name=Java Chassis\", null, String.class);\n        String sayHelloResult = restTemplate\n                .postForObject(\"cse://springmvc/springmvchello/sayhello\", person, String.class);\n        System.out.println(\"RestTemplate consumer sayhi services: \" + sayHiResult);\n        System.out.println(\"RestTemplate consumer sayhello services: \" + sayHelloResult);\n    }\n\n    public static void init() throws Exception {\n        Log4jUtils.init();\n        BeanUtils.init();\n    }\n}\n</code></pre> <ul> <li>Sample code for JAX RS Consumer:</li> </ul> <pre><code>@Component\npublic class JaxrsConsumerMain {\n\n    public static void main(String[] args) throws Exception {\n        init();\n        // The rest is just like the Spring MVC Consumer sample code, notice that if the provider only accepts GET requests, the consumer should use method getForObject()\n        RestTemplate restTemplate = RestTemplateBuilder.create();\n        String result = restTemplate.getForObject(\"cse://jaxrs/jaxrshello/saybye\", String.class);\n    }\n\n    public static void init() throws Exception {\n        Log4jUtils.init();\n        BeanUtils.init();\n    }\n}\n</code></pre> <p>NOTE:</p> <ul> <li>The URL should be in format: <code>cse//microserviceName/path?querystring</code>. Taking the provider example from Develop micro service with SpringMVC, the micro service's name is <code>springmvc</code>, the basePath is <code>/springmvchello</code>, then the microserviceName in the URL is <code>springmvc</code>, the path to call sayhi is <code>springmvchello/sayhi</code>, so the URL for sayhi in the sample is <code>cse://springmvc/springmvchello/sayhi?name=Java Chassis</code>, below is the code for the provider:</li> </ul> <pre><code>@RestSchema(schemaId = \"springmvcHello\")\n@RequestMapping(path = \"/springmvchello\", produces = MediaType.APPLICATION_JSON)\n//\u8fd9\u91cc path = \u201c/springmvchello\u201d \u4e2d\u7684 springmvchello \u5c31\u662f \u4e0a\u8ff0\u7684basePath\npublic class SpringmvcHelloImpl implements Hello {\n    @Override\n    @RequestMapping(path = \"/sayhi\", method = RequestMethod.POST)\n    public String sayHi(@RequestParam(name = \"name\") String name) {\n        return \"Hello \" + name;\n    }\n\n    @Override\n    @RequestMapping(path = \"/sayhello\", method = RequestMethod.POST)\n    public String sayHello(@RequestBody Person person) {\n        return \"Hello person \" + person.getName();\n    }\n}\n</code></pre> <p>The following configuration is the file <code>resources/microservice.yaml</code> of the springmvc-provider module in the SpringMVC sample:</p> <pre><code>APPLICATION_ID: springmvc-sample\nservice_description:\n  name: springmvc # The name of the micro service\n  version: 0.0.2\nservicecomb:\n  service:\n    registry:\n      address: http://127.0.0.1:30100\n  rest:\n    address: 0.0.0.0:8080\n  highway:\n    address: 0.0.0.0:7070\n</code></pre> <ul> <li>With the URL format, ServiceComb framework will perform internal microservice descovery, fallback, fault tolerance and send the requests to the microservice providers.</li> </ul>"},{"location":"build-consumer/with-contract/","title":"Using Contracts","text":""},{"location":"build-consumer/with-contract/#scenario","title":"Scenario","text":"<p>When a consumer calls a service from a provider, the contract is required. The consumer can get the providers' contracts in 2 ways: get the providers' contract from off-line, then manually configure it in the  project. Or, download the contract from the service center.</p>"},{"location":"build-consumer/with-contract/#configuration","title":"Configuration","text":"<p>NOTE</p> <p>Users can get the contract in either way, regardless of the consumers' development mode.</p>"},{"location":"build-consumer/with-contract/#configure-the-dependencies","title":"Configure the Dependencies","text":"<p>In the microservice.yaml file, configure a provider for the consumer. The following is an example of the configuration:</p> <pre><code>servicecomb:\n  # other configurations omitted\n  references:\n    springmvc:\n      version-rule: 0.0.1\n</code></pre> <p>The version-rule field is the rules to match the version, there are 4 version-rule formats:</p> <ul> <li>Accurate version: such as <code>version-rule: 0.0.1</code>, it indicates that only those  providers with version 0.0.1 are matched.</li> <li>Later versions: such as <code>version-rule: 1.0.0+</code>, it indicates that those providers with version greater than 1.0.0 are matched.</li> <li>Latest version: <code>version-rule: latest</code>, it indicates that only  those providers with the latest are matched.</li> <li>Version range: such as<code>1.0.0-2.0.2</code>,  it indicates that those provider with versions between 1.0.0 and 2.0.2 are matched, including 1.0.0 and 2.0.2</li> </ul> <p>The default version matching rule is <code>latest</code>.</p>"},{"location":"build-consumer/with-contract/#manually-configure-contracts","title":"Manually Configure Contracts","text":"<p>When providers' contracts are obtained from off-line,  they should be put into the specific directory of the consumer project. The directory is the one mentioned in the configuration description Service Contract.</p> <p>Each directory under the microservices directory indicates a microservice, and each yaml file under the microservice directory represents a contract schema. The file name is the schemaId. The contracts stored in application folder should specify the appId for cross application access. The directory tree is as follows:</p> <pre><code>resources\n  - microservices\n      - serviceName            # Microservice name\n          - schemaId.yaml      # The contract schemaId\n  - applications\n      - appId                  # Application ID\n          - serviceName        # Microservice name\n              - schemaId.yaml  # The contract schemaId\n</code></pre>"},{"location":"build-consumer/with-contract/#automatically-download-contract-from-service-center","title":"Automatically Download Contract from Service Center","text":"<p>If a consumer does not explicitly store the contract in the project, when the application starts, ServiceComb framework automatically downloads contracts from the service center based on the providers' microservices name and version configured in microservice.yaml.</p>"},{"location":"build-provider/access-log-configuration/","title":"Access Log Configuration","text":""},{"location":"build-provider/access-log-configuration/#concepts","title":"Concepts","text":"<p>ServiceComb provides Vert.x based access log. When developing with REST over Vert.x , access log printing can be enabled through a simple configuration.</p>"},{"location":"build-provider/access-log-configuration/#scenario","title":"Scenario","text":"<p>The user may need the access log when debugging the application. When using REST over servlet, the web container provides the access log function; for REST over Vert.x, ServiceComb provides a set of access log functionalities.</p>"},{"location":"build-provider/access-log-configuration/#configuration","title":"Configuration","text":""},{"location":"build-provider/access-log-configuration/#enable-access-log","title":"Enable Access Log","text":"<p>Add the following configurations in the microservice.yaml file to enable access log:</p> <pre><code>servicecomb:\n  accesslog:\n    enabled: true  ## Enable access log\n</code></pre> <p>Access log Configuration Items</p> Configuration Item Values Default Value Description servicecomb.accesslog.enabled true/false false true to enabled access log servicecomb.accesslog.pattern the format of the log \"%h - - %t %r %s %B\" See log configuration items for more details <p>Note</p> <ul> <li>The 2 items are optional, if not configured, the default value will be applied.</li> </ul>"},{"location":"build-provider/access-log-configuration/#log-format-configuration","title":"Log format configuration","text":"<p>The currently available configuration items for log are describe in the following table Log configuration items(Apache &amp; W3C) andLog configuration items(ServiceComb) \u3002</p> <p>Log configuration items (Apache &amp; W3C)</p> Item Apache log format W3C log format Description HTTP method %m cs-method - HTTP status %s sc-status - Duration in second %T - - Duration in millisecond %D - - Remote hostname %h - - Local hostname %v - - Local port %p - - Size of response %B - Print \"0\" if body size is 0 Size of response %b - Print \"-\" if body size is 0 First line of request %r - Include HTTP Method, Uri and HTTP version URI path %U cs-uri-stem - Query string %q cs-uri-query - URI path and query string - cs-uri - Request protocol %H - - Datetime the request is received %t - Print time stamp by the default configuration, the format is \"EEE, dd MMM yyyy HH:mm:ss zzz\", in English and GMT time zone Configurable datetime the request is received %{PATTERN}t - Print time stamp by specified format, in English and GMT time zone Configurable datetime the request is received %{PATTERN|TIMEZONE|LOCALE}t - Print time stamp by the specified format, language and time zone. The items between vertical bar can be empty(while the | should not be omitted) Request header %{VARNAME}i - Print \"-\" if the specified request header is not found Response header %{VARNAME}o - Print \"-\" if the specified response header is not found Cookie %{VARNAME}C - Print \"-\" if the specified cookie is not found <p>Log configuration items(ServiceComb)</p> Element Placeholder Comment TraceId %SCB-traceId Print the trace id generated by ServiceComb, if the id is not found, print \"-\" Invocation Context %{VARNAME}SCB-ctx Print the invocation context value whose key is <code>VARNAME</code>, if the key is not found, print \"-\""},{"location":"build-provider/access-log-configuration/#output-file-configuration","title":"Output file configuration","text":"<p>The default log framework for Access log is Log4j which provides a default set of configurations for output files. Users can override these configurations in their own log4j.properties file. The configuration items for output files are as follows.</p> <p>Log file configuration items</p> Item Default Value Description Remarks paas.logs.accesslog.dir ${paas.logs.dir} The output path of the log file The common logs will be outputted to the same path paas.logs.accesslog.file access.log Name of the log file - log4j.appender.access.MaxBackupIndex 10 Max file numbers for log rotating - log4j.appender.access.MaxFileSize 20MB Max size of log file When log file reaches the max size, log rotating is triggered .appender.access.logPermission rw------- Log file permissions - <p>Note  Since ServiceComb's log function relies only on the slf4j interface, users can select other log frameworks. For other frameworks, users need to configure the log file output options.</p>"},{"location":"build-provider/access-log-configuration/#switch-to-logback","title":"Switch to logback","text":"<p>For the project that uses logback, the log framework dependency should be changed from Log4j to logback with some extra configurations to make access log work.</p>"},{"location":"build-provider/access-log-configuration/#1-remove-log4j-dependencies","title":"1. Remove Log4j dependencies","text":"<p>Before switching to logback, check the dependencies of the project and remove Log4j related dependencies. Run the maven command <code>dependency:tree</code> in the project, find the ServiceComb components that depend on Log4j, and add the following configuration to its <code>&lt;dependency&gt;</code>:</p> <pre><code>&lt;exclusion&gt;\n  &lt;groupId&gt;org.slf4j&lt;/groupId&gt;\n  &lt;artifactId&gt;slf4j-log4j12&lt;/artifactId&gt;\n&lt;/exclusion&gt;\n</code></pre>"},{"location":"build-provider/access-log-configuration/#2-add-a-logback-dependency","title":"2. Add a logback dependency","text":"<p>Add a dependency for the logback in the pom file:</p> <pre><code>&lt;dependency&gt;\n  &lt;groupId&gt;org.slf4j&lt;/groupId&gt;\n  &lt;artifactId&gt;slf4j-api&lt;/artifactId&gt;\n&lt;/dependency&gt;\n&lt;dependency&gt;\n  &lt;groupId&gt;ch.qos.logback&lt;/groupId&gt;\n  &lt;artifactId&gt;logback-classic&lt;/artifactId&gt;\n&lt;/dependency&gt;\n&lt;dependency&gt;\n  &lt;groupId&gt;ch.qos.logback&lt;/groupId&gt;\n  &lt;artifactId&gt;logback-core&lt;/artifactId&gt;\n&lt;/dependency&gt;\n</code></pre>"},{"location":"build-provider/access-log-configuration/#3-configure-the-logger-for-the-access-log-component","title":"3. Configure the logger for the access log component","text":"<p>Since the log component provided by ServiceComb obtains the logger named <code>accesslog</code> for log printing, the key to log framework switching is to provide a file called <code>accesslog</code> and configure the output file for it. The following is a sample configuration of the access log for logback. It only shows the configurations related to the access log. Other log configurations are omitted:</p> <pre><code>&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;\n&lt;configuration&gt;\n  &lt;!-- Users can customize the appender by their requirement --&gt;\n  &lt;appender name=\"ACCESSLOG\" class=\"ch.qos.logback.core.rolling.RollingFileAppender\"&gt;\n    &lt;file&gt;./logs/access.log&lt;/file&gt;\n    &lt;rollingPolicy class=\"ch.qos.logback.core.rolling.TimeBasedRollingPolicy\"&gt;\n      &lt;fileNamePattern&gt;./logs/access-%d{yyyy-MM-dd}.log&lt;/fileNamePattern&gt;\n    &lt;/rollingPolicy&gt;\n    &lt;!-- Note: the access log content is formatted in code, the pattern should only specify the message without extra format --&gt;\n    &lt;encoder&gt;\n      &lt;pattern&gt;%msg%n&lt;/pattern&gt;\n    &lt;/encoder&gt;\n  &lt;/appender&gt;\n\n  &lt;!-- Provide a logger named \"accesslog\" for log printing --&gt;\n  &lt;logger name=\"accesslog\" level=\"INFO\" additivity=\"false\"&gt;\n    &lt;appender-ref ref=\"ACCESSLOG\" /&gt;\n  &lt;/logger&gt;\n&lt;/configuration&gt;\n</code></pre>"},{"location":"build-provider/access-log-configuration/#extending-access-log","title":"Extending Access Log","text":"<p>Users can customize their AccessLogItem by ServiceComb's AccessLogItem extension mechanism.</p>"},{"location":"build-provider/access-log-configuration/#related-classes","title":"Related classes","text":"<ol> <li><code>AccessLogItem</code></li> </ol> <pre><code>  public interface AccessLogItem&lt;T&gt; {\n    /**\n     * Get specified content from accessLogParam, generate the access log and return\n     */\n    String getFormattedItem(AccessLogParam&lt;T&gt; accessLogParam);\n  }\n</code></pre> <p>The definition of <code>AccessLogItem</code> is as shown above. When request triggers Access Log printing, ServiceComb's Access Log mechanism will traverse a valid <code>AccessLogItem</code>, call the <code>getFormattedItem</code> method to get the item's Access Log fragment, concatenate all the the fragments into an Access Log, and output it to the log file.</p> <p>The parameter <code>AccessLogParam&lt;T&gt;</code> contains the request start time, the end time, and the request context of type <code>T</code>. In the REST over Vert.x communication mode, the type <code>T</code> is the <code>RoutingContext</code> of Vert.x.</p> <ol> <li><code>VertxRestAccessLogItemMeta</code></li> </ol> <pre><code>  // pattern placeholder prefix\n  protected String prefix;\n  // pattern placeholder suffix\n  protected String suffix;\n  // order number of priority\n  protected int order;\n  // AccessLogItem constructor\n  protected AccessLogItemCreator&lt;RoutingContext&gt; accessLogItemCreator;\n</code></pre> <p>The  <code>VertxRestAccessLogItemMeta</code> contains the properties listed above, it specifies how ServiceComb parse the pattern string to get specific AccessLogItem.</p> <ul> <li> <p>To define a <code>AccessLogItem</code> with placeholder <code>%user-defined</code>, declare a subclass of <code>VertxRestAccessLogItemMeta</code>\uff0cset prefix=\"%user-defined\", suffix=null, when <code>AccessLogPatternParser</code> parses the \"%user-defined\", it will fetch the <code>AccessLogItemCreator</code> from the meta class and create the corresponding <code>AccessLogItem</code>. Note: since there is not variable in placeholder \"%user-defined\", the call to <code>AccessLogItemCreator</code> passes the configuration parameter null\u3002</p> </li> <li> <p>To get a <code>AccessLogItem</code> with placeholder <code>%{VARNAME}user-defined</code>, declare a subclass of<code>VertxRestAccessLogItemMeta</code>, set prefix=\"%{\", suffix=\"}user-defined\". When <code>AccessLogPatternParser</code>parses \"%{VARNAME}user-defined\", it will extract the \"VARNAME\" as parameter to call <code>AccessLogItemCreator</code>, to create a <code>AccessLogItem</code>.</p> </li> </ul> <p><code>VertxRestAccessLogItemMeta</code> has a subclass<code>CompositeVertxRestAccessLogItemMeta</code>. When user needs to define multiple AccessLogItems, multiple <code>VertxRestAccessLogItemMeta</code> can be aggregated into <code>CompositeVertxRestAccessLogItemMeta</code>. When Parser loads AccessLogItemMeta of type <code>CompositeVertxRestAccessLogItemMeta</code>, it calls the meta class's <code>getAccessLogItemMetas()</code> method to get a set of AccessLogItemMeta. <code>VertxRestAccessLogItemMeta</code> is loaded by the SPI mechanism, and <code>CompositeVertxRestAccessLogItemMeta</code> allows user to load multiple meta infos with on one record in the SPI configuration file, which provides great flexibility.</p> <ol> <li><code>AccessLogItemCreator</code></li> </ol> <pre><code>  public interface AccessLogItemCreator&lt;T&gt; {\n    // Receive configuration values and return an AccessLogItem. The method receives a null if there is no variables in AccessLogItem placeholder\n    AccessLogItem&lt;T&gt; createItem(String config);\n  }\n</code></pre> <p>The user instantiates his AccessLogItem by setting the AccessLogItemCreator in the custom VertxRestAccessLogItemMeta. Since this is a functional interface, when the AccessLogItem is initialized in a simple way, you can directly define the Creator using a Lambda expression to simplify development.</p>"},{"location":"build-provider/access-log-configuration/#matching-rules-of-accesslogitemmeta","title":"Matching rules of AccessLogItemMeta","text":"<p>Once AccessLogItemMeta is loaded into the Parser, it will be sorted once. Parser will match the meta list from front to back when parsing the pattern string. The general matching rules are as follows: 1. Match metas with higher priority. 2. Match the meta with suffix first. When metas with multiple suffixes are matched, ~~take the one with the smallest suffix.~~ 3. Match the meta with a longer placeholder, for example, there are two metas, \"%abc\" and \"%a\". If  \"%abc\" is matched, it will return directly.</p>"},{"location":"build-provider/access-log-configuration/#sample","title":"Sample","text":"<ol> <li>Extend AccessLogItem</li> </ol> <p>First, the user needs the AccessLogItem interface to implement their own item:</p> <pre><code>  public class UserDefinedAccessLogItem implements AccessLogItem&lt;RoutingContext&gt; {\n    private String config;\n\n    public UserDefinedAccessLogItem(String config) {\n      this.config = config;\n    }\n\n    @Override\n    public String getFormattedItem(AccessLogParam&lt;RoutingContext&gt; accessLogParam) {\n      // Here is the user's custom logic, user needs to take relevant data from AccessLogParam or other places, generate and return access log fragments\n      return \"user-defined-[\" + config + \"]-[\" + accessLogParam.getStartMillisecond() + \"]\";\n    }\n  }\n</code></pre> <ol> <li>Define AccessLogItem meta class</li> </ol> <p>Inherit the class <code>VertxRestAccessLogItemMeta</code> or <code>CompositeVertxRestAccessLogItemMeta</code>, define the prefix and suffix of the AccessLogItem:</p> <pre><code>  public class UserDefinedCompositeExtendedAccessLogItemMeta extends CompositeVertxRestAccessLogItemMeta {\n    private static final List&lt;VertxRestAccessLogItemMeta&gt; META_LIST = new ArrayList&lt;&gt;();\n\n    static {\n      META_LIST.add(new VertxRestAccessLogItemMeta(\"%{\", \"}user-defined\", UserDefinedAccessLogItem::new));\n    }\n\n    @Override\n    public List&lt;VertxRestAccessLogItemMeta&gt; getAccessLogItemMetas() {\n      return META_LIST;\n    }\n  }\n</code></pre> <ol> <li>Configure the SPI load file</li> </ol> <p>In the <code>resources/META-INF/services/</code> directory, create a file named \"org.apache.servicecomb.transport.rest.vertx.accesslog.parser.VertxRestAccessLogItemMeta\" and fill in the full class path of the meta class defined in the previous step. Parser will use this file to load the meta class.</p> <ol> <li>Configure Access Log pattern</li> </ol> <p>The configuration pattern in the microservice.yaml file is assumed to be \"%{test-config}user-defined\". The running service triggers the Access Log to print. If the request start time is 1, Access Log will print \"user- Defined-[test-config]-[1]\".</p>"},{"location":"build-provider/access-log-configuration/#sample-code","title":"Sample code","text":""},{"location":"build-provider/access-log-configuration/#configurations-in-microserviceyaml","title":"Configurations in microservice.yaml","text":"<pre><code>## other configurations omitted\nservicecomb:\n  accesslog:\n    enabled: true  ## Enable access log\n    pattern: \"%h - - %t %r %s %B\"  ## Custom log format\n</code></pre>"},{"location":"build-provider/access-log-configuration/#configurations-in-log4jproperties","title":"Configurations in log4j.properties","text":"<pre><code># access log configuration item\npaas.logs.accesslog.dir=../logs/\npaas.logs.accesslog.file=access.log\n# access log File appender\nlog4j.appender.access.MaxBackupIndex=10\nlog4j.appender.access.MaxFileSize=20MB\nlog4j.appender.access.logPermission=rw-------\n</code></pre>"},{"location":"build-provider/bootup/","title":"Application Boot-up Process","text":""},{"location":"build-provider/bootup/#concepts","title":"Concepts","text":"<p>The startup process of a service provider includes initializing Log4j, loading bean(including its parameters), and registering service.</p> <ul> <li>Initialize Log4j:</li> </ul> <p>By default, Log4jUtils merges the log4j configurations from <code>classpath\\*:config/base/log4j.properties</code> and <code>classpath\\*:config/log4j.properties</code>, then transfer them to log4j's <code>PropertyConfigurator</code> method to initialize it. If the configuration file with the highest priority is stored on the disk directory with write permission, the combined configuration will be saved to this location to view which parameters take effect during maintenance.</p> <ul> <li>Load the bean.</li> </ul> <p>By default <code>BeanUtils</code>  loads the configuration file from the <code>classpath\\*:META-INF/spring/\\*.bean.xml</code> and transfer the configuration to <code>ClassPathXmlApplicationContext</code> of the Spring framework to load the application context. The bean of foundation-config module will be loaded during the process.</p> <ul> <li> <p>Register the service.</p> <p>When Spring context is loaded, <code>org.apache.servicecomb.core.CseApplicationListener</code> will load the handlers configurations and providers' schema info, then register the microservice in the Service Center.</p> </li> </ul> <p>NOTE:</p> <p>ServiceComb has 3 configuration sources: configuration center, environment variables and local files, with priorities from high to low. If there are configuration items with the same name in different sources, then items with lower priority will be overwritten. Configuration items stored in the configuration center can be modified at runtime.</p>"},{"location":"build-provider/code-first/","title":"Implicit API definition","text":""},{"location":"build-provider/code-first/#implicit-contract","title":"Implicit Contract","text":""},{"location":"build-provider/code-first/#concept-description","title":"Concept Description","text":"<p>The Implicit Contract definition is ServiceComb automatically generate a contract of service based on the service implementation class.</p>"},{"location":"build-provider/code-first/#scenario","title":"Scenario","text":"<p>By using the implicit API definition you can define the implementation class without pre-defining APIs. When the service is started, an API is automatically generated and registered to the service center.</p>"},{"location":"build-provider/code-first/#involved-api","title":"Involved API","text":"<p>Implicit API definitions can be used for Spring MVC, JAX-RS, and transparent RPC development modes, For details, see Development Style-SpringMVC, Development Stype-JAX-RS and Development Style-Transparent RPC.</p> <p>When you develop a microservice in transparent RPC mode, the code does not show how you want to define an API, and all generated APIs are POST methods, The input parameters of all the methods will be packaged as a class and transferred as body parameters. Therefore, if you develop providers using implicit APIs, you are advised to choose Spring MVC or JAX-RS mode to obtain complete RESTful statements.</p>"},{"location":"build-provider/define-contract/","title":"Service Contract Definition","text":""},{"location":"build-provider/define-contract/#concept-description","title":"Concept Description","text":"<p>The Service Contract refers to the micro-service interface contract based on the OpenAPI specification. The interface definition between the server and the consumer. The java chassis provides two ways to define the contract: 'code first' and 'contract first'.</p> <ul> <li> <p>Code first The Producer use of Jax-RS or SpringMVC's RESTful annotation declares the input and output parameters of the interface, or with the OpenAPI annotations, to add human-readable information, such as sample code, text descriptions, etc.; when the ServiceComb engine starts, according to these annotations generate a contract description and automatically upload it to the service center.  The producer can also be developed using the transparent RPC model, but since there is no RESTful annotation to guide how to generate the contract, at this time, the automatically generated contract very non-standard and not recommended. The consumer is called with a transparent RPC or RestTemplate.  Under the code first development model, developers do not have to handwritten contracts.  </p> </li> <li> <p>Contract first In this scenario, instead of using the contract automatically generated by the framework, the contract file provided by the developer is directly used, which requires the developer to ensure the consistency of the contract and the code.</p> </li> </ul>"},{"location":"build-provider/define-contract/#scenario","title":"Scenario","text":"<p>The service contract is used for decoupling between the server and the consumer. The server implements the service around the contract. The consumer invokes the service according to the contract, which can support the server and the consumer to implement in different programming languages.</p> <p> Description:  The service provider registers the interface contract with the service center at startup, which can be downloaded and used by the service consumer. The interface contract is micro-service-version level information. When multiple micro-service instances are started, if an instance registers the contract with the service center, the service center will not overwrite the existing contract with the contract information registered by the latecomer. Therefore, only modifying the service provider's interface information will not change the contract stored by the service center. For the service consumer, the acquired interface information is still old. To update the interface contract in the service center, you can choose to upgrade the microservice version number or delete existing microservice information (the latter is not recommended for use in a production environment).</p>"},{"location":"build-provider/define-contract/#configuration","title":"Configuration","text":"<p>ServiceComb defines API in a .yaml file. It's recommended to use Swagger Editor to define the APIs. This tool can check syntax and automaticlly generate an API document. For details about the API definition file format, see  Official OpenAPI documentation\u3002</p> <p>The API definition file is located in \"resources/microservices\" or \"resources/applications\" directory. The directory structure is as follows:</p> <pre><code>resources\n  - microservices\n    - serviceName #Microservice name\n      - schemaId.yaml #schema ID\n  - applications\n    - appId #Application ID\n      - serviceName #Service name\n        - schemaId.yaml #Schema ID\n</code></pre> <p>Note:</p> <ul> <li>ServiceComb's Swagger contract file should be saved using the UTF-8 character set. If the user saves the contract file with a different character set and the file contains Chinese characters, it may cause an unknown error.</li> </ul>"},{"location":"build-provider/define-contract/#sample-code","title":"Sample Code","text":"<p>The contents of the schemaId.yaml file in the <code>resources/microservices</code> directory and the <code>resources/application</code> directory are as follows. The interface definitions in the file need to match the actual interface of the service.</p> <pre><code>swagger: '2.0'\ninfo:\n  title: hello\n  version: 1.0.0\n  x-java-interface: org.apache.servicecomb.samples.common.schema.Hello\nbasePath: /springmvchello\nproduces:\n  - application/json\n\npaths:\n  /sayhi:\n    post:\n      operationId: sayHi\n      parameters:\n        - name: name\n          in: query\n          required: true\n          type: string\n      responses:\n        200:\n          description: return value\n          schema:\n            type: string\n        default:\n          description: return a default result\n          schema:\n            type: string\n  /sayhello:\n    post:\n      operationId: sayHello\n      parameters:\n        - name: person\n          in: body\n          required: true\n          schema:\n            $ref: \"#/definitions/Person\"\n      responses:\n        200:\n          description: return value\n          schema:\n            type: string\n        default:\n          description: return a default result\n          schema:\n            type: string\ndefinitions:\n  Person:\n    type: \"object\"\n    properties:\n      name:\n        type: \"string\"\n        description: \"person name\"\n    xml:\n      name: \"Person\"\n</code></pre> <p>NOTE\uff1a * Contract in ServiceComb, it is recommended that basePath not include the web root of the web container, and the url pattern of the servlet.</p> <p>Because ServiceComb supports deployment decoupling, it can be deployed independently from the servlet container, or deployed to the servlet container using the war, or it can be run using the embedded servlet container. As long as the base path does not contain the web root and the url pattern, the actual url changes caused by the deployment mode modification, the ServiceComb consumer business code does not need to be perceived, and the framework will automatically adapt.</p> <ul> <li>info.x-java-interface needs to indicate the specific interface path, depending on the actual situation of the project.</li> <li>SchemaId can contain \".\" characters, but it is not recommended. This is because the configuration file used by ServiceComb is in yaml format. The \".\" symbol is used to split the configuration item name. If the SchemaId also contains \".\", some configurations that support the contract level may not be recognized correctly.</li> <li>The \".\" character cannot be included in the naming of the OperationId.</li> </ul>"},{"location":"build-provider/interface-constraints/","title":"API Constraints","text":"<p>A Java Chassis API constraints is that an API definition should describe its usage. You can identify how to call the API without checking the code.</p> <p>As developers, we aim at making our APIs easy to be called. However, developers have different understanding about this aim.</p> <p>For example:</p> <pre><code>public Person query(String id);\npublic Object query(String id);\npublic Person query(String name);\n</code></pre> <p>Obviously, if API 1 is called, we know that an ID parameter of String type needs to be transferred. The returned value is of Person type, which contains a string-typed name parameter. If API 2 is called, we do not know how to process the returned value, and need to refer to documents provided by the service provider. API 2 is developed in the perspective of RPC developers.</p> <p>To release an API as a REST API, we can use the swagger file; specify the ID to be transmitted using RequestParam, PathVariable, or RequestBody; or use the label provided by SpringMVC or JAX-RS.</p> <pre><code>public Person query(@RequestParam String id); \npublic Person query(@PathVariable String id); \npublic Person query(@RequestBody String id); \n</code></pre> <p>Generally , simple data types, such as String and int, are transmitted in RequestParam or PathVariable, and complex data types are transmitted in RequestBody after being coded using JSON, to reduce problems cause by HTTP protocol restrictions on developers.</p>"},{"location":"build-provider/interface-constraints/#detailed-constraint-list","title":"Detailed Constraint List","text":"<p>Developers cannot use the following types to define APIs:</p> <ul> <li>Abstract data structures, such as  java.lang.Object, net.sf.json.JsonObject</li> <li>API or abstract class    <code>java    public interface IPerson {...}    public abstract class AbstractPerson  {...}</code></li> <li>Generic type    <code>java    public class PersonHolder&lt;T&gt; {...}</code></li> <li>A collection type of the preceding types or a set without a specified type, such as <code>List&lt;IPerson&gt;, Map&lt;String, PersonHolder&lt;?&gt;&gt;, List, Map</code>. such as <code>List&lt;String&gt;, List&lt;Person&gt;</code> are supported.</li> </ul> <p><code>java    public class GroupOfPerson {IPerson master ...}</code></p> <p>Developers do not need to worry about the constraints. The program automatically checks them when it is started, and displays types as properties.</p>"},{"location":"build-provider/interface-constraints/#protocol-difference","title":"Protocol Difference","text":"<p>Although ServiceComb-Java-Chassis implements transparent transmission between protocols, there are slight differences between protocols due to the limitations of the underlying protocols:</p> <ul> <li> <p>Map, The key supports only string.</p> </li> <li> <p>highway (protobuf restriction)</p> </li> <li>Null values cannot be transmitted over the network, including elements in Collection and array, and value in map.</li> <li> <p>The array and list with the length of 0 are not transmitted over the network. The receiver obtains the default value after decoding them.</p> </li> <li> <p>springmvc</p> </li> <li>Date cannot be used for the path or query parameter. Spring MVC stores toString in path and query, which does not match the swagger standard.</li> </ul>"},{"location":"build-provider/jaxrs/","title":"Develop Microservice with JAX-RS","text":""},{"location":"build-provider/jaxrs/#concept-description","title":"Concept Description","text":"<p>ServiceComb supports developers in developing services in JAX-RS mode by using JAX-RS.</p>"},{"location":"build-provider/jaxrs/#development-example","title":"Development Example","text":"<ul> <li>Step 1 Import dependencies into your maven project:</li> </ul> <p><code>xml     &lt;dependencyManagement&gt;      &lt;dependencies&gt;        &lt;dependency&gt;          &lt;groupId&gt;org.apache.servicecomb&lt;/groupId&gt;          &lt;artifactId&gt;java-chassis-dependencies&lt;/artifactId&gt;          &lt;version&gt;1.0.0-m1&lt;/version&gt;          &lt;type&gt;pom&lt;/type&gt;          &lt;scope&gt;import&lt;/scope&gt;        &lt;/dependency&gt;      &lt;/dependencies&gt;     &lt;/dependencyManagement&gt;     &lt;dependencies&gt;       &lt;!--transport can optional import through endpoint setting in microservice.yaml, we import both rest and highway as example--&gt;       &lt;dependency&gt;         &lt;groupId&gt;org.apache.servicecomb&lt;/groupId&gt;         &lt;artifactId&gt;transport-rest-vertx&lt;/artifactId&gt;       &lt;/dependency&gt;       &lt;dependency&gt;         &lt;groupId&gt;org.apache.servicecomb&lt;/groupId&gt;         &lt;artifactId&gt;transport-highway&lt;/artifactId&gt;       &lt;/dependency&gt;       &lt;dependency&gt;         &lt;groupId&gt;org.apache.servicecomb&lt;/groupId&gt;         &lt;artifactId&gt;provider-jaxrs&lt;/artifactId&gt;       &lt;/dependency&gt;       &lt;dependency&gt;         &lt;groupId&gt;org.slf4j&lt;/groupId&gt;         &lt;artifactId&gt;slf4j-log4j12&lt;/artifactId&gt;       &lt;/dependency&gt;     &lt;/dependencies&gt;</code></p> <ul> <li>Step 2 Implement the service. JAX-RS is used to describe the development of service code. The implementation of the Hello service is as follows:</li> </ul> <p>```java    import javax.ws.rs.POST;    import javax.ws.rs.Path;    import javax.ws.rs.Produces;    import javax.ws.rs.core.MediaType;    import org.apache.servicecomb.samples.common.schema.models.Person;</p> <p>@Path(\"/jaxrshello\")    @Produces(MediaType.APPLICATION_JSON)    public class JaxrsHelloImpl {      @Path(\"/sayhi\")      @POST      public String sayHi(String name) {      \u3000return \"Hello \" + name;      }</p> <pre><code> @Path(\"/sayhello\")\n @POST\n public String sayHello(Person person) {\n   return \"Hello person \" + person.getName();\n }\n</code></pre> <p>}    ```</p> <p>Note: PLEASE MAKE SURE TO MARK @Path ON YOUR PRODUCER(JaxrsHelloImpl), OR THE PATH AND METHOD OF PUBLISHED WILL BE INCORRECT!</p> <p>In this sample the Path of sayHi is <code>/jaxrshello/sayhi</code>, and the Path of sayHello is <code>/jaxrshello/sayhello</code>, if you wish them <code>/sayhi</code> and <code>/sayhello</code>, please change the setting of <code>@Path</code> on the JaxrsHelloImpl to <code>@Path(\"/\")</code>.</p> <ul> <li>Step 3 Release the service. Add <code>@RestSchema</code> as the annotation of the service implementation class and specify schemaID, which indicates that the implementation is released as a schema of the current microservice. The code is as follows:</li> </ul> <p><code>java    import org.apache.servicecomb.provider.rest.common.RestSchema;    // other code omitted    @RestSchema(schemaId = \"jaxrsHello\")    public class JaxrsHelloImpl implements Hello {      // other code omitted    }</code></p> <p>Create the jaxrsHello.bean.xml file in the resources/META-INF/spring directory and configure base-package that performs scanning. The content of the file is as follows:</p> <p>```xml    </p> <p> <pre><code>   &lt;context:component-scan base-package=\"org.apache.servicecomb.samples.jaxrs.provider\"/&gt;\n</code></pre> <p>    ```</p> <ul> <li>Step 4 Add service definition file:</li> </ul> <p>Add microservice.yaml file into resources folder of your project.</p> <ul> <li>Step 5 Add Main class:</li> </ul> <p>```java    import org.apache.servicecomb.foundation.common.utils.BeanUtils;    import org.apache.servicecomb.foundation.common.utils.Log4jUtils;</p> <p>public class Application {      public static void main(String[] args) throws Exception {         //initializing log, loading bean(including its parameters), and registering service, more detail can be found here :  http://servicecomb.incubator.apache.org/users/application-boot-process/         Log4jUtils.init();         BeanUtils.init();      }    }    ```</p>"},{"location":"build-provider/jaxrs/#involved-apis","title":"Involved APIs","text":"<p>Currently, the JAX-RS development mode supports the following annotation. For details about how to use JAX-RS, see JAX-RS official documentation\u3002</p> Remarks Location Description javax.ws.rs.Path schema/operation URL path javax.ws.rs.Produces schema/operation Coding/decoding capability supported by the method javax.ws.rs.DELETE operation http method javax.ws.rs.GET operation http method javax.ws.rs.POST operation http method javax.ws.rs.PUT operation http method javax.ws.rs.QueryParam parameter Obtain parameters from query string javax.ws.rs.PathParam parameter Obtain parameters from path, This parameter must be defined in path. javax.ws.rs.HeaderParam parameter Obtain parameters from header. javax.ws.rs.CookieParam parameter Obtain parameters from cookie. <p>NOTE\uff1a - When the method parameter has no annotation and is not an HttpServletRequest parameter, the parameter is of the body type by default. One method supports a maximum of one body-typed parameter. - You are advised to explicitly define the value of the parameter. Otherwise, the parameter name in the API definition is used, such as <code>@QueryParam\\(\"name\"\\) String name</code> String name instead of <code>@QueryParam String name</code>.</p>"},{"location":"build-provider/listen-address-and-publish-address/","title":"Service listening address and publishing address","text":""},{"location":"build-provider/listen-address-and-publish-address/#concept-description","title":"Concept Description","text":"<p>In JavaChassis, the listening address and publishing address of the service are two independent concepts that can be configured independently:</p> <ul> <li>Listening address: refers to the address that the microservice instance listens to when it starts. This configuration item determines which IPs can be accessed by this IP.</li> <li>Publish Address: refers to the address where the microservice instance is registered to the service center. Other microservice instances will obtain information about this instance through the service center and access the service instance based on the publication address, so this configuration item determines which IP other services actually use to access the service.</li> </ul>"},{"location":"build-provider/listen-address-and-publish-address/#scene-description","title":"Scene Description","text":"<p>The user determines the IP address that the service instance listens to and the IP address requested by other service instances when accessing the instance by configuring the listening address and the publishing address of the service.</p>"},{"location":"build-provider/listen-address-and-publish-address/#configuration-instructions","title":"Configuration instructions","text":"<p>The configuration items of the service listening address are <code>servicecomb.rest.address</code> and <code>servicecomb.highway.address</code>, which respectively correspond to the listening address of the rest transmission mode and the highway transmission mode. The configuration rules for both are the same. The following only uses <code>servicecomb.rest.address</code> as an explanation. The configuration item of the service publishing address is <code>servicecomb.service.publishAddress</code>, which can be configured without **. When this item is not configured, JavaChassis will select the publishing address according to the specific rules.</p> <p>Table 1 Service Release Address Effective Rules</p> Rule Number Listening Address Configuration Publishing Address Configuration Effective Delivery Address 1 127.0.0.1 - 127.0.0.1 2 0.0.0.0 - Select the IP address of a network card as the publishing address. Require that the address cannot be a wildcard address, loopback address, or broadcast address 3 Specific IP - Consistent with the listening address 4 * Specific IP Consistent with the published address configuration item 5 * \"{NIC name}\" Specify the IP of the NIC name, note the need to put quotation marks and brackets &gt; **Note: ** &gt; - The address actually listened to by the service instance is always consistent with the listening address configuration item. &gt; - When using the NIC name to configure the publishing address, you need to use double quotation marks to wrap the NIC name placeholder, otherwise the parsing configuration will be reported. &gt; - The NIC name must be the NIC that the host exists."},{"location":"build-provider/listen-address-and-publish-address/#sample-code","title":"Sample Code","text":"<p>An example of the configuration of the microservice.yaml file is as follows:</p> <pre><code>servicecomb:\n  service:\n    publishAddress: \"{eth0}\" # The publishing address, registered to the service center, will be the IP of the eth0 network card\n  rest:\n    address: 0.0.0.0:8080 # Monitor all NIC IPs of the hos\n  highway:\n    address: 0.0.0.0:7070 # Listen to all NIC IPs of the host\n</code></pre>"},{"location":"build-provider/service-configuration/","title":"Service configuration","text":""},{"location":"build-provider/service-configuration/#load-balancing-policy","title":"Load Balancing Policy","text":"<p>\u2022 ServiceComb provides a Ribbon-based load balancing solution which can be configured through file. There are different routing policies including random, sequential, policy based on response time weight etc. Service Center</p>"},{"location":"build-provider/service-configuration/#rate-limiting-policy","title":"Rate Limiting Policy","text":"<p>\u2022 Users can set the rate limiting policy in the provider's configuration. By setting the request frequency from a particular micro service, provider can limit the max number of requests per second.</p>"},{"location":"build-provider/service-configuration/#fallback-policy","title":"Fallback Policy","text":"<p>\u2022 A fallback policy is used when a service request is abnormal.</p>"},{"location":"build-provider/service-configuration/#parameter-validation","title":"Parameter Validation","text":"<p>\u2022 Users can set parameter validation rules in the provider's configuration. The rules will validate input parameters when provider APIs are called, so the parameters can be defined in a specific format.</p>"},{"location":"build-provider/springmvc/","title":"Develop Microservice with SpringMVC","text":""},{"location":"build-provider/springmvc/#concept-description","title":"Concept Description","text":"<p>ServiceComb supports Spring MVC annotations to define your REST services. The samples project has a lot of working examples.</p>"},{"location":"build-provider/springmvc/#development-example","title":"Development Example","text":""},{"location":"build-provider/springmvc/#step1-define-the-service-interface-optional","title":"Step1 Define the service interface \uff08optional\uff09","text":"<p>Writing a interface for the REST service make it easy to call the service in client in RPC style.</p> <pre><code>public interface Hello {\n    String sayHi(String name);\n    String sayHello(Person person);\n}\n</code></pre>"},{"location":"build-provider/springmvc/#step2-implement-the-services","title":"Step2 Implement the services","text":"<p>The annotations of Spring MVC are used to describe the development of service code. The implementation of the Hello service is as follow:</p> <p>```java @RestSchema(schemaId = \"springmvcHello\") @RequestMapping(path = \"/springmvchello\", produces = MediaType.APPLICATION_JSON) public class SpringmvcHelloImpl implements Hello {     @Override     @RequestMapping(path = \"/sayhi\", method = RequestMethod.POST)     public String sayHi(@RequestParam(name = \"name\") String name) {         return \"Hello \" + name;     }</p> <pre><code>@Override\n@RequestMapping(path = \"/sayhello\", method = RequestMethod.POST)\npublic String sayHello(@RequestBody Person person) {\n    return \"Hello person \" + person.getName();\n}\n</code></pre> <p>}</p> <pre><code>\n### Step3 add a component scan \uff08optional\uff09\n\ncreate `resources/META-INF/spring` folder and add `springmvcprovider.bean.xml`, add component-scan to specify the bean package. This step is optional. The package where main class located is automatically added.\n\n```xml\n&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;\n\n&lt;beans xmlns=\"http://www.springframework.org/schema/beans\"\n       xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n       xmlns:context=\"http://www.springframework.org/schema/context\"\n       xsi:schemaLocation=\"http://www.springframework.org/schema/beans classpath:org/springframework/beans/factory/xml/spring-beans-3.0.xsd\n       http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-3.0.xsd\"&gt;\n\n    &lt;context:component-scan base-package=\"org.apache.servicecomb.samples.springmvc.povider\"/&gt;\n&lt;/beans&gt;\n</code></pre>"},{"location":"build-provider/springmvc/#step4-wrtie-a-main-class","title":"Step4 Wrtie a main class","text":"<p>This code using log4j as the logger framework. Users can change it to any other favorite logger framework.</p> <pre><code>public class SpringmvcProviderMain {\n\n  public static void main(String[] args) throws Exception {\n    Log4jUtils.init();\n    BeanUtils.init();\n  }\n}\n</code></pre>"},{"location":"build-provider/springmvc/#using-pojo-as-query-parameters","title":"Using POJO as query parameters","text":""},{"location":"build-provider/springmvc/#description","title":"Description","text":"<p>SpringBoot supports to map a bean parameter to HTTP queries.</p> <pre><code>@RequestMapping(\"/hello\")\npublic class HelloService {\n  @RequestMapping(value = \"/sayHello\", method = RequestMethod.GET)\n  public String sayHello(Person person) {\n    System.out.println(\"sayHello is called, person = [\" + person + \"]\");\n    return \"Hello, your name is \" + person.getName() + \", and age is \" + person.getAge();\n  }\n}\n</code></pre> <p>ServiceComb supports this usage too, but has following constraints. 1. Must not add any mapping annotations, such as <code>@QueryParam</code> 2. Only map to query parameters, headers and forms not supported. 3. Variables name in POJO definition must be the same as query keys. 4. Only primitive and String types supported in POJO, add <code>@JsonIgnore</code> to other types to ignore it. 5. In consumer site(e.g RestTemplate), still need to use query parameters, can not use POJO.</p>"},{"location":"build-provider/springmvc/#examples","title":"Examples","text":""},{"location":"build-provider/springmvc/#provider","title":"Provider","text":"<ul> <li>service definition</li> </ul> <pre><code>  @RestSchema(schemaId = \"helloService\")\n  @RequestMapping(\"/hello\")\n  public class HelloService {\n    @RequestMapping(value = \"/sayHello\", method = RequestMethod.GET)\n    public String sayHello(Person person) {\n      System.out.println(\"sayHello is called, person = [\" + person + \"]\");\n      return \"Hello, your name is \" + person.getName() + \", and age is \" + person.getAge();\n    }\n  }\n</code></pre> <ul> <li>parameters</li> </ul> <pre><code>  public class Person {\n    private String name;\n    private int age;\n    @JsonIgnore  // add @JsonIgnore to unsupported types\n    private List&lt;Person&gt; children;\n  }\n</code></pre> <ul> <li>Schemas</li> </ul> <pre><code>\nbasePath: \"/hello\"\npaths:\n  /sayHello:\n    get:\n      operationId: \"sayHello\"\n      parameters:\n        # name and age is query parameter\n      - name: \"name\"\n        in: \"query\"\n        required: false\n        type: \"string\"\n      - name: \"age\"\n        in: \"query\"\n        required: false\n        type: \"integer\"\n        format: \"int32\"\n      responses:\n        200:\n          description: \"response of 200\"\n          schema:\n            type: \"string\"\n</code></pre>"},{"location":"build-provider/springmvc/#consumer","title":"Consumer","text":"<ul> <li>Call using RPC</li> <li>add an interface   <code>java     public interface HelloServiceIntf {       String sayHello(String name, int age);     }</code></li> <li>call the interface   <code>java     String result = helloService.sayHello(\"Bob\", 22); // result is \"Hello, your name is Bob, and age is 22\"</code></li> <li>Call using RestTemplate   <code>java     String result = restTemplate.getForObject(       \"cse://provider-service/hello/sayHello?name=Bob&amp;age=22\",       String.class);</code></li> </ul>"},{"location":"build-provider/springmvc/#servicecomb-suppoted-spring-mvc-annotations-and-differences","title":"ServiceComb suppoted Spring MVC annotations and differences","text":"<p>ServiceComb supports Spring MVC annotatioins(org.springframework.web.bind.annotation) to define REST interfaces, but they are different. ServiceComb do not support <code>@Controller</code> frameworks and only support <code>@RestController</code> frameworks.</p> <ul> <li>Differences in supported annotations</li> </ul>"},{"location":"build-provider/springmvc/#table-1-1-annotations","title":"Table 1-1 annotations","text":"annotation supported notes RequestMapping Yes Can only have one path, multiple path is not supported. GetMapping Yes PutMapping Yes PostMapping Yes DeleteMapping Yes PatchMapping Yes RequestParam Yes CookieValue Yes PathVariable Yes RequestHeader Yes RequestBody Yes supports application/json\uff0cplain/text RequestPart Yes Used in file upload. Using Part\u3001MultipartFile annotations. ResponseBody No @Controller framework is not supported ResponseStatus No Using ApiResponse to define status code RequestAttribute No SessionAttribute No MatrixVariable No ModelAttribute No ControllerAdvice No CrossOrigin No ExceptionHandler No InitBinder No <ul> <li>Define a REST service</li> </ul> <p>Spring MVC using <code>@RestController</code> to define a REST service\uff0cServiceComb using <code>@RestSchema</code> to define a REST service\uff0cand path value in <code>@RequestMapping</code> is required.</p> <pre><code>@RestSchema(schemaId = \"hello\")\n@RequestMapping(path = \"/\")\n</code></pre> <p><code>@RestController</code> is also supported and equals to <code>@RestSchma(schemaId=\"class name\")</code>. However we suggest using <code>@RestSchema</code> to define a schemaId\uff0cit's more convenient when used in configurations.  </p> <p>Cautions: If the classes with <code>@RestController</code> are not expected to be processed by ServiceComb-Java-Chassis and work as REST services, the config item <code>servicecomb.provider.rest.scanRestController=false</code> can be specified to disable the feature mentioned above.</p> <ul> <li>Supported data types</li> </ul> <p>Spring MVC supports almost all java types in service difinition, e.g.</p> <pre><code>// abstract class\npublic void postData(@RequestBody Object data)\n// interface\npublic void postData(@RequestBody IPerson interfaceData)\n// generic without types\npublic void postData(@RequestBody Map rawData)\n// servlet types\npublic void postData(HttpServletRequest rquest)\n</code></pre> <p>ServiceComb need to generate Open API schemas based on definition, and support cross language features, so some of there usage is not supported.</p> <p>HttpServletRequest\uff0cObject is supported in latest version, but they are different. We suggest not using there features if possible.</p> <p>please refer to API Constraints for data type supports.</p>"},{"location":"build-provider/swagger-annotation/","title":"Using Swagger annotations","text":""},{"location":"build-provider/swagger-annotation/#concept-description","title":"Concept Description","text":"<p>Swagger provides a set of annotations for describing interface contracts. Users can use annotations to add descriptions of contracts to their code. ServiceComb supports part of these annotations.</p>"},{"location":"build-provider/swagger-annotation/#scene-description","title":"Scene Description","text":"<p>By using annotations to describe interface contracts, users can use ServiceComb's Swagger contract generation function to automatically generate contract documents that meet the requirements without having to manually write and modify contracts, which can effectively improve development efficiency.</p>"},{"location":"build-provider/swagger-annotation/#configuration-instructions","title":"Configuration instructions","text":"<p>The official description can be found in the [Swagger Annotation Document] (https://github.com/swagger-api/swagger-core/wiki/Annotations-1.5.X). You can refer to the official documentation and this guide to learn how to use annotations to specify the properties of a Swagger contract under the ServiceComb framework.</p> <p>In ServiceComb, Swagger annotations are not required. When a user uses SpringMVC and JAX-RS annotations to annotate microservice methods, ServiceComb can infer the contract information for each microservice method based on the values \u200b\u200bof these annotations.</p>"},{"location":"build-provider/swagger-annotation/#api","title":"<code>@Api</code>","text":"<p><code>@Api</code> acts at the class level and is used to mark a Class as a Swagger resource in the official Swagger description. However, this annotation is not required in ServiceComb. ServiceComb can determine which classes need to parse the Swagger contract based on <code>@RestSchema</code> and <code>@RpcSchema</code>.</p> Attribute Type Description Tags string set the default tag value of the operation defined under the current Class consumes string specify the MIME types of request in schema level, separated by commas produces string specify the MIME types of response in schema level, separated by commas"},{"location":"build-provider/swagger-annotation/#swaggerdefinition","title":"<code>@SwaggerDefinition</code>","text":"<p>Acts at the class level to define information in a Swagger resource.</p> Attribute Type Description info.title string Contract Document Title info.description string Description info.version string contract version number info.termsOfService string Terms of Service info.contact string Contact information, including name, email, url attributes info.license string License information, including name, url attribute info.extensions string Extended Information consumes string Receive Request Format produces string returned response format schemes SwaggerDefinition.Scheme Optional values \u200b\u200bare <code>HTTP/HTTPS/WS/WSS/DEFAULT</code> tags <code>@Tag</code> Tag definition, @Tag contains three attributes: name, description, externalDocs externalDocs <code>@externalDocs</code> External documentation links, including values \u200b\u200band urls"},{"location":"build-provider/swagger-annotation/#apioperation","title":"<code>@ApiOperation</code>","text":"<p>Acts at the method level to describe a Swagger operation.</p> Attribute Type Description value string A brief description of the method, corresponding to the <code>summary</code> field of the Swagger contract operation notes string Details, corresponding to the <code>description</code> field of the Swagger contract operation Tags string label operation label code int HTTP status code for response messages response Class&lt;?&gt; Method return value type responseContainer string The container type that wraps the return value. The optional values \u200b\u200bare <code>List</code>, <code>Set</code>, <code>Map</code> ResponseHeaders <code>@ResponseHeader</code> HTTP response message header, ServiceComb support attribute value of<code>name</code>, <code>response</code>,<code>responseContainer</code> Consumes string specified data format request body Produces string body in response to the data format specified Protocols string the available protocol (schemes), possible values \u200b\u200bare <code>http</code>,<code>https</code>, <code>ws</code>,<code>wss</code>, separated by commas httpMethod string Set HTTP method hidden boolean Weather to hide this method"},{"location":"build-provider/swagger-annotation/#apiimplicitparam","title":"<code>@ApiImplicitParam</code>","text":"<p>Acts at the method level, which is used to describe the properties of the parameters of the operation in the Swagger document.</p> <p>Note: ServiceComb can automatically infer parameter names based on code and SpringMVC, JAX-RS annotations. If the parameter name of the <code>@ApiImplicitParam</code> configuration is different from the automatically inferred parameter name, then the parameter of the annotation configuration will be added as a new parameter to the operation in which the annotation is located; otherwise, the property of the parameter with the same name will be overwritten.</p> Attribute Type Description name string parameter name value string Parameter Description required boolean Is this a required parameter dataType string Parameter Data Type paramType string parameter location, valid optional value is path/query/body/header/form allowableValues \u200b\u200b string Range of valid values \u200b\u200bfor allowEmptyValue boolean Whether to allow null values \u200b\u200b allowMultiple boolean Whether to allow multiple values \u200b\u200b(if true, parameters can be used as an array) collectionFormat string In which format the parameter array is specified, the current ServiceComb support value is <code>csv/multi</code> defaultValue string parameter default example string Example value for a non-body parameter format string Allows users to customize the data format. See the Swagger official documentation for details."},{"location":"build-provider/swagger-annotation/#apiimplicitparams","title":"<code>@ApiImplicitParams</code>","text":"<p><code>@ApiImplicitParams</code> acts on methods, class levels, and is used to batch specify multiple <code>@ApiImplicitParam</code>.</p> Attribute Type Description value <code>@ApiImplicitParam</code> Parameter definition"},{"location":"build-provider/swagger-annotation/#apiresponse","title":"<code>@ApiResponse</code>","text":"<p>Used to describe the meaning of the HTTP status code of the returned message. Usually <code>@ApiOperation</code> can represent the HTTP status code of a normal return message. In other cases, the HTTP status code is described by this note. According to the Swagger official documentation, this annotation should not be used directly at the method level, but should be included in <code>@ApiResponses</code>.</p> Attribute Type Description code int Return the HTTP status code of the message message string Description of the return value response Class&lt;?&gt; Type of return value responseContainer string The wrapper for the return value, with an optional value of <code>List/Set/Map</code> responseHeaders @ResponseHeader Describes a set of HTTP headers that return messages. The properties of <code>@ResponseHeader</code> supported by ServiceComb are <code>name</code>, <code>description</code>, <code>response</code>, <code>responseContainer</code>"},{"location":"build-provider/swagger-annotation/#apiresponses","title":"<code>@ApiResponses</code>","text":"<p>Acts on methods, class levels, to specify and specify a set of return values.</p> Attribute Type Description value <code>@ApiResponse</code> Return to message description"},{"location":"build-provider/thread-pool/","title":"Thread pool","text":""},{"location":"build-provider/thread-pool/#concept-description","title":"Concept Description","text":"<p>Thread pool is for executing synchronization business logic. net send/receive or reactive business logic executing in eventloop, is independent of the thread pool  </p> <p>By default all synchronization methods are executed in a global built-in thread pool If the business has special requirements, you can specify to use a custom global thread pool, and you can use separate thread pools according to the schemaId or operationId to achieve the effect of the isolated bin.  </p>"},{"location":"build-provider/thread-pool/#customize-thread-pool","title":"Customize thread pool","text":"<ul> <li>Implementing a thread pool   Choose one of the following methods.  </li> <li>Implement the <code>java.util.concurrent.Executor</code> interface      In order to support elegant exit, if the internal thread is not set to the daemon thread, you also need to implement the <code>java.io.Closeable</code> interface, responsible for destroying the thread pool.  </li> <li>Implement the <code>java.util.concurrent.ExecutorService</code> interface  </li> <li>Declare the thread pool of the implementation as a spring bean  </li> <li>Enable thread pool   Suppose the new thread pool spring bean id is custom-executor  </li> <li>Replace the global thread pool     servicecomb.executors.default: custom-executor</li> <li>Specify a thread pool dedicated to the schema       servicecomb.executors.Provider.${schemaId}: custom-executor</li> <li>Specify a thread pool dedicated to the operation       servicecomb.executors.Provider.${schemaId}.${operationId}: custom-executor</li> </ul>"},{"location":"build-provider/thread-pool/#servicecomb-built-in-thread-pool","title":"ServiceComb built-in thread pool","text":"<p>In a general thread pool, all threads share a task queue. In this case, all network threads need to apply for the same queue to join the queue. All threads in the thread pool need to grab the task from the same queue. Throughput scenarios, which can lead to competitive conflicts and create performance bottlenecks Therefore, in order to improve performance, ServiceComb's built-in thread pool is actually a wrapper of real thread pools, allowing multiple sets of thread pools to be configured inside, and each network thread is bound to a set of thread pools to reduce contention conflicts. </p> <ul> <li>Before version 1.2.0  </li> </ul> Configuration default Description servicecomb.executor.default.group 2 Create several sets of thread pools servicecomb.executor.default.thread-per-group CPU count Number of threads per thread pool <ul> <li>Version greater than or equal to 1.2.0</li> </ul> Configuration default Description servicecomb.executor.default.group 2 Create several sets of thread pools servicecomb.executor.default.thread-per-group 100 Maximum number of threads per group of thread poolsDeprecated\uff0cnew name\uff1amaxThreads-per-group servicecomb.executor.default.coreThreads-per-group 25 Minimum number of threads per group of thread poolsThreads are not pre-created, but after they have been created, only threads larger than this value will be destroyed by idle. servicecomb.executor.default.maxThreads-per-group 100 Maximum number of threads per group of thread pools servicecomb.executor.default.maxIdleSecond-per-group 60 Each thread in the thread pool that exceeds coreThreads-per-group will destroy the thread if the idle timeout servicecomb.executor.default.maxQueueSize-per-group Integer.MAX_VALUE Maximum length of the task queue in each group of thread pools"},{"location":"build-provider/transparent-rpc/","title":"Develop Microservice with Transparent RPC","text":""},{"location":"build-provider/transparent-rpc/#concept-description","title":"Concept Description","text":"<p>The transparent remote procedure call(RPC) development mode is a development mode based on API and API implementation. The service developer does not need to use the description of Spring MVC and JAX-RS.</p>"},{"location":"build-provider/transparent-rpc/#development-example","title":"Development Example","text":"<ul> <li>Step 1 Import dependencies into your maven project:</li> </ul> <p><code>xml     &lt;dependencyManagement&gt;      &lt;dependencies&gt;        &lt;dependency&gt;          &lt;groupId&gt;org.apache.servicecomb&lt;/groupId&gt;          &lt;artifactId&gt;java-chassis-dependencies&lt;/artifactId&gt;          &lt;version&gt;1.0.0-m1&lt;/version&gt;          &lt;type&gt;pom&lt;/type&gt;          &lt;scope&gt;import&lt;/scope&gt;        &lt;/dependency&gt;      &lt;/dependencies&gt;     &lt;/dependencyManagement&gt;     &lt;dependencies&gt;       &lt;!--transport can optional import through endpoint setting in microservice.yaml, we import both rest and highway as example--&gt;       &lt;dependency&gt;         &lt;groupId&gt;org.apache.servicecomb&lt;/groupId&gt;         &lt;artifactId&gt;transport-rest-vertx&lt;/artifactId&gt;       &lt;/dependency&gt;       &lt;dependency&gt;         &lt;groupId&gt;org.apache.servicecomb&lt;/groupId&gt;         &lt;artifactId&gt;transport-highway&lt;/artifactId&gt;       &lt;/dependency&gt;       &lt;dependency&gt;         &lt;groupId&gt;org.apache.servicecomb&lt;/groupId&gt;         &lt;artifactId&gt;provider-pojo&lt;/artifactId&gt;       &lt;/dependency&gt;       &lt;dependency&gt;         &lt;groupId&gt;org.slf4j&lt;/groupId&gt;         &lt;artifactId&gt;slf4j-log4j12&lt;/artifactId&gt;       &lt;/dependency&gt;     &lt;/dependencies&gt;</code></p> <ul> <li>Step 2 Define a service API. Compile the Java API definition based on the API definition defined before development. The code is as follows:</li> </ul> <p><code>java    public interface Hello {      String sayHi(String name);      String sayHello(Person person);    }</code></p> <ul> <li>Step 3 implement the service. The implementation of the Hello service is as follows:</li> </ul> <p>```java    import org.apache.servicecomb.samples.common.schema.Hello;    import org.apache.servicecomb.samples.common.schema.models.Person;</p> <p>public class HelloImpl implements Hello {      @Override      public String sayHi(String name) {        return \"Hello \" + name;      }</p> <pre><code> @Override\n public String sayHello(Person person) {\n   return \"Hello person \" + person.getName();\n }\n</code></pre> <p>}    ```</p> <ul> <li>Step 4 Release the service.     The transparent RPC development mode supports two service release mode: Spring XML configuration and Annotation configuration:</li> <li>Spring XML configuration Mode:    Create the pojoHello.bean.xml file in the resources/META-INF/spring directory and declare the schema in the file. The content of the file is as follows:</li> </ul> <p>```xml    </p> <p> <pre><code>   &lt;cse:rpc-schema schema-id=\"pojoHello\" implementation=\"org.apache.servicecomb.samples.pojo.provider.PojoHelloImpl\"/&gt;\n</code></pre> <p>    ```</p> <ol> <li>Annotation configuration Mode:    @RpcSchema is used to define schema during the API Hello implementation. The code is as follows:</li> </ol> <p>```java    import org.apache.servicecomb.provider.pojo.RpcSchema;    @RpcSchema(schemaId = \"pojoHello\")    public class HelloImpl implements Hello {       @Override       public String sayHi(String name) {         return \"Hello \" + name;       }</p> <pre><code>  @Override\n  public String sayHello(Person person) {\n    return \"Hello person \" + person.getName();\n  }\n</code></pre> <p>}    ```</p> <p>In the pojoHello.bean.xml file of resources/META-INF/spring directory, configure base-package that performs scanning. The content of the file is as follows:</p> <p>```xml    </p> <p> <pre><code>   &lt;context:component-scan base-package=\"org.apache.servicecomb.samples.pojo.provider\"/&gt;\n</code></pre> <p>    ```</p> <p>Note: THE PATH FOR RPC IS <code>ClassName/MethodName</code>, AND THE METHOD IS <code>POST</code>.</p> <p>In this sample the Path of sayHi is <code>/HelloImpl/sayHi</code>, and the Path of sayHello is <code>/HelloImpl/sayHello</code>.</p> <p>NOTE\uff1a Different from the Spring MVC and JAX-RS development modes, the transparent RPC development mode used <code>@RpcSchema</code> instead of <code>@RestSchema</code>.</p> <ul> <li>Step 5 Add service definition file:</li> </ul> <p>Add microservice.yaml file into resources folder of your project.</p> <ul> <li>Step 6 Add Main class:</li> </ul> <p>```java    import org.apache.servicecomb.foundation.common.utils.BeanUtils;    import org.apache.servicecomb.foundation.common.utils.Log4jUtils;</p> <p>public class Application {      public static void main(String[] args) throws Exception {         //initializing log, loading bean(including its parameters), and registering service, more detail can be found here : http://servicecomb.incubator.apache.org/users/application-boot-process/         Log4jUtils.init();         BeanUtils.init();      }    }    ```</p>"},{"location":"build-provider/configuration/downgrade-strategy/","title":"Downgrade strategy","text":""},{"location":"build-provider/configuration/downgrade-strategy/#fallback","title":"Fallback","text":""},{"location":"build-provider/configuration/downgrade-strategy/#concepts","title":"Concepts","text":"<p>A fallback policy is applied when a service request is abnormal.</p> <p>There are three key concepts in fallback: isolation, circuit breaking, and fault tolerance:</p> <ul> <li>Isolation is an exception detection mechanism. There are two common \"exception\"s: timeout and overload, which can be controlled by timeout duration and max concurrent requests.</li> <li>Circuit breaking is an exception response mechanism which depends on isolation. Circuit breaking is triggered by the error rate, like the number of bad requests, or the rate of invalid calls.</li> <li>Fault tolerance is an exception handling mechanism that depends on circuit breaking. Fault tolerance is called after a circuit breaking is triggered. Users can set the number of fault tolerance calls in the configuration.</li> </ul> <p>Let's combine the 3 concepts: the isolation mechanism detects there are M(the threshold) errors in N requests, the circuit breaking is triggered and make sure there are no more requests sent, and then fault tolerance method is called. Technically the concept definition is the same with Netflix Hystrix, making it easy to understand the config items(Reference: Hystrix Configuration). ServiceComb provides 2 fault tolerance methods: returning null values and throwing exceptions.</p>"},{"location":"build-provider/configuration/downgrade-strategy/#scenario","title":"Scenario","text":"<p>Users configure a fallback policy to handle microservices' exceptions.</p>"},{"location":"build-provider/configuration/downgrade-strategy/#configuration","title":"Configuration","text":"<p>Configuration items can be set to be applied to all APIs or a particular method of a microservice.</p>"},{"location":"build-provider/configuration/downgrade-strategy/#configuration-scope","title":"Configuration Scope","text":"<ul> <li>Configuration by type: items can be applied to Providers and Consumers</li> <li>Configuration by scope: items can be applied to a specific microservice, or [x-schema-id+operationId]</li> </ul> <p>All the items in this chapter can be configured in the following format:</p> <pre><code>servicecomb.[namespace].[type].[MicroServiceName].[interface name].[property name]\n</code></pre> <p>The type can be Consumer or Provider. Specify the [MicroServiceName] to apply configuration to specific microservice. To make the configuration applied to API, we have to specify the API name in the format x-[schema-id+operationId]</p> <p>The possible Isolation config items are as follows:</p> <pre><code>servicecomb.isolation.Consumer.timeout.enabled\nservicecomb.isolation.Consumer.DemoService.timeout.enabled\nservicecomb.isolation.Consumer.DemoService.hello.sayHello.timeout.enabled\nservicecomb.isolation.Provider.timeout.enabled\nservicecomb.isolation.Provider.DemoService.timeout.enabled\nservicecomb.isolation.Provider.DemoService.hello.sayHello.timeout.enabled\n</code></pre>"},{"location":"build-provider/configuration/downgrade-strategy/#configuration-items","title":"Configuration Items","text":"<p>For Providers, the configuration item should be: servicecomb.isolation.Consumer.timeout.enabled</p> <p>For Consumers, the conriguration item should be servicecomb.isolation.Provider.timeout.enabled</p> <p>Table 1-1 The fallback policy config items</p> Configuration Item Default value Value Range Required Description Tips servicecomb.isolation.[type].timeout.enabled FALSE - No Enable timeout detection or not. servicecomb.isolation.[type].timeoutInMilliseconds 30000 - No The timeout duration threshold. servicecomb.isolation.[type].maxConcurrentRequests 10 - No The maximum number of concurrent requests. servicecomb.circuitBreaker.[type].enabled TRUE - No Enable circuit breaking or not. servicecomb.circuitBreaker.[type].forceOpen FALSE - No Force circuit breaker to be enabled regardless of the number of errors. servicecomb.circuitBreaker.[type].forceClosed FALSE - No Force circuit breaker to be disabled. When forceOpen and forceClose are set at the same time, forceOpen will take effect. servicecomb.circuitBreaker.[type].sleepWindowInMilliseconds 15000 - No How long to recover from a circuit breaking. After the recovery, the number of failures will be reset. Note: If the call fails immediately after a recover, the circuit breaker is triggered immediately again. servicecomb.circuitBreaker.[type].requestVolumeThreshold 20 - No The threshold of failed requests within 10 seconds. If the threshold is reached, circuit breaker is triggered. The 10 seconds duration is splitted evenly into 10 segments for error calculation. The calculation will start after 1 second. So circuit breakers are triggered after at least 1 second. servicecomb.circuitBreaker.[type].errorThresholdPercentage 50 - No The threshold of error rate. If the threshold is reached, circuit breaker is triggered. servicecomb.fallback.[type].maxConcurrentRequests 10 - No The max number of concurrent fallback(specified by servicecomb.fallbackpolicy.policy) calls. When the threshold is reached, the fallback method is not called by return exception directly. servicecomb.fallbackpolicy.[type].policy throwException returnNull | throwException No The fallback policy when errors occurred. <p>Caution: Be cautious to set servicecomb.isolation.timeout.enabled to true. All handlers in the handler chain are asynchronously executed, the intermediate handlers' return will make the follow-up handlers processing abandoned. Therefore, we recommend to set servicecomb.isolation.timeout.enabled to be false(by default) and set the network timeout duration servicecomb.request.timeout to 30000.</p>"},{"location":"build-provider/configuration/downgrade-strategy/#sample-code","title":"Sample Code","text":"<pre><code>servicecomb:\n  handler:\n    chain:\n      Consumer:\n        default: bizkeeper-consumer\n  isolation:\n    Consumer:\n      timeout:\n        enabled: true\n      timeoutInMilliseconds: 30000\n  circuitBreaker:\n    Consumer:\n      sleepWindowInMilliseconds: 15000\n      requestVolumeThreshold: 20\n  fallback:\n    Consumer:\n      enabled: true\n  fallbackpolicy:\n    Consumer:\n      policy: throwException\n</code></pre> <p>NOTE:</p> <p>You need to enable service governance for fallback. The corresponding provider handler  <code>bizkeeper-provider</code>, and the consumer handler is <code>bizkeeper-consumer</code>.</p>"},{"location":"build-provider/configuration/parameter-validator/","title":"Parameter Validation","text":""},{"location":"build-provider/configuration/parameter-validator/#scenario","title":"Scenario","text":"<p>Users can set parameter validation rules in the provider's configuration. The rules will validate input parameters when provider APIs are called, so the parameters can be defined in a specific format.</p>"},{"location":"build-provider/configuration/parameter-validator/#configuration-instructions","title":"Configuration instructions","text":"<ul> <li>Add the pom dependency of swagger-invocation-validator:</li> </ul> <p><code>xml   &lt;dependency&gt;       &lt;groupId&gt;org.apache.servicecomb&lt;/groupId&gt;       &lt;artifactId&gt;swagger-invocation-validator&lt;/artifactId&gt;   &lt;/dependency&gt;</code></p> <ul> <li>Add validator annotations to the code that requires validation by the JSR 349 specification, such as @NotNull, @Min, @Max, etc.</li> </ul>"},{"location":"build-provider/configuration/parameter-validator/#sample-code","title":"Sample Code","text":"<ul> <li>Interface parameter verification</li> </ul> <pre><code>@RestSchema(schemaId = \"validator\")\n@Path(\"/validator\")\n@Produces(MediaType.APPLICATION_JSON)\npublic class Validator {\n\n  @Path(\"/add\")\n  @POST\n  public int add(@FormParam(\"a\") int a, @Min(20) @FormParam(\"b\") int b) {\n    return a + b;\n  }\n\n  @Path(\"/sayhi/{name}\")\n  @PUT\n  public String sayHi(@Length(min = 3) @PathParam(\"name\") String name) {\n    ContextUtils.getInvocationContext().setStatus(202);\n    return name + \" sayhi\";\n  }\n\n  @Path(\"/sayhello\")\n  @POST\n  public Student sayHello(@Valid Student student) {\n    student.setName(\"hello \" + student.getName());\n    student.setAge(student.getAge());\n    return student;\n  }\n}\n</code></pre> <ul> <li>bean class validation</li> </ul> <p>Add @Valid in front of the incoming Student object, like the method sayHello(@Valid Student student) shown above.</p> <pre><code>public class Student {\n  @NotNull\n  private String name;\n\n  @Max(20)\n  private int age;\n\n  public void setName(String name) {\n    this.name = name;\n  }\n\n  public String getName() {\n    return this.name;\n  }\n\n  public void setAge(int age) {\n    this.age = age;\n  }\n\n  public int getAge() {\n    return age;\n  }\n}\n</code></pre>"},{"location":"build-provider/configuration/parameter-validator/#custom-return-exception","title":"Custom return exception","text":"<ul> <li>The default parameter validator ParameterValidator has implemented the interface ProducerInvokeExtension to handle the required parameter validation with the JSR 349 specification.</li> </ul> <p>If any parameter validation fails, the default error is BAD_REQUEST(400, \"Bad Request\").</p> <p>Return error can be customized with the SPI mechanism.</p> <ul> <li>Developer can customize the returned error information by implementing the interface ExceptionToProducerResponseConverter, taking the ConstraintViolationExceptionToProducerResponseConverter as an example.</li> </ul> <p>1. Implement the ExceptionToProducerResponseConverter interface, override the method, the return value of the getOrder method indicates the priority of the validator. The smaller the value, the higher the priority.</p> <pre><code> ```java\n public class ConstraintViolationExceptionToProducerResponseConverter\n     implements ExceptionToProducerResponseConverter&lt;ConstraintViolationException&gt; {\n   @Override\n   public Class&lt;ConstraintViolationException&gt; getExceptionClass() {\n     return ConstraintViolationException.class;\n   }\n\n   @Override\n   public Response convert(SwaggerInvocation swaggerInvocation, ConstraintViolationException e) {\n     return Response.createFail(new InvocationException(Status.BAD_REQUEST, e.getConstraintViolations().toString()));\n   }\n\n   @Override\n   public int getOrder() {\n     return -100;\n   }\n }\n ```\n</code></pre> <ol> <li>Add a file in the services folder under META-INF, with the implemented interface x.x.x.ExceptionToProducerResponseConverter(with package name) as the name, and the implementation class x.x.x.ConstraintViolationExceptionToProducerResponseConverter(with package name) as the content.</li> </ol>"},{"location":"build-provider/configuration/ratelimite-strategy/","title":"Rate Limiting Policy","text":""},{"location":"build-provider/configuration/ratelimite-strategy/#rate-limiting-policy","title":"Rate Limiting Policy","text":""},{"location":"build-provider/configuration/ratelimite-strategy/#scenario","title":"Scenario","text":"<p>Users can set the rate limiting policy in the provider's configuration. By setting the request frequency from a particular micro service, provider can limit the max number of requests per second.</p>"},{"location":"build-provider/configuration/ratelimite-strategy/#cautions","title":"Cautions","text":"<ol> <li>There may be a small difference between the rate limit and actual traffic.</li> <li>The provider's rate limit control is for service rather than security. To prevent distributed denial of service(DDos) attacks, you need to take other measures.</li> <li>Traffic control is scoped to microservice rather than instance. Consume a consumer microservice has 3 instances, and calls a provider service. After configuring the rate limit policy, the provider won't distinguish which consumer instance makes the request, but take all requests together as the 'consume request' for rate limiting.</li> </ol>"},{"location":"build-provider/configuration/ratelimite-strategy/#configuration","title":"Configuration","text":"<p>Rate limiting policies are configured in the microservice.yaml file. The table below shows all the configuration items. To enable the provider's rate limit policy, you also need to configure the rate limiting handler in the server's handler chain and add dependencies in the pom.xml file. </p> <ul> <li>An example of rate limit configuration in microservice.yaml:</li> </ul> <pre><code>servicecomb:\n  handler:\n    chain:\n      Provider:\n        default: qps-flowcontrol-provider\n</code></pre> <ul> <li>Add the handler-flowcontrol-qps dependency in the pom.xml file:</li> </ul> <pre><code>&lt;dependency&gt;\n    &lt;groupId&gt;org.apache.servicecomb&lt;/groupId&gt;\n    &lt;artifactId&gt;handler-flowcontrol-qps&lt;/artifactId&gt;\n    &lt;version&gt;1.0.0-m1&lt;/version&gt;\n&lt;/dependency&gt;\n</code></pre> <p>QPS rate limit configuration items</p> Configuration Item Default Value Value Range Required Description Remarks servicecomb.flowcontrol.Provider.qps.enabled true true/false No Enable provider's traffic control  or not - servicecomb.flowcontrol.Provider.qps.limit.[ServiceName] 2147483647\uff08max int\uff09 (0,2147483647]\uff0cInteger No Specifies the number of requests allowed per second. This parameter can be configured to microservice/schema/operation, the latter has a higher priorty servicecomb.flowcontrol.Provider.qps.global.limit 2147483647\uff08max int\uff09 (0,2147483647]\uff0cInteger No Specifies the provider's total number of requests If no configuration is set for any specific microservice, this parameter takes effect <p>Notes:</p> <p>The <code>ServiceName</code> in provider's rate limit config is the name of the consumer that calls the provider. While <code>schema</code> and <code>operation</code> is the provider's own config item. That is, the rate limit policy controls the consumer requests that  call the provider's schema or operation.</p>"},{"location":"build-provider/definition/heartbeats/","title":"Heartbeats","text":""},{"location":"build-provider/definition/heartbeats/#_1","title":"\u573a\u666f\u63cf\u8ff0","text":"<p>\u5f53\u5fae\u670d\u52a1\u5b9e\u4f8b\u6ce8\u518c\u5230\u670d\u52a1\u4e2d\u5fc3\u540e\uff0c\u5fae\u670d\u52a1\u9700\u8981\u5b9a\u65f6\u5411\u670d\u52a1\u4e2d\u5fc3\u53d1\u9001\u5fc3\u8df3\u3002\u82e5\u670d\u52a1\u4e2d\u5fc3\u5728\u4e00\u5b9a\u65f6\u95f4\u5185\u6ca1\u6709\u6536\u5230\u5fc3\u8df3\u4fe1\u606f\uff0c\u5219\u4f1a\u6ce8\u9500\u6b64\u5b9e\u4f8b\u3002</p>"},{"location":"build-provider/definition/heartbeats/#api","title":"\u6d89\u53caAPI","text":"<ul> <li><code>org.apache.servicecomb.serviceregistry.client.ServiceRegistryClient</code>\uff1a\u670d\u52a1\u4e2d\u5fc3\u5ba2\u6237\u7aef</li> </ul>"},{"location":"build-provider/definition/heartbeats/#_2","title":"\u914d\u7f6e\u8bf4\u660e","text":"<p><code>ServiceRegistryClient</code>\u63d0\u4f9b\u4e86\u53d1\u9001\u5fc3\u8df3\u7684\u65b9\u6cd5<code>heartbeat</code>\uff0c\u7528\u6237\u76f4\u63a5\u8c03\u7528\u5373\u53ef\uff0c\u793a\u4f8b\u4ee3\u7801\u5982\u4e0b\uff1a</p> <pre><code>public static void main(String[] args) throws Exception {\n    // \u9996\u5148\u9700\u8981\u6ce8\u518c\u5fae\u670d\u52a1\u548c\u5b9e\u4f8b\u2026\u2026\n    // \u53d1\u9001\u5fc3\u8df3\uff0c\u4e0d\u7136\u5b9e\u4f8b\u4f1a\u6d88\u5931\n    while (true) {\n        System.out.println(\"heartbeat sended:\" + client.heartbeat(service2.getServiceId(), instance.getInstanceId()));\n        Thread.sleep(3000);\n    }\n}\n</code></pre>"},{"location":"build-provider/definition/isolate-relationship/","title":"Isolate relationship","text":""},{"location":"build-provider/definition/isolate-relationship/#_1","title":"\u573a\u666f\u63cf\u8ff0","text":"<p>\u8fdb\u884c\u670d\u52a1\u53d1\u73b0\u7684\u65f6\u5019\uff0c\u5f00\u53d1\u8005\u9700\u8981\u4e86\u89e3\u672c\u5fae\u670d\u52a1\u80fd\u591f\u53d1\u73b0\u90a3\u4e9b\u5176\u4ed6\u670d\u52a1\u7684\u5b9e\u4f8b\u3002ServiceComb\u63d0\u4f9b\u4e86\u5206\u5c42\u6b21\u7684\u5b9e\u4f8b\u9694\u79bb\u3002</p>"},{"location":"build-provider/definition/isolate-relationship/#_2","title":"\u5fae\u670d\u52a1\u5b9e\u4f8b\u5206\u5c42\u7ba1\u7406","text":"<p>\u8981\u4e86\u89e3\u5b9e\u4f8b\u95f4\u7684\u9694\u79bb\u5c42\u6b21\uff0c\u9996\u5148\u9700\u8981\u4e86\u89e3ServiceComb\u5b9a\u4e49\u7684\u4e00\u4e2a\u4f53\u7cfb\u5b8c\u5907\u7684\u5fae\u670d\u52a1\u7cfb\u7edf\u7ed3\u6784\uff1a</p> <p></p> <p>\u5728\u5fae\u670d\u52a1\u7cfb\u7edf\u7ed3\u6784\u4e2d\uff0c\u9876\u5c42\u662f\u201c\u9879\u76ee\u201d\uff0c\u5728\u9879\u76ee\u4e0b\u5206\u4e3a\u591a\u4e2a\u79df\u6237\uff0c\u79df\u6237\u4e2d\u5305\u542b\u591a\u4e2a\u5e94\u7528\uff0c\u800c\u6bcf\u4e2a\u5e94\u7528\u7531\u5305\u542b\u591a\u4e2a\u73af\u5883\uff0c\u5373\u6d4b\u8bd5\u548c\u751f\u4ea7\u73af\u5883\u53ef\u4ee5\u5206\u5f00\u3002\u5728\u67d0\u4e2a\u7279\u5b9a\u5e94\u7528\u7684\u7279\u5b9a\u73af\u5883\u4e2d\uff0c\u5305\u542b\u591a\u4e2a\u5fae\u670d\u52a1\uff0c\u800c\u4e00\u4e2a\u5fae\u670d\u52a1\u53c8\u53ef\u4ee5\u540c\u65f6\u5b58\u5728\u591a\u4e2a\u7248\u672c\u3002\u4ee5\u4e0a\uff0c\u662f\u6240\u6709\u9759\u6001\u5143\u6570\u636e\u7684\u8303\u7574\uff0c\u67d0\u4e2a\u7279\u5b9a\u670d\u52a1\u7684\u7279\u5b9a\u7248\u672c\u5219\u5305\u542b\u591a\u4e2a\u5728\u8fd0\u884c\u65f6\u6ce8\u518c\u4e0a\u6765\u7684\u5fae\u670d\u52a1\u5b9e\u4f8b\uff0c\u56e0\u4e3a\u670d\u52a1\u5b9e\u4f8b\u7684\u4fe1\u606f\u5728\u8fd0\u884c\u65f6\u968f\u7740\u7cfb\u7edf\u7684\u4f38\u7f29\u3001\u6545\u969c\u7b49\u539f\u56e0\u662f\u52a8\u6001\u53d8\u5316\u7684\uff0c\u6240\u4ee5\u670d\u52a1\u5b9e\u4f8b\u7684\u8def\u7531\u4fe1\u606f\u53c8\u4e3a\u52a8\u6001\u6570\u636e\u3002\u901a\u8fc7\u5206\u5c42\u7ba1\u7406\u5fae\u670d\u52a1\u7684\u8fd9\u4e9b\u6570\u636e\uff0c\u4e5f\u5c31\u81ea\u7136\u800c\u7136\u7684\u5b9e\u73b0\u4e86\u5b9e\u4f8b\u4e4b\u95f4\u7684\u903b\u8f91\u9694\u79bb\u3002</p>"},{"location":"build-provider/definition/isolate-relationship/#_3","title":"\u9694\u79bb\u5c42\u6b21\u8bf4\u660e","text":"<p>ServiceComb\u652f\u6301\u81ea\u5b9a\u4e49\u5206\u5c42\u914d\u7f6e\uff0c\u6ee1\u8db3\u7528\u6237\u7684\u5b9e\u4f8b\u5206\u5c42\u7ba1\u7406\u9700\u6c42\uff0c\u4ee5\u4e0b\u662f\u5177\u4f53\u914d\u7f6e\u8bf4\u660e\u3002</p> <ul> <li>\u5e94\u7528ID</li> </ul> <p>\u901a\u8fc7APPLICATIOIN_ID\u6765\u5b9a\u4e49\uff0c\u7f3a\u7701\u503c\u4e3adefault\u3002\u5fae\u670d\u52a1\u5728\u53d1\u73b0\u5b9e\u4f8b\u7684\u65f6\u5019\uff0c\u7f3a\u7701\u53ea\u80fd\u591f\u88ab\u76f8\u540cAPPLICATIOIN_ID\u4e0b\u7684\u6d88\u8d39\u8005\u53d1\u73b0\u3002</p> <ul> <li>Domain\u540d\u79f0</li> </ul> <p>\u901a\u8fc7cse.config.client.domainName\u6765\u5b9a\u4e49\uff0c\u7f3a\u7701\u503c\u4e3adefault\u3002\u4f5c\u4e3a\u5fae\u670d\u52a1\u63d0\u4f9b\u8005\uff0c\u7528\u4e8e\u8868\u660e\u81ea\u8eab\u6240\u5c5e\u79df\u6237\u4fe1\u606f\u3002\u5fae\u670d\u52a1\u5728\u53d1\u73b0\u5b9e\u4f8b\u7684\u65f6\u5019\uff0c\u53ea\u80fd\u88ab\u76f8\u540c\u79df\u6237\u4e0b\u7684\u6d88\u8d39\u8005\u53d1\u73b0\u3002</p> <ul> <li>\u6570\u636e\u4e2d\u5fc3\u4fe1\u606f</li> </ul> <p>\u6570\u636e\u4e2d\u5fc3\u5305\u62ec3\u4e2a\u5c5e\u6027\uff1acse.datacenter.name\uff0c cse.datacenter.region, cse.datacenter.availableZone\u3002\u6570\u636e\u4e2d\u5fc3\u4fe1\u606f\u4e0d\u63d0\u4f9b\u9694\u79bb\u80fd\u529b\uff0c\u5fae\u670d\u52a1\u53ef\u4ee5\u53d1\u73b0\u5176\u4ed6\u6570\u636e\u4e2d\u5fc3\u7684\u5b9e\u4f8b\u3002\u4f46\u662f\u53ef\u4ee5\u901a\u8fc7\u542f\u7528\u5b9e\u4f8b\u4eb2\u548c\u6027\uff0c\u6765\u4f18\u5148\u5f80\u6307\u5b9a\u7684\u533a\u57df\u6216\u8005Zone\u53d1\u6d88\u606f\uff1a</p> <pre><code>cse:\n  loadbalance:\n    serverListFilters: zoneaware\n    serverListFilter:\n      zoneaware:\n        className: org.apache.servicecomb.loadbalance.filter.ZoneAwareServerListFilterExt\n</code></pre> <p>\u8fd9\u6837\u914d\u7f6e\u540e\uff0c\u5ba2\u6237\u7aef\u5728\u8def\u7531\u7684\u65f6\u5019\uff0c\u4f1a\u4f18\u5148\u5c06\u8bf7\u6c42\u8f6c\u53d1\u5230zone/region\u90fd\u76f8\u540c\u7684\u5b9e\u4f8b\uff0c\u7136\u540e\u662fregion\u76f8\u540c\uff0c\u4f46zone\u4e0d\u76f8\u540c\u7684\u5b9e\u4f8b\uff0c\u90fd\u4e0d\u76f8\u540c\u7684\u65f6\u5019\uff0c\u5219\u6309\u7167\u8def\u7531\u89c4\u5219\u9009\u62e9\u4e00\u4e2a\u3002\u4eb2\u548c\u6027\u4e0d\u662f\u903b\u8f91\u9694\u79bb\uff0c\u53ea\u8981\u5b9e\u4f8b\u4e4b\u95f4\u7f51\u7edc\u662f\u8054\u901a\u7684\uff0c\u90a3\u4e48\u90fd\u6709\u53ef\u80fd\u8bbf\u95ee\u5230\uff1b\u5982\u679c\u7f51\u7edc\u4e0d\u901a\uff0c\u5219\u4f1a\u8bbf\u95ee\u5931\u8d25\u3002</p> <ul> <li>\u73af\u5883\u4fe1\u606f</li> </ul> <p>\u5728yaml\u6587\u4ef6\u91cc\u901a\u8fc7service_description.environment\u6765\u914d\u7f6e\uff0c\u540c\u65f6\u652f\u6301\u901a\u8fc7\u73af\u5883\u53d8\u91cfSERVICECOMB_ENV\u914d\u7f6e\uff0c\u4ec5\u652f\u6301\u4ee5\u4e0b\u679a\u4e3e\u503c development,testing,acceptance,production\uff0c\u7f3a\u7701\u503c\u4e3a\"\"(\u7a7a)\u3002\u5fae\u670d\u52a1\u5728\u53d1\u73b0\u5b9e\u4f8b\u7684\u65f6\u5019\uff0c\u7f3a\u7701\u53ea\u80fd\u591f\u88ab\u76f8\u540cenvironment\u4e0b\u7684\u6d88\u8d39\u8005\u53d1\u73b0\u3002</p> <pre><code>service_description:\n  environment: production\n</code></pre>"},{"location":"build-provider/definition/isolate-relationship/#_4","title":"\u4e0e\u534e\u4e3a\u516c\u6709\u4e91\u6982\u5ff5\u7684\u5bf9\u5e94\u5173\u7cfb","text":"<p>\u534e\u4e3a\u516c\u6709\u4e91\u6709\u7c7b\u4f3c\u7684\u6982\u5ff5\uff0c\u5e94\u7528\u3001\u79df\u6237\u3001Project\u3001Cluster\u7b49\uff0c\u5728\u5b9e\u9645\u5e94\u7528\u7684\u65f6\u5019\uff0c\u53ef\u4ee5\u5206\u522b\u5bf9\u5e94\u5230ServiceComb\u7684\u5e94\u7528\u3001\u79df\u6237\u3001Domain\u3001Zone\u7b49\u4fe1\u606f\u3002\u6bd4\u5982\u5728\u516c\u6709\u4e91\u4e0a\u5982\u679cCluster\u5171\u4eabProject\uff0c\u90a3\u4e48\u5c31\u53ef\u4ee5\u901a\u8fc7zone\u6765\u5bf9\u5e94Cluster\uff0c\u5b9e\u73b0\u96c6\u7fa4\u4e4b\u95f4\u7684\u4eb2\u548c\u6027\u8bbf\u95ee\u3002</p>"},{"location":"build-provider/definition/service-definition/","title":"Service Definition","text":""},{"location":"build-provider/definition/service-definition/#concept-description","title":"Concept Description","text":"<p>A service definition identifies a microservice. It defines the service name, version, and the application that the service belongs to. The service definition can also contain extended information defining the attribute metadata of a service.</p>"},{"location":"build-provider/definition/service-definition/#scenario","title":"Scenario","text":"<p>To define a new microservice or modify its basic information, you may need to create and modify service definitions.</p>"},{"location":"build-provider/definition/service-definition/#configuration","title":"Configuration","text":"<p>This section describe the following configration items related to the microservice.yaml file in the src\\main\\resources\\ directory.</p> Configuration on Item Default Range Mandatory Description Remarks APPLICATION_ID - - Yes Indicates an application name. - service_description.name - - Yes Indicates a microservice name The microservice name should be unique within an application. The name can contain digits, uppercase and lowercase letters, hyphens(-), underscores(_), and periods(.); and can neither start nor end with punctuations. The naming rule is as follows: ^[a-zA-Z0-9]+$|^[a-zA-Z0-9][a-zA-Z0-9_-.]*[a-zA-Z0-9]$. service_description.version - - Yes Indicates a service version. - service_description.properties - - No Configures microservice metadata(in the microservice.yaml file). - service_description.propertyExtendedClass - - No Configures microservice metadata(through the PropertyExtended API). The configurations returned through the API will overwrite those with the same keys in the configuration file. instance_description.properties - - No Configures instance metadata(in the microservice.yaml file) instance_description.propertyExtendedClass - - No Configures microservice metadata(through the PropertyExtended API). The configurations returned through the API will overwrite thos with the same keys in the configuration file. <p>NOTE\uff1a - The metadata of a service is registered to the service center with the service. It is changed together with the service version. Changing metadata in the service center will keep the version unchanged. - By default, one microservice can be called by only one APPLICATION_ID. You can set allowCrossApp=true in microservice properties to access a microservice acroos APPLICATION_ID.</p>"},{"location":"build-provider/definition/service-definition/#sample-code","title":"Sample Code","text":"<pre><code>APPLICATION_ID: helloTest #Application name\nservice_description: #Service description\n  name: helloServer #Microservice name\n  version: 0.0.1 #Service version\n  properties: #Metadata\n \u00a0 \u00a0allowCrossApp: false\n \u00a0 \u00a0key1: value1\n    key2: value2\n  propertyExtendedClass: org.apache.servicecomb.serviceregistry.MicroServicePropertyExtendedStub\ninstance_description: #Instance description\n  properties: #Metadata\n    key3: value3\n  propertyExtendedClass: org.apache.servicecomb.serviceregistry.MicroServicePropertyExtendedStub\n</code></pre>"},{"location":"catalog/build-consumer/","title":"Build consumer","text":""},{"location":"catalog/build-consumer/#develop-consumer-with-rest-template","title":"Develop consumer with Rest Template","text":"<p>RestTemplate is a RESTful API provided by the Spring framework.  ServiceComb provides the implementation class for service calling</p>"},{"location":"catalog/build-consumer/#develop-consumer-with-asyncresttemplate","title":"Develop consumer with AsyncRestTemplate","text":"<p>AsyncRestTemplate allows users to make asynchronous service calls. The logic is similar to restTemplate, except that the service is called asynchronously.</p>"},{"location":"catalog/build-consumer/#develop-consumer-with-transparent-rpc","title":"Develop consumer with transparent RPC","text":"<p>The transparent RPC allows users to make service calls like a local call through a simple java interface.</p>"},{"location":"catalog/build-consumer/#using-contracts","title":"Using Contracts","text":"<p>When a consumer calls a service from a provider, the contract is required. The consumer can get the providers' contracts in 2 ways: get the providers' contract from off-line, then manually configure it in the  project. Or, download the contract from the service center.</p>"},{"location":"catalog/build-consumer/#call-control","title":"Call Control","text":""},{"location":"catalog/build-consumer/#instance-level-fault-isolation","title":"Instance level fault isolation","text":"<p>The instance-level fault isolation feature introduces the ability to isolate failed service instances by stopping sending request to them.</p>"},{"location":"catalog/build-consumer/#fallback-strategy","title":"Fallback strategy","text":"<p>The fallback strategy allows user to specify the conditions under which the ServiceComb framework will terminate the requests.</p>"},{"location":"catalog/build-consumer/#rate-limiting-strategy","title":"Rate limiting strategy","text":"<p>The user uses the rate limiting policy on the consumer side to control the frequency of requests sent to the specified microservice.</p>"},{"location":"catalog/build-consumer/#fault-injection","title":"Fault injection","text":"<p>The user uses fault injection on the consumer side to set the delay and error of the request sent to the specified microservice and its trigger probability.</p>"},{"location":"catalog/build-provider/","title":"Build provider","text":""},{"location":"catalog/build-provider/#service-definition","title":"Service Definition","text":"<p>\u2022 Service definition information is the identity of the microservice, which defines which application the service belongs to, as well as the name and version. The service definition information may also have extension information for defining attribute metadata of the service. \u00a0</p>"},{"location":"catalog/build-provider/#defining-service-contracts","title":"Defining Service Contracts","text":"<p>\u2022 Service contract, which refers to the micro-service interface contract based on the OpenAPI specification, which is the definition of the interface between the server and the consumer. The java chassis provides two ways to define contracts: code first and contract first.</p>"},{"location":"catalog/build-provider/#use-implicit-contract","title":"Use implicit contract","text":"<p>\u2022 The downgrade strategy is the exception handling strategy used by the microservice when the service request is abnormal.</p>"},{"location":"catalog/build-provider/#using-swagger-annotations","title":"Using Swagger Annotations","text":"<p>\u2022 Swagger provides a set of annotations to describe the interface contract. Users can use annotations to add descriptions of contracts to the code. ServiceComb supports some of these annotations.</p>"},{"location":"catalog/build-provider/#developing-microservices-with-springmvc","title":"Developing microservices with SpringMVC","text":"<p>\u2022 ServiceComb supports SpringMVC annotations, allowing the development of microservices using SpringMVC style. It is recommended to read the project in detail with reference to the project SpringMVC.</p>"},{"location":"catalog/build-provider/#developing-microservices-with-jax-rs","title":"Developing microservices with JAX-RS","text":"<p>\u2022 ServiceComb supports developers using JAX-RS annotations to develop services using JAX-RS patterns.</p>"},{"location":"catalog/build-provider/#developing-microservices-with-transparent-rpc","title":"Developing microservices with transparent RPC","text":"<p>\u2022 The transparent RPC development model is a development model based on interfaces and interfaces. Service developers do not need to use Spring MVC and JAX-RS annotations.</p>"},{"location":"catalog/build-provider/#interface-definition-and-data-type","title":"interface definition and data type","text":"<p>\u2022 ServiceComb-Java-Chassis suggests that the interface definition follows a simple principle: the interface definition is the interface usage specification, and you can identify how to call this interface without looking at the code implementation. It can be seen that this principle stands on the user side and is easier to use as a reference. ServiceComb will generate interface contracts based on interface definitions, interfaces that conform to this principle, and the generated contracts are also easy for users to read.</p>"},{"location":"catalog/build-provider/#service-listening-address-and-publishing-address","title":"Service Listening Address and Publishing Address","text":"<p>\u2022 In JavaChassis, the listening and publishing addresses of the service are two separate concepts that can be configured independently:</p> <p>Listening address: refers to the address that the microservice instance listens to when it starts. This configuration item determines which IPs can be accessed by this IP. Publish address: refers to the address where the microservice instance is registered to the service center. Other microservice instances will obtain information about this instance through the service center and access the service instance based on the publication address, so this configuration item determines which IP other services actually use to access the service.</p>"},{"location":"catalog/build-provider/#service-configuration","title":"Service Configuration","text":"<p>\u2022 Load Balancing Policy \u2022 Limiting Policy \u2022 Parameters and Research</p>"},{"location":"catalog/config/","title":"Config","text":""},{"location":"catalog/config/#general-configuration-instructions","title":"General configuration instructions","text":"<p>Introduce the configuration hierarchy relationship and the usage of the configuration mechanism of ServiceComb-Java-Chassis.</p>"},{"location":"catalog/general-develop/","title":"General develop","text":""},{"location":"catalog/general-develop/#access-service-center","title":"Access Service Center","text":"<p>The system realizes the discovery between services through the service center. During the service startup process, the service center is registered. When calling other services, the service center will query the instance information of other services, such as the access address, the protocol used, and other parameters. The service center supports the use of PULL and PUSH modes to notify instance changes.</p>"},{"location":"catalog/general-develop/#application-performance-monitoring","title":"Application Performance Monitoring","text":"<p>1. The introduction of Metrics \u00a02. The summary of statistical items \u00a03. The usage</p>"},{"location":"catalog/general-develop/#micro-service-call-chain","title":"Micro Service Call Chain","text":"<p>The microservices architecture solves the problems of many single applications, but it also requires us to pay extra. Request processing latency due to network instability is one of the costs.</p> <p>In a single application, all modules run in the same process, so there is no inter-module interworking problem. However, in the micro-service architecture, services communicate through the network, so we have to deal with network-related issues such as delays, timeouts, network partitions, and so on.</p> <p>In addition, as the business expands its services, it is difficult to see how data flows through a spider-like complex service structure. How can we effectively monitor network latency and visualize data flow in services?</p> <p>Distributed call chain tracking is used to effectively monitor network latency for microservices and visualize data flow in microservices.</p>"},{"location":"catalog/general-develop/#custom-call-chain-management","title":"Custom call chain management","text":"<p>Distributed call chain tracking provides timing information for calls between services, but the link call information inside the service is equally important to the developer. If you can combine the two into one, you can provide a more complete call chain, which is easier to locate. Errors and potential performance issues. \u00a0\u00a0</p>"},{"location":"catalog/general-develop/#local-development-and-testing","title":"Local development and testing","text":"<p>This section describes how to develop and debug consumer/provider applications locally on the developer side. For development service providers, please refer to the section 3 Development Service Providers. For development service consumers, please refer to 4 Development Service Consumers. Both the service provider and the consumer provider need to connect to the remote service center. For the development and debugging of local microservices, this section describes two ways to set up a local service center for local microservices debugging:</p>"},{"location":"catalog/general-develop/#http-filter","title":"Http Filter","text":"<p>In some scenarios, the service uses http instead of https as the network transmission channel. In order to prevent the falsification or tampering request, the signature function of the http code stream between the consumer and the producer needs to be provided.</p>"},{"location":"catalog/general-develop/#file-upload","title":"File Upload","text":"<p>File upload, currently supported in vertx rest channel and servlet rest. File uploads use the standard http form format, which interfaces directly with the browser's upload.</p>"},{"location":"catalog/general-develop/#download-document","title":"Download Document","text":"<p>File downloads are currently available in the vertx rest channel and servlet rest.</p>"},{"location":"catalog/general-develop/#reactive","title":"Reactive","text":"<p>Comparison and description between simple synchronization mode, nested synchronous call, pure Reactive mechanism, and hybrid Reactive mechanism.</p>"},{"location":"catalog/general-develop/#dns-custom-configuration","title":"DNS Custom Configuration","text":"<p>When a user uses a domain name to connect to a Huawei public cloud or a three-party system, you need to use the domain name resolution system. The domain name resolution mechanisms used in different systems and different frameworks may be different. Therefore, it is necessary to provide a unified configuration entry so that development and operation personnel can customize the DNS resolution mechanism without being completely subject to system configuration.</p>"},{"location":"catalog/general-develop/#proxy-settings","title":"Proxy settings","text":"<p>As a developer, in a company development environment, it is possible to access the Internet through a corporate agent network. If you must also rely on online resources when debugging services, such as directly connecting to Huawei's shared cloud service center, you must configure the agent.</p>"},{"location":"catalog/general-develop/#frame-report-version-number","title":"Frame report version number","text":"<p>In order to facilitate the management, using ServiceComb for development, the currently used ServiceComb version number will be reported to the service center, and the version number of other frameworks will be reported when other frameworks integrate ServiceComb.</p>"},{"location":"catalog/general-develop/#cross-application-call","title":"Cross-application call","text":"<p>An application is a layer in the microservice instance isolation hierarchy, and an application contains multiple microservices. By default, only microservice instances of the same application are allowed to call each other.</p>"},{"location":"catalog/general-develop/#custom-serialization-and-deserialization-methods","title":"Custom Serialization and Deserialization Methods","text":"<p>Due to the non-security of the HTTP protocol, data transmitted over the network can be easily monitored by various packet capture tools. In practical applications, services have high security requirements for sensitive data transmitted between applications or services. Such data requires special encryption protection (different services have different algorithm requirements), so that even if the content is intercepted, it can protect Sensitive data is not easily obtained.</p>"},{"location":"catalog/general-develop/#using-context-to-pass-control-messages","title":"Using Context to pass control messages","text":"<p>ServiceComb provides a Context to pass data between microservices. Context is a key/value pair and can only use data of type String. Since the Context is serialized into the json format and passed through the HTTP header, characters other than ASCII are not supported. Other characters require the developer to encode and pass the code. The Context is passed on the request chain in a single request and does not need to be reset. Functions such as the trace id of the access log are implemented based on this feature.</p>"},{"location":"catalog/general-develop/#return-value-serialization-extension","title":"return value serialization extension","text":"<p>The current REST channel return value supports both application/json and text/plain formats, supports developer extensions and rewrites, service providers provide serialization capabilities through producer declarations, and service consumers specify return value serialization through the request's Accept header. By default, the data in application/json format is returned.</p>"},{"location":"catalog/general-develop/#cors-mechanism","title":"CORS mechanism","text":"<p>Cross-Origin Resource Sharing (CORS) allows Web servers to perform cross-domain access control, enabling browsers to more securely transfer data across domains.</p>"},{"location":"catalog/general-develop/#obtaining-the-fuse-and-instance-isolation-alarm-event-information","title":"Obtaining the fuse and instance isolation alarm event information","text":"<p>When the microservice is running or the instance isolation status changes, you need to listen to related events, get relevant information and process it.</p>"},{"location":"catalog/security/","title":"Security","text":""},{"location":"catalog/security/#using-tls-communication","title":"Using TLS communication","text":"<p>Users can enable TLS communication through simple configuration to ensure data transmission security.</p>"},{"location":"catalog/security/#use-rsa-certification","title":"Use RSA certification","text":"<p>Users can enable RSA authentication between services through simple configuration to ensure the security of the service interface. Detailed reference to public key authentication</p>"},{"location":"catalog/service-package-run/","title":"Service package run","text":""},{"location":"catalog/service-package-run/#packaged-in-standalone-mode","title":"Packaged in standalone mode","text":"<p>A Standalone container that loads Spring with a simple Main method, because the service usually does not require the properties of a Web container such as Tomcat/JBoss, and there is no need to use the Web container to load the service. The microframework provides a standalone deployment run mode. The service container is just a simple Main method and loads a simple Spring container to expose the service.</p>"},{"location":"catalog/service-package-run/#packaged-in-web-container-mode","title":"Packaged in WEB container mode","text":"<p>If you need to load the microservice into the web container to start the runtime, you need to create a new servlet project wrapper. The servlet project, if necessary, can not write or write a small amount of boot code.</p>"},{"location":"catalog/start/","title":"Start","text":""},{"location":"catalog/start/#glossary","title":"Glossary","text":""},{"location":"catalog/start/#micro-service-system-architecture","title":"Micro Service System Architecture","text":""},{"location":"catalog/start/#install-local-development-environment","title":"Install local development environment","text":"<p>\u2022 Service definition information is the identity of the microservice, which defines which application the service belongs to, as well as the name and version. The service definition information may also have extensive information for defining attribute metadata of the service. \u00a0</p>"},{"location":"catalog/start/#developing-the-first-microservice","title":"Developing the first microservice","text":"<p>Developers can quickly build a project in two ways:</p> <p>\u2022 Download the samples project. It is recommended to download the entire project and initialize it according to the example SpringMVC or JAX RS. \u2022 Generate projects with archetypes</p>"},{"location":"config/general-config/","title":"General configuration instructions","text":""},{"location":"config/general-config/#configuration-source-hierarchical-relationship","title":"Configuration source hierarchical relationship","text":"<p>ServiceComb provides a hierarchical configuration mechanism. According to the priority, it is divided as below(the former is higher):</p> <ul> <li>Configuration Center (dynamic configuration)</li> <li>Java System Property (-D parameter)</li> <li>Environmental variables</li> <li>Configuration file</li> </ul>"},{"location":"config/general-config/#configuration-file","title":"Configuration file","text":"<p>The configuration file is the microservice.yaml file on classpath by default. When the ServiceComb-Java-Chassis is booting up, the microservice.yaml files are loaded from the jar files and the directories on the hard disks. All of the configuration files are merged into a set of valid configurations. The configuration files on the hard disks has higher priority than those in the jar files. The priority can also be specified by the <code>servicecomb-config-order</code> item in the configuration files.</p> <p>Tips: Since the microservice.yaml file on the hard disk has a higher priority, the <code>.</code> directory can be added into the classpath of the executable jar package, so that a microservice.yaml file can be placed in the directory where the service jar package is located, to overwrite the configuration files in the jar package.</p> <p>The default name of the configuration files is \"microservice.yaml\". The additional configuration files can be added by specifying Java System Property, and the name of the configuration files can be changed in this way, too:</p> Java System Property Variable Name Description servicecomb.configurationSource.additionalUrls List of configuration files, multiple full file names can be specified with the ',' as separator servicecomb.configurationSource.defaultFileName Default configuration file name"},{"location":"config/general-config/#environmental-variables","title":"Environmental variables","text":"<p>On Linux, the <code>.</code> charactor cannot be contained into environment variable name. As a result, some configuration items cannot be specified into environment variables directly. As a solution, the <code>.</code> charactor can be replaced by <code>_</code>, and the converted configuration item can be specified as environment variable. ServiceComb-Java-Chassis can map those converted configuration items to the original configuration items.</p> <p>For example, for the configration in microservice.yaml file:</p> <pre><code>servicecomb:\n  rest:\n    address: 0.0.0.0:8080\n</code></pre> <p>We can specify <code>servicecomb_rest_address=0.0.0.0:9090</code> in the environment variable to overwrite the server port as 9090. This mapping mechanism can also applied to other configuration levels.</p>"},{"location":"config/general-config/#configuration-center-dynamic-configuration","title":"Configuration Center (dynamic configuration)","text":"<p>The default implementation of the dynamic configuration is the config-cc client, which is connected to the configuration center. The configuration items are as follows:</p> Variable Description servicecomb.config.client.refreshMode Application configuration refresh mode, <code>0</code> is config-center active push, <code>1</code> is client cycle pull, default is <code>0</code> servicecomb.config.client.refreshPort config-center push configured port servicecomb.config.client.tenantName Application tenant name servicecomb.config.client.serverUri config-center access address, the format is <code>http(s)://{ip}:{port}</code>, to separate multiple addresses with comma (optional, when cse.config.client.regUri is configured as This configuration item will take effect when empty)) servicecomb.config.client.refresh_interval the configuration refresh interval, the unit is millisecond, default value is 15000"},{"location":"config/general-config/#get-configuration-information-in-the-program","title":"Get configuration information in the program","text":"<p>Developers use a consistent API to get the configuration, regardless of the configured storage path:</p> <pre><code>DynamicDoubleProperty myprop = DynamicPropertyFactory.getInstance().getDoubleProperty(\"trace.handler.sampler.percent\", 0.1);\n</code></pre> <p>The instance above shows a configuration item whose key is <code>trace.handler.sampler.percent</code>, with default value 0.1. Developers can specify the value of this item in the microservice.yaml file, environment variable, Java System Property or Configuration center. There is no need for the developers to consider where to get the configuration values, Java-Chassis will load the configurations from everywhere, and merge them into one set of configurations according to the priority rule mentioned above.</p> <p>For details, please refer to [API DOC] (https://netflix.github.io/archaius/archaius-core-javadoc/com/netflix/config/DynamicPropertyFactory.html)</p> <p>You can register for a callback to handle configuration changes:</p> <pre><code> myprop.addCallback(new Runnable() {\n      public void run() {\n        // this method is invoked when the value of this configuration item is modified\n        System.out.println(\"trace.handler.sampler.percent is changed!\");\n      }\n  });\n</code></pre>"},{"location":"config/general-config/#performing-configuration-item-mapping","title":"Performing configuration item mapping","text":"<p>In some cases, we want to block the configuration of some of the open source components we use and provide our users with their own configuration items. In this case, you can define the mapping through mapping.yaml under the classpath:</p> <pre><code>registry:\n  client:\n    serviceUrl:\n      defaultZone: eureka.client.serviceUrl.defaultZone\n</code></pre> <p>After the mapping is defined, the framework maps by default when the configuration is loaded, and the configuration items defined by us are mapped to the configuration items that the open source component can recognize.</p>"},{"location":"config/inject-config/","title":"Configuration injection","text":"<p>ServiceComb provides the ability to inject configuration attributes into Java object fields and wildcard support.</p> <p>A Java object can be a Java Bean or a class with a public field.</p>"},{"location":"config/inject-config/#configure-injection-objects","title":"Configure injection objects","text":"<p>We first design two Java classes to inject configuration attributes to demonstrate scenarios where annotations are not used and where annotations are used.</p> <pre><code>/*\nUse ServiceComb annotations\n*/\n@InjectProperties(prefix = \"root\") //Specify the prefix of the configuration attribute associated with the model\npublic class ConfigWithAnnotation {\n\n  /*\n  The prefix attribute value \"override\" here overrides the prefix attribute value \"root\" labeled in the @InjectProperties annotation of the class definition. The keys attribute can be an array of strings and the lower the subscript of the array element, the higher the priority.\n\n  Configuration attributes are searched by the attribute names in the following order until the configuration attributes that have been configured are found, then the search is stopped:\n    1)override.high\n  2)override.low\n    */\n  @InjectProperty(prefix = \"override\", keys = {\"high\", \"low\"})\n  public String strValue;\n\n  //Keys support wildcards and specify wildcards'input objects when configuration attributes are injected.\n  @InjectProperty(keys = \"${key}.value\")\n  public int intValue;\n\n    //The wildcard's surrogate object can be a list of strings. Priority follows the strategy that the lower the subscript of array elements, the higher the priority.\n    @InjectProperty(keys = \"${full-list}\")\n  public float floatValue;\n\n  //The keys attribute also supports multiple wildcards, with priority as follows: first, the priority of wildcards decreases from left to right, and then, if wildcards are substituted into List, the lower the index of elements in List, the higher the priority strategy.\n  @InjectProperty(keys = \"${low-list}.a.${high-list}.b\")\n  public long longValue;\n\n    //Default values can be specified by the defaultValue attribute of the annotation. If the field is not associated with any configuration properties, the default values defined will take effect, otherwise the default values will be overwritten.\n  @InjectProperty(defaultValue = \"abc\")\n  public String strDef;\n\n}\n</code></pre> <pre><code>/*\nnot use Service Comb annotations\n*/\npublic class ConfigNoAnnotation {\n  /*\n  If the @InjectProperties and @InjectProperty annotations are not provided, the field name is used as the configuration property name by default. Note that class names do not function as prefixes.\n\n  Here, the configuration property strValue is bound to the field\n    */\n  public String strValue;\n}\n</code></pre>"},{"location":"config/inject-config/#execution-injection","title":"Execution injection","text":"<p>We can execute injection with the following sample code\uff1a</p> <p>Inject configuration properties into objects without <code>InjectProperties</code> and <code>InjectProperty</code> annotations:</p> <pre><code>ConfigNoAnnotation config = SCBEngine.getInstance().getPriorityPropertyManager().createConfigObject(ConfigNoAnnotation.class);\n</code></pre> <p>Inject configuration properties into objects annotated with <code>InjectProperties</code> and <code>InjectProperty</code>:</p> <ul> <li>Inject the configuration property named <code>root.k.value</code> into the intValue field of a ConfigWithAnnotation object</li> <li>The <code>longValue</code> field of the <code>ConfigWithAnnotation</code> object is injected by looking up the configured configuration properties in the following order:</li> <li>root.low-1.a.high-1.b</li> <li>root.low-1.a.high-2.b</li> <li>root.low-2.a.high-1.b</li> <li>root.low-2.a.high-2.b</li> <li>The <code>floatValue</code> field of the <code>ConfigWithAnnotation</code> object is injected by looking up the configured configuration properties in the following order:</li> <li>root.l1-1</li> <li>root.l1-2</li> </ul> <pre><code>ConfigWithAnnotation config = SCBEngine.getInstance().getPriorityPropertyManager().createConfigObject(ConfigWithAnnotation.class,\n        \"key\", \"k\",\n        \"low-list\", Arrays.asList(\"low-1\", \"low-2\"),\n        \"high-list\", Arrays.asList(\"high-1\", \"high-2\"),\n        \"full-list\", Arrays.asList(\"l1-1\", \"l1-2\")\n        );\n</code></pre> <p>Finally, whether it is an annotation injection or not, you must explicitly reclaim the configuration injection object.</p> <pre><code>priorityPropertyManager.unregisterConfigObject(config)\n</code></pre>"},{"location":"config/inject-config/#reference-resources","title":"Reference resources","text":"<p>Refer to the sample code\uff1a https://github.com/apache/servicecomb-java-chassis/blob/master/foundations/foundation-config/src/test/java/org/apache/servicecomb/config/inject/TestConfigObjectFactory.java</p>"},{"location":"edge/by-servicecomb-sdk/","title":"Using Edge Service for Edge Services","text":"<p>Edge Service is the JAVA gateway service development framework provided by ServiceComb. As the external interface of the entire microservice system, the Edge Service provides services to end users, accesses RESTful requests, and forwards them to internal microservices. The Edge Service is provided in the form of a development framework. Developers can easily build an Edge Service service and define routing and forwarding rules with a simple configuration. At the same time, Edge Service supports powerful expansion capabilities, and services such as service mapping, request parsing, encryption and decryption, and authentication can be extended.</p> <p>The Edge Service itself is also a microservice that is subject to all microservice development rules. It can be deployed as a multi-instance, and the front-end uses a load balancing device for load distribution. It can also be deployed as a master and backup, and directly access user requests. Developers can plan according to the logic and service access and networking conditions carried by the Edge Service.</p>"},{"location":"edge/by-servicecomb-sdk/#developing-edge-service","title":"Developing Edge Service","text":"<p>Developing Edge Service is similar to developing a normal microservice. Developers can import [ServiceComb Edge Service Demo] (https://github.com/apache/incubator-servicecomb-java-chassis/tree/master/demo/demo -edge) Start. Building a project from scratch involves the following steps:</p> <ul> <li>Configure dependencies</li> </ul> <p>By adding edge-core dependencies to your project, you can start the Edge Service. When the Edge Service requests forwarding, it will go through the processing chain, so it can also join the dependencies of the relevant processing chain modules. The following example adds the load balancing processing chain. This is a must.</p> <pre><code>&lt;dependency&gt;\n  &lt;groupId&gt;org.apache.servicecomb&lt;/groupId&gt;\n  &lt;artifactId&gt;edge-core&lt;/artifactId&gt;\n&lt;/dependency&gt;\n&lt;dependency&gt;\n  &lt;groupId&gt;org.apache.servicecomb&lt;/groupId&gt;\n  &lt;artifactId&gt;handler-loadbalance&lt;/artifactId&gt;\n&lt;/dependency&gt;\n</code></pre> <ul> <li>Define the startup class</li> </ul> <p>Just like developing a normal microservice, you can pull the service by loading Spring.</p> <pre><code>public class EdgeMain {\n  public static void main(String[] args) throws Exception {\n    Log4jUtils.init();\n    BeanUtils.init();\n  }\n}\n</code></pre> <ul> <li>Increase the configuration file microservie.yaml The Edge Service itself is also a microservice that follows the rules of microservice lookup and will register itself. Note that APPLICAIONT_ID is the same as the microservice that needs to be forwarded. In the following configuration, the address that the Edge Service listens to, the processing chain, and so on are specified. The auth processing chain is a custom processing chain in the DEMO project for implementing authentication. At the same time, the auth service itself, without going through this processing chain, is equivalent to not authenticating.</li> </ul> <pre><code>APPLICATION_ID: edge\nservice_description:\n  name: edge\n  version: 0.0.1\nservicecomb:\n  service:\n    registry:\n      address: http://127.0.0.1:30100\n  rest:\n    address: 127.0.0.1:18080\n  handler:\n    chain:\n      Consumer:\n        default: auth,loadbalance\n        service:\n          auth: loadbalance\n</code></pre>"},{"location":"edge/by-servicecomb-sdk/#work-process","title":"work process","text":"<p>The workflow of the Edge Service is as follows, the blue background part is executed in the Eventloop thread, and the yellow background part: \u00a0\u00a0 * If working in reactive mode, execute directly in the Eventloop thread \u00a0\u00a0 * If working in thread pool mode, execute in the thread pool thread </p>"},{"location":"edge/by-servicecomb-sdk/#custom-routing-rules","title":"Custom routing rules","text":"<p>The core job of using the Edge Service is to configure routing rules. The rules are different, and the rules are different. A routing rule consists of a series of AbstractEdgeDispatchers. The Edge Service provides several common Dispatchers that can be enabled through configuration. If these Dispatchers do not meet the needs of the business scenario, they can be customized.</p> <ul> <li>Using DefaultEdgeDispatcher</li> </ul> <p>DefaultEdgeDispatcher is a very simple and easy to manage Dispatcher. With this Dispatcher, users do not need to manage forwarding rules dynamically. It is very convenient to apply to actual business scenarios. This is also a recommended management mechanism. It contains the following configuration items:</p> <pre><code>servicecomb:\n  http:\n    dispatcher:\n      edge:\n        default:\n          enabled: true\n          prefix: rest\n          withVersion: true\n          prefixSegmentCount: 1\n</code></pre> <p>Examples and meanings of these common configuration items are as follows: * [prefix=rest;withVersion=true;prefixSegmentCount=1] The URL provided by the microservice xService is: /xService/v1/abc, the address accessed by the Edge is /rest/xService/v1/abc, and the request is only forwarded to [1.0 .0-2.0.0) version of the microservice instance. * [prefix=rest;withVersion=true;prefixSegmentCount=2] The URL provided by the microservice xService is: /v1/abc, the address accessed by the Edge is /rest/xService/v1/abc, and the request is only forwarded to [1.0.0] -2.0.0) version of the microservice instance. * [prefix=rest;withVersion=true;prefixSegmentCount=3] The URL provided by the microservice xService is: /abc, the address accessed by Edge is /rest/xService/v1/abc, and the request is forwarded only to [1.0.0-2.0] .0) version of the microservice instance. * [prefix=rest;withVersion=false;prefixSegmentCount=1] The URL provided by the microservice xService is: /xService/v1/abc, the address accessed by the Edge is /rest/xService/v1/abc, and the request may be forwarded to any micro Service instance. * [prefix=rest;withVersion=false;prefixSegmentCount=2] The URL provided by the microservice xService is: /v1/abc, the address accessed by Edge is /rest/xService/v1/abc, and the request may be forwarded to any microservice. Example. * [prefix=rest;withVersion=false;prefixSegmentCount=2] The URL provided by the microservice xService is: /abc, the address accessed by the Edge is /rest/xService/abc, and the request may be forwarded to any microservice instance.</p> <p>The withVersion configuration item provides a client grayscale rule that allows the client to specify which server version to access. The Edge Service also includes the ability to route based on interface compatibility automatically, and requests are forwarded to instances that contain the interface. Assume that a microservice, compatibility plan for all high versions must be compatible with the lower version, deploy the following version of the instance:</p> <ul> <li> <p>1.0.0, provides operation1</p> </li> <li> <p>1.1.0, provided operation1, operation2</p> </li> </ul> <p>When Edge Service forwards operation1, it automatically uses the rule of 1.0.0+ to filter the instance.</p> <p>When Edge Service forwards operation2, it automatically uses the rules of 1.1.0+ to filter instances.</p> <p>The above process does not require any intervention and is fully automated to avoid forwarding the new version of the operation to the instance of the old version.</p> <ul> <li>Using URLMappedEdgeDispatcher</li> </ul> <p>URLMappedEdgeDispatcher allows users to configure mappings between URLs and microservices. It is very flexible to define which URLs are forwarded to which microservices. It contains the following configuration items:</p> <pre><code>servicecomb:\n  http:\n    dispatcher:\n      edge:\n        url:\n          enabled: true\n          mappings:\n            businessV1:\n              prefixSegmentCount: 1\n              path: \"/url/business/v1/.*\"\n              microserviceName: business\n              versionRule: 1.0.0-2.0.0\n            businessV2:\n              prefixSegmentCount: 1\n              path: \"/url/business/v2/.*\"\n              microserviceName: business\n              versionRule: 2.0.0-3.0.0\n</code></pre> <p>The meaning of the businessV1 configuration item is that the request with the request path of /usr/business/v1/. is forwarded to the microservice of business and only forwarded to the instance with version number 1.0.0-2.0.0 (excluding 2.0). .0). The URL when forwarding is /business/v1/.. Path uses the JDK regular expression, and you can view the description of the Pattern class. prefixSegmentCount indicates the number of URL segments of the prefix, and the prefix is not included in the forwarded URL path. Three forms of versionRule can be specified. 2.0.0-3.0.0 indicates the version range, including 2.0.0, but does not contain 3.0.0; 2.0.0+ indicates a version greater than 2.0.0, including 2.0.0; 2.0.0 means forwarding only to 2.0.0 version. 2, 2.0 is equivalent to 2.0.0.</p> <p>As can be seen from the above configuration, URLMappedEdgeDispatcher also supports client grayscale. Of course, there will be more configuration items than DefaultEdgeDispatcher. The URLMappedEdgeDispatcher supports dynamic configuration modification of the configuration center to adjust routing rules.</p> <ul> <li>Custom Dispatcher</li> </ul> <p>Customizing the Dispatcher involves two steps:</p> <ol> <li>Implement AbstractEdgeDispatcher</li> <li>Release via SPI: add the file META-INF/services/org.apache.servicecomb.transport.rest.vertx.VertxHttpDispatcher and write the implementation class</li> </ol> <p>Detailed code details can be found in the following section \"DEMO Functional Description\". Developers can also refer to the Code such as DefaultEdgeDispatcher to define their Dispatcher.</p> <ul> <li>Perform authentication and other business processing</li> </ul> <p>Through the Edge Service workflow, you can see that the Edge Service features can be extended in a variety of ways, including Dispatcher, HttpServerFilter, Handler, HttpClientFilter, and more. More common and straightforward is to extend through Handler. DEMO shows how to implement authentication through Handler extensions. Detailed code details can be found in the following section \"DEMO Functional Description\"."},{"location":"edge/by-servicecomb-sdk/#deployment-example","title":"Deployment example","text":""},{"location":"edge/by-servicecomb-sdk/#operating-mode","title":"Operating mode","text":"<ul> <li>reactive (default)</li> </ul> <p>The Edge Service works by default in the high-performance reactive mode. This mode requires that the business code working in the Edge Service forwarding process cannot have any blocking operations, including:</p> <ul> <li> <p>Remote synchronization calls, such as an asynchronous query database, synchronous call microservices, or synchronous query remote cache, etc.</p> </li> <li> <p>any sleep call</p> </li> <li> <p>any wait call</p> </li> <li> <p>Oversized loop</p> </li> </ul> <p>The underlying Edge Service is based on netty's vertx. The above constraint is netty's reactive mode constraint.</p> <p></p> <ul> <li>Thread Pool</li> </ul> <p>If the business model cannot meet the reactive requirements, you need to use the thread pool mode.</p> <p>In this case, you need to configure it in the microservice.yaml of the Edge Service:</p> <pre><code>servicecomb:\n  executors:\n    default: servicecomb.executor.groupThreadPool\n</code></pre> <p>Here servicecomb.executor.groupThreadPool is the beanId of the spring bean corresponding to the default thread pool built into ServiceComb; the service can customize its thread pool and declare it as a bean whose beanId can also be configured here.</p> <p></p>"},{"location":"edge/by-servicecomb-sdk/#demo-function-description","title":"DEMO Function Description","text":"<p>Please refer to the edge service demo on GitHub:</p> <p>https://github.com/ServiceComb/ServiceComb-Java-Chassis/tree/master/demo/demo-edge</p> <p>The demo contains the following projects:</p> <ul> <li>authentication: microservice: authentication server</li> <li>edge-service</li> <li>hiboard-business-1.0.0 microservices: business, version 1.0.0, operation add</li> <li>hiboard-business-1.1.0 microservices: business, version 1.1.0, operation add/dec</li> <li>hiboard-business-2.0.0 microservices: business, version 2.0.0, operation add/dec</li> <li>hiboard-consumer as a normal httpclient, not a servicecomb consumer</li> <li>hiboard-model non-micro service, just some public models</li> </ul> <p>Access different versions of microservices through edge-service and confirm that the correct instance handles them.</p> <ul> <li>Register Dispatcher</li> </ul> <p>Implement the interface org.apache.servicecomb.transport.rest.vertx.VertxHttpDispatcher, or inherit from org.apache.servicecomb.edge.core.AbstractEdgeDispatcher to implement your own dispatcher function.</p> <p>The implementation class is registered to the system through the Java standard SPI mechanism.</p> <p>Dispatcher needs to implement 2 methods:</p> <ul> <li>getOrder</li> </ul> <p>Dispatcher needs to inject routing rules into vertx, and routing rules have a priority order relationship.</p> <p>All Dispatchers in the system are sorted according to the return value of getOrder from small to large and initialized in order.</p> <p>If the GetOrder return values the two Dispatchers are the same, the order of the two is unpredictable.</p> <ul> <li>init</li> </ul> <p>The init method is included in the io.vertx.ext.web.The router in the vertx framework. You need to customize the routing rules through this object.</p> <p>You can specify the url that meets the requirements, whether you need to process the cookie, whether you need to handle the body, which custom method to use to process the received request, etc.</p> <p>For more details on routing rules, please refer to the official vertx documentation: [vertx routing mechanism] (http://vertx.io/docs/vertx-web/java/#_routing_by_exact_path)</p> <p>prompt:</p> <p>_ Multiple Dispatchers can set routing rules to cover the same url. _</p> <p>_Assuming Dispatcher A and B can both handle the same url, and A has a higher priority, then: _</p> <ul> <li> <p>_ If A is processed, neither responding nor calling RoutingContext.next(), it is a bug, this request is hanged _</p> </li> <li> <p>_ If A is processed and then calling RoutingContext.next(), the request will be transferred to B.</p> </li> <li> <p>Forwarding request</p> </li> </ul> <p>When registering a route, it specifies which method is used to process the request (the following method is used to refer to the method), and the forwarding logic is implemented in the onRequest.</p> <p>The method prototype is:</p> <pre><code>void onRequest(RoutingContext context)\n</code></pre> <p>The system encapsulates org.apache.servicecomb.edge.core.EdgeInvocation to implement forwarding. At least the following parameters need to be prepared:</p> <ul> <li> <p>microserviceName, the business makes its own rules, can be passed in the url, or according to the url search, etc.</p> </li> <li> <p>context, that is, the input of onRequest</p> </li> <li> <p>path, the url of the forwarding target</p> </li> <li> <p>httpServerFilters, the Dispatcher parent class has initialized member variables</p> </li> </ul> <pre><code>\u00a0 EdgeInvocation edgeInvocation = new EdgeInvocation();\n\u00a0 edgeInvocation.init(microserviceName, context, path, httpServerFilters);\n\u00a0 edgeInvocation.edgeInvoke();\n</code></pre> <p>The edgeInvoke call is internally called and will be forwarded as a ServiceComb standard consumer.</p> <p>As a standard consumer, it means that the governance capabilities of all ServiceComb standards are valid here.</p> <ul> <li>Setting compatibility rules</li> </ul> <p>Different services may have different compatibility plans, servicecomb default compatibility rules, and all new versions are required to be compatible with the old version. If this requirement is met, no special settings need to be made.</p> <p>There is also a typical plan:</p> <ul> <li> <p>1.0.0-2.0.0 is internally compatible, url is in the form of /microserviceName/v1/....</p> </li> <li> <p>2.0.0-3.0.0 is internally compatible, url is in the form of /microserviceName/v2/....</p> </li> </ul> <p>......</p> <p>Incompatible between major versions</p> <p>At this point, the developer needs to set compatibility rules for EdgeInvocation:</p> <pre><code>private CompatiblePathVersionMapper versionMapper = new CompatiblePathVersionMapper();\n\n\u2026\u2026\n\nedgeInvocation.setVersionRule(versionMapper.getOrCreate(pathVersion).getVersionRule());\n</code></pre> <p>The role of versionMapper is to convert a string such as v1 or v2 to a compatibility rule such as 1.0.0-2.0.0 or 2.0.0-3.0.0.</p> <p>note:</p> <p>Incompatible interfaces can cause many problems. The java chassis requires that the higher version of the service is compatible with the lower version of the service, and only allows the addition of the interface to not allow the interface to be deleted. After adding an interface, you must increase the version number of the microservice. In the development phase, interfaces change frequently, and developers often forget this rule. When this constraint is broken, you need to clean up the service center microservices information and restart the microservices and Edge Service\\ (and other services that depend on the microservices). Otherwise, the request forwarding failure may occur.</p> <ul> <li>Authentication</li> </ul> <p>The Edge Service is the boundary of the system and requires authentication logic for many requests.</p> <p>Based on the standard ServiceComb mechanism, this function can be implemented by the handler.</p> <p>The simplest code is as follows:</p> <pre><code>public class AuthHandler implements Handler {\n private Auth auth;\n\n public AuthHandler() {\n auth = Invoker.createProxy(\"auth\", \"auth\", Auth.class);\n }\n\u2026\u2026\n\n @Override\n public void handle(Invocation invocation, AsyncResponse asyncResp) throws Exception {\n if (!auth.auth(\"\")) {\n asyncResp.consumerFail(new InvocationException(Status.UNAUTHORIZED, (Object) \"auth failed\"));\n return;\n }\n\n LOGGER.debug(\"auth success.\");\n invocation.next(asyncResp);\n }\n}\n</code></pre> <p>Auth is the interface provided by the authentication microservice. Invoker.createProxy(\"auth\", \"auth\", Auth.class) is the underlying api of the consumer in the transparent RPC development mode, which is equivalent to @ReferenceRpc, but not Need to rely on the spring bean mechanism.</p> <p>The business completely defines the Auth interface, but here is just an example.</p> <p>After the Handler development is complete, configure it into the microservice.yaml of the edge service:</p> <pre><code>servicecomb:\n  handler:\n    chain:\n      Consumer:\n        default: auth,\u2026\u2026\n        service:\n          auth: \u2026\u2026\n</code></pre> <p>In this example, it means that the forwarding request to all microservices must be authenticated, but authentication is not required when calling the authentication microservice.</p>"},{"location":"edge/nginx/","title":"Using confd and Nginx for edge services","text":""},{"location":"edge/nginx/#concept-description","title":"Concept Description","text":""},{"location":"edge/nginx/#confd","title":"confd","text":"<p>Confd is a lightweight configuration management tool, source code: [https://github.com/kelseyhightower/confd] (https://github.com/kelseyhightower/confd), which stores configuration information in etcd, Consul, dynamodb, redis, and zookeeper. Confd periodically pulls the latest configuration from these storage nodes, then reloads the service and completes the configuration file update.</p>"},{"location":"edge/nginx/#nginx","title":"Nginx","text":"<p>Nginx (engine x) is a high-performance HTTP and reverse proxy server with load balancing capabilities. For details, please refer to [http://www.nginx.cn/doc/] (http://www.nginx.cn/doc/). The services introduced in this section mainly use the Nginx http proxy function.</p>"},{"location":"edge/nginx/#scene-description","title":"Scene Description","text":"<p>The technology introduced in this section is to use nginx+confd as the edge service. At the same time, you can dock the service center in the Java Chassis microservices framework, and pull the service information from the service center to dynamically update the nginx configuration through confd.</p> <p>The implementation steps of using nginx+confd dynamic reverse proxy can be found in the article [http://www.cnblogs.com/Anker/p/6112022.html] (http://www.cnblogs.com/Anker/p/6112022. Html), this section mainly introduces how confd docks the service center of the Java Chassis framework.</p>"},{"location":"edge/nginx/#docking-service-center","title":"Docking Service Center","text":"<p>The core of the technology introduced in this section is how to make confd get the service information of the service center. The service center opens the following interfaces for external calls:</p>"},{"location":"edge/nginx/#method-one-http-call","title":"**Method one: http call **","text":"<p>The service provider open http interface needs to add the tenant header information: \"X-Tenant-Name:tenantName\", and the tenameName is the tenant name. The default is default, for example, \"X-Tenant-Name: default\".</p> <ul> <li>Check the health status of the service center</li> </ul> <p><code>GET 127.0.0.1:30100/health</code></p> <ul> <li>Get all micro service information</li> </ul> <p><code>GET 127.0.0.1:30100/registry/v3/microservices</code></p> <ul> <li>Get the microservice information of the specified id</li> </ul> <ol> <li>First get the serviceId based on the microservice information</li> </ol> <p><code>GET 127.0.0.1:30100/registry/v3/existence?type=microservice&amp;appId={appId}&amp;serviceName={serviceName}&amp;version={version}</code></p> <ol> <li> <ol> <li>Obtain the microservice complete information according to the serviceId returned by the above interface.</li> </ol> </li> </ol> <p>GET 127.0.0.1:30100/registry/v3/microservices/{serviceId}</p> <ul> <li>Get all instance information for the specified microservice</li> </ul> <p>``` \u00a0\u00a0\u00a0GET 127.0.0.1:30100/registry/v3/microservices/{serviceId}/instances</p> <p>Need to add in the header: \"X-ConsumerId: {serviceId}\". \u00a0\u00a0```</p> <ul> <li>Find micro service instance information</li> </ul> <p>``` \u00a0\u00a0\u00a0GET 127.0.0.1:30100/registry/v3/instances?appId={appId}&amp;serviceName={serviceName}&amp;version={version}</p> <p>Need to add in the header: \"X-ConsumerId: {serviceId}\". \u00a0\u00a0```</p>"},{"location":"edge/nginx/#note-in-actual-development-please-visit-the-actual-service-center-access-address-and-replace-the-variable-of-in-the-above-url-with-a-specific-value-the-data-returned-by-http-is-in-json-format","title":"Note: In actual development, please visit the actual service-center access address, and replace the variable of {} in the above url with a specific value. The data returned by http is in json format.","text":""},{"location":"edge/nginx/#method-2-use-servicecomb-open-source-code-interface","title":"Method 2: Use servicecomb open source code interface","text":"<p>In the development of microservices applications, you only need to call the interface provided in the tool class RegistryUtil.java in the servicecomb framework code to get the information of the service center. The interface description is as follows:</p> <ul> <li>Get all micro service information</li> </ul> <p><code>java \u00a0\u00a0List&lt;Microservice&gt; getAllMicroservices();</code></p> <ul> <li>Get the microservice unique identifier</li> </ul> <p><code>java \u00a0\u00a0String getMicroserviceId(String appId, String microserviceName, String versionRule);</code></p> <ul> <li>Query microservice static information based on microservice unique identifier</li> </ul> <p><code>java \u00a0\u00a0Microservice getMicroservice(String microserviceId);</code></p> <ul> <li>Query all micro service instance information based on multiple microservice unique identifiers</li> </ul> <p><code>java \u00a0\u00a0List&lt;MicroserviceInstance&gt; getMicroserviceInstance(String consumerId, String providerId);</code></p> <ul> <li>Query instance endpoints information by app+interface+version</li> </ul> <p><code>java \u00a0\u00a0List&lt;MicroserviceInstance&gt; findServiceInstance(String consumerId, String appId, String serviceName, String versionRule);</code></p> <p>Through the above http interface, information about the microservices of the service center and its instances can be obtained, thereby dynamically updating the nginx configuration through confd.</p>"},{"location":"edge/open-service/","title":"Open service capacity","text":"<p>A large number of micro-service capabilities need to be opened to users and other external systems through the gateway. On the one hand, the gateway plays the role of collecting user requests, and also plays the role of authentication, authentication, flow control, and anti-attack. At the same time, because the gateway is a convergence point, it is easy to form a bottleneck of the service. Usually, a multi-level gateway mechanism is adopted. The external gateway provides the master and backup as well as the simple request forwarding function, and the middle layer implements authentication and other functions. Deploy. Common technologies and services that can be used for gateways include LVS, Nginx, Zuul, and others.</p> <p>ServiceComb also provides its gateway service, Edge Service. The Edge Service has built-in powerful routing policies, supports interface-level compatibility forwarding (grayscale publishing), embedded ServiceComb governance capabilities, and supports very flexible extension mechanisms.</p>"},{"location":"edge/zuul/","title":"Using zuul for edge services","text":""},{"location":"edge/zuul/#concept-description","title":"Concept Description","text":""},{"location":"edge/zuul/#api-gateway","title":"API Gateway:","text":"<p>The API Gateway is a server or a unique node that enters the system. The API Gateway encapsulates the architecture of the internal system and provides APIs to individual clients.</p>"},{"location":"edge/zuul/#zuul","title":"Zuul","text":"<p>Zuul is Netflix's JVM-based router and server-side load balancer, which can be used by Zuul to:</p> <ul> <li>Certification</li> <li>Insight</li> <li>pressure test</li> <li>Canary Test</li> <li>Dynamic routing</li> <li>Service migration</li> <li>Load shedding</li> <li>Safety</li> <li>Static phase response processing</li> <li>Active / passive traffic management</li> </ul> <p>This section focuses on using Zuul as an API Gateway in SpringBoot applications. For detailed functions of Zuul, please refer to the document [router and filter: Zuul] (https://springcloud.cc/spring-cloud-dalston.html#_router_and_filter_zuul).</p>"},{"location":"edge/zuul/#scene-description","title":"Scene Description","text":"<p>Zuul is the API Gateway, which is to establish a Zuul Proxy application. All the microservice access portals are defined in the Proxy application, and different microservices are distinguished by using different prefixes (stripped). This section demonstrates Zuul's API Gateway functionality by creating a ZuulProxy SpringBoot application.</p>"},{"location":"edge/zuul/#precautions","title":"Precautions","text":"<p>The demos such as ZuulProxy and ZuulServer described in this section are based on SpringBoot and ServiceComb frameworks. For details, please refer to [using java chassis in Spring Boot] (../using-java-chassis-in-spring-boot/using-java-chassis-in-spring-boot.md).</p>"},{"location":"edge/zuul/#launching-zuul-proxy","title":"Launching Zuul Proxy","text":"<p>This section describes how to launch a zuul proxy application as an API Gateway. Proceed as follows:</p> <ul> <li>Step 1Add a dependency to the pom file:</li> </ul> <pre><code>&lt;dependency&gt;\n\u00a0\u00a0&lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;\n\u00a0\u00a0&lt;artifactId&gt;spring-cloud-starter-zuul&lt;/artifactId&gt;\n&lt;/dependency&gt;\n&lt;dependency&gt;\n\u00a0\u00a0&lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;\n\u00a0\u00a0&lt;artifactId&gt;spring-cloud-starter-ribbon&lt;/artifactId&gt;\n&lt;/dependency&gt;&lt;dependency&gt;\n\u00a0\u00a0&lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;\n\u00a0\u00a0&lt;artifactId&gt;spring-cloud-starter-hystrix&lt;/artifactId&gt;\n&lt;/dependency&gt;\n&lt;dependency&gt;\n\u00a0\u00a0&lt;groupId&gt;org.apache.servicecomb&lt;/groupId&gt;\n\u00a0\u00a0&lt;artifactId&gt;spring-boot-starter-discovery&lt;/artifactId&gt;\n&lt;/dependency&gt;\n</code></pre> <ul> <li>Step 2Add annotations to the SpringBoot main class:</li> </ul> <pre><code>@SpringBootApplication\n@EnableServiceComb\n@EnableZuulProxy//Additional annotations\npublic class ZuulMain{\n\u00a0\u00a0\u00a0\u00a0public static void main(String[] args) throws Exception{\n        SpringApplication.run(ZuulMain.class, args);\n\u00a0\u00a0\u00a0\u00a0}\n}\n</code></pre> <ul> <li>Step 3 Define the routing policy in the application.yml file:</li> </ul> <pre><code>server:\n\u00a0\u00a0port: 8754 #api gateway service port\nzuul:\n\u00a0\u00a0routes: #route strategy\n\u00a0\u00a0\u00a0\u00a0discoveryServer: /myServer/** #route rule\n</code></pre> <p>The red configuration item indicates that it can be configured according to the actual development environment. For detailed definition rules of the routing policy of zuul.routers, please refer to the official literature: [router and filter: Zuul] (https://springcloud.cc/spring-cloud-dalston.html#_router_and_filter_zuul), which can be more finely Control the route.</p> <ul> <li>Step 4 Define microservice properties in microservice.yaml:</li> </ul> <pre><code>APPLICATION_ID: discoverytest #service ID\nservice_description:\n\u00a0\u00a0name: discoveryGateway #service name\n\u00a0\u00a0version: 0.0.2 #service version number\nservicecomb:\n\u00a0\u00a0service:\n\u00a0\u00a0\u00a0\u00a0Registry:\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0Address: http://127.0.0.1:30100 #Service registry address\n\u00a0rest:\n\u00a0\u00a0\u00a0address: 0.0.0.0:8082 # Service port, can not write\n</code></pre> <ul> <li>Step 5 Run ZuulMain Application</li> </ul>"},{"location":"edge/zuul/#using-zuul-proxy","title":"Using Zuul Proxy","text":"<p>Before using the API Gateway made by Zuul, you must first start the microservice provider defined in zuul.routers.</p> <p>To develop a service provider, please refer to 3 Development Service Provider for the opening process. Pay attention to the following two points in the microservice.yaml file:</p> <ul> <li> <p>APPLICATION_ID needs to be consistent in the definition defined in the zuul proxy.</p> </li> <li> <p>service_description.name needs to correspond to zuul.routers.</p> </li> </ul> <p>An example is as follows:</p> <pre><code>APPLICATION_ID: discoverytest # is consistent with zuul proxy\nservice_description:\n\u00a0\u00a0name: discoveryServer #service name, corresponding to zuul.routers\n\u00a0\u00a0version: 0.0.2\nservicecomb:\n\u00a0\u00a0service:\n\u00a0\u00a0\u00a0\u00a0registry:\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0address: http://127.0.0.1:30100 #Service registry address\nrest:\n\u00a0\u00a0address: 0.0.0.0:8080\n</code></pre> <p>The API Gateway access is: [http://127.0.0.1:8754] (http://127.0.0.1:8754), all services defined in zuul.routers can be accessed through this access portal, access The rules are as follows:</p> <p>http://127.0.0.1:8754/myServer/***</p> <p>This means that Http calls [http://127.0.0.1:8754/myServer/***] (http://127.0.0.1:8754/myServer/***) and will go to the discoveryServer service (for example: \"/myServer/101\" jumps to \"/101\" under the discoveryServer service)</p> <p>If there are multiple discoveryServer services in the service center (version is different), zuul uses the Ribbon policy to forward requests.</p>"},{"location":"general-development/AlarmEvent/","title":"Get warning event from Circuit Breaker or Instance Isolation.","text":""},{"location":"general-development/AlarmEvent/#senario","title":"Senario","text":"<ul> <li>When the microservice is running, Circuit Breaker or the instance isolation status changes, you need to listen to related events, get relevant information and handle it.</li> </ul>"},{"location":"general-development/AlarmEvent/#use-reference","title":"Use Reference","text":"<ul> <li>Monitor CircuitBreaker events</li> </ul> <pre><code>Object receiveEvent = new Object() {\n  @Subscribe\n  public void onEvent(CircutBreakerEvent circutBreakerEvent) {\n    //Get information from circutBreakerEvent\n    }\n  };\nEventManager.getEventBus().register(receiveEvent);\n</code></pre> <ul> <li>Listen for instance isolation events</li> </ul> <pre><code>Object receiveEvent = new Object() {\n  @Subscribe\n  public void onEvent(IsolationServerEvent isolationServerEvent) {\n    //Get information from isolationServerEvent\n    }\n  };\nEventManager.getEventBus().register(receiveEvent);\n</code></pre> <ul> <li>Both events are monitored</li> </ul> <pre><code>Object receiveEvent = new Object() {\n  @Subscribe\n  public void onEvent(AlarmEvent alarmEvent) {\n    //Get information from alarmEvent\n    }\n  };\nEventManager.getEventBus().register(receiveEvent);\n</code></pre>"},{"location":"general-development/CORS/","title":"CORS mechanism","text":""},{"location":"general-development/CORS/#concept-description","title":"Concept Description","text":"<p>Cross-Origin Resource Sharing (CORS) allows Web servers to perform cross-domain access, enabling browsers to more securely transfer data across domains.</p>"},{"location":"general-development/CORS/#scenario","title":"Scenario","text":"<p>When the user needs to send REST requests across the origin webserver, the CORS mechanism may be used. The microservices that receive cross-domain requests need to enable CORS support.</p>"},{"location":"general-development/CORS/#configuration-instructions","title":"Configuration instructions","text":"<p>The CORS function is configured in the microservice.yaml file. The configuration items are described in the following table.</p> <p>| Configuration Item | Default Value | Range of Value | Required | Meaning | | :--- | :--- | :--- | :--- | :--- | :--- | | servicecomb.cors.enabled | <code>false</code> | <code>true</code>/<code>false</code> | No | Whether to enable CORS function | - | | servicecomb.cors.origin | <code>*</code> | - | No | Access-Control-Allow-Origin | - | | servicecomb.cors.allowCredentials | <code>false</code> | <code>true</code>/<code>false</code> | No | Access-Control-Allow-Credentials | According to the CORS standard, when Access-Control-Allow-Credentials is set to <code>true</code>, Access- Control-Allow-Origin cannot be set to \"*\", otherwise an exception will be thrown | | servicecomb.cors.allowedHeader | None | - | No | Access-Control-Allow-Headers | Multiple values \u200b\u200bseparated by commas | | servicecomb.cors.allowedMethod | None | - | No | Access-Control-Allow-Methods | Multiple values \u200b\u200bseparated by commas | | servicecomb.cors.exposedHeader | None | - | No | Access-Control-Expose-Headers | Multiple values \u200b\u200bseparated by commas | | servicecomb.cors.maxAge | None | (0,2147483647], Integer | No | Access-Control-Max-Age | The unit is seconds. If the user does not configure this, there is no Access-Control-Max in the CORS response. Age |</p>"},{"location":"general-development/CORS/#sample-code","title":"Sample Code","text":"<pre><code>servicecomb:\n  cors:\n    enabled: true\n    origin: \"*\"\n    allowCredentials: false\n    allowedMethod: PUT,DELETE\n    maxAge: 3600\n</code></pre>"},{"location":"general-development/context/","title":"Delivery Messages through Context","text":"<p>ServiceComb provides a Context to delivery data between microservices. Context is a key/value pair and can only use data of type String. Since the Context is serialized into the Json format and passed through the HTTP header, characters other than ASCII are not supported. Other characters require the developer to encode and pass the code. The Context is passed on the request chain in a single request and does not need to be reset. The functions such as trace id of access log are implemented based on this feature.</p>"},{"location":"general-development/context/#scenario","title":"Scenario","text":"<ul> <li>In the authentication scenario, after the Edge Service authentication is passed, the session ID, username, and other information need to be passed to the microservice to implement authentication and other logic.</li> <li>Grayscale publishing scenarios, need to be combined with custom tags shunt request, tag information needs to be passed to the microservices</li> </ul>"},{"location":"general-development/context/#use-reference","title":"Use Reference","text":"<ul> <li>Get and set the Context in Handler</li> </ul> <p>The Handler contains the Invocation object, which can be called directly in the invocation.addContext and invocation.getContext settings.</p> <ul> <li>Get Context in the service interface</li> </ul> <p>Inject through the interface</p> <pre><code>public Response cseResponse(InvocationContext c1)\n</code></pre> <p>or</p> <pre><code>ContextUtils.getInvocationContext()\n</code></pre> <ul> <li>Set the Context in the Edge Service</li> </ul> <p>By override EdgeInvocation</p> <pre><code>EdgeInvocation edgeInvocation = new EdgeInvocation() {\n  protected void createInvocation() {\n    super.createInvocation();\n    this.invocation.addContext(\"hello\", \"world\");\n  }\n};\n</code></pre>"},{"location":"general-development/cross-app-invocation/","title":"Cross App Invocation","text":""},{"location":"general-development/cross-app-invocation/#concept-description","title":"Concept Description","text":"<p>An application is a layer in the microservice instance isolation hierarchy, and an application contains multiple microservices. By default, only microservice instances of the same application are allowed to call each other.</p>"},{"location":"general-development/cross-app-invocation/#scenario","title":"Scenario","text":"<p>When a user needs micro-services between different applications to call each other, it is necessary to enable the cross-application calling function.</p>"},{"location":"general-development/cross-app-invocation/#configuration-instructions","title":"Configuration instructions","text":"<p>To enable cross-application calls, you first need to enable cross-application call configuration in the microservice.yaml file on the provider side.</p> <p>Note: * Need to upgrade the micro service version number to re-register micro service information in the service center * Even in the development development environment, you need to upgrade the microservice version number, because in the development environment, only the contract changes, will re-register the contract</p> <p>The configuration items are as follows:</p> <pre><code>service_description:\n  # other configuration omitted\n  properties:\n    allowCrossApp: true # enable cross-app invocation\n</code></pre> <p>When the consumer client specifies the microservice name to call the provider, it needs to add the application ID to which the provider belongs, and the format becomes <code>[appID]:[microserviceName]</code>.</p>"},{"location":"general-development/cross-app-invocation/#sample-code","title":"Sample Code","text":"<p>The example assumes that the application to which the provider belongs is helloApp, the name of the microservice is helloProvider, the application to which the consumer belongs is helloApp2, and the name of the microservice is helloConsumer.</p> <ul> <li>RestTemplate invocation mode</li> </ul> <p>When the consumer client develops the microservice consumer in the RestTemplate mode, you need to change <code>[microserviceName]</code> to <code>[appID]:[microserviceName]</code> in the called URL. The code example is as follows:   ```java     RestTemplate restTemplate = RestTemplateBuilder.create();</p> <pre><code>ResponseEntity&lt;String&gt; responseEntity = restTemplate\n    .getForEntity(\"cse://helloApp:helloProvider/hello/sayHello?name={name}\",\n        String.class, \"ServiceComb\");\n</code></pre> <p><code>- RPC invocation mode \u00a0\u00a0When the consumer client develops a microservice consumer in RPC mode, the declared service provider proxy is as follows:</code>java     @RpcReference(schemaId = \"hello\", microserviceName = \"helloApp:helloProvider\")     private Hello hello;   <code>Cross-application invocation is the same way as invocate microservices under the same application:</code>java     hello.sayHello(\"ServiceComb\");   ```</p>"},{"location":"general-development/customized-tracing/","title":"Customized-Tracing","text":""},{"location":"general-development/customized-tracing/#concept-description","title":"Concept Description","text":"<p>Distributed call chain tracking provides timing information for calls between services, but the link call information inside the service is equally important to the developer. If you can combine the two into one, you can provide a more complete call chain, which is easier to locate. Errors and potential performance issues.</p>"},{"location":"general-development/customized-tracing/#prerequisites","title":"Prerequisites","text":"<ul> <li>Using the custom dot function requires first configuring and enabling the Java Chassis microservice call chain.</li> </ul>"},{"location":"general-development/customized-tracing/#precautions","title":"Precautions","text":"<ul> <li>The custom dot function using the <code>@Span</code> annotation only supports method calls that are requesting the same thread as the Java Chassis call.</li> <li>The method to add the <code>@Span</code> annotation must be a Spring-managed bean, otherwise you need to press the [Methods mentioned] (https://stackoverflow.com/questions/41383941/load-time-weaving-for-non-spring -beans-in-a-spring-application) configuration.</li> </ul>"},{"location":"general-development/customized-tracing/#custom-call-chain-management","title":"Custom call chain management","text":"<p>This feature integrates Zipkin and provides the <code>@Span</code> annotation for custom tracking of methods that need to be tracked. Java Chassis will automatically track all methods that add <code>@Span</code> annotations, linking the local call information of each method to the call information between services.</p>"},{"location":"general-development/customized-tracing/#steps-for-usage","title":"Steps for usage:","text":""},{"location":"general-development/customized-tracing/#adding-dependencies","title":"Adding dependencies","text":"<p>Microservices based on ServiceComb Java Chassis only need to add the following dependency to pom.xml:</p> <pre><code>    &lt;dependency&gt;\n      &lt;groupId&gt;org.apache.servicecomb&lt;/groupId&gt;\n      &lt;artifactId&gt;tracing-zipkin&lt;/artifactId&gt;\n    &lt;/dependency&gt;\n</code></pre>"},{"location":"general-development/customized-tracing/#enable-custom-management-function-configure-tracking-processing-and-data-collection","title":"Enable custom management function {#Configure tracking processing and data collection}","text":"<p>Add the <code>@EnableZipkinTracing</code> annotation to the application portal or Spring configuration class:</p> <pre><code>@SpringBootApplication\n@EnableZipkinTracing\npublic class ZipkinSpanTestApplication {\n  public static void main(String[] args) {\n    SpringApplication.run(ZipkinSpanTestApplication.class);\n  }\n}\n</code></pre>"},{"location":"general-development/customized-tracing/#customized-management","title":"Customized management","text":"<p>Add the <code>@Span</code> annotation to the method that requires custom management:</p> <pre><code>@Component\npublic class SlowRepoImpl implements SlowRepo {\n  private static final Logger logger = LoggerFactory.getLogger(SlowRepoImpl.class);\n\n  private final Random random = new Random();\n\n  @Span\n  @Override\n  public String crawl() throws InterruptedException {\n    logger.info(\"in /crawl\");\n    Thread.sleep(random.nextInt(200));\n    return \"crawled\";\n  }\n}\n</code></pre> <p>In this way, by using the <code>@Span</code> annotation, we started the Zipkin-based custom management function.</p>"},{"location":"general-development/customized-tracing/#customized-reported-data","title":"Customized reported data","text":"<p>The call chain that is escalated by custom management contains two pieces of data:</p> <ul> <li>span name defaults to the full name of the method currently being annotated.</li> <li>call.path defaults to the method signature of the current annotation.</li> </ul> <p>For example, the data reported in the above example <code>SlowRepoImp</code> is as follows:</p> key value span name crawl call.path public abstract java.lang.String org.apache.servicecomb.tests.tracing.SlowRepo.crawl() throws java.lang.InterruptedException <p>If you need to customize the reported data content, you can pass in the custom parameters:</p> <pre><code>  public static class CustomSpanTask {\n    @Span(spanName = \"transaction1\", callPath = \"startA\")\n    public String invoke() {\n      return \"invoke the method\";\n    }\n  }\n</code></pre>"},{"location":"general-development/dai-li-she-zhi/","title":"Proxy Settings","text":""},{"location":"general-development/dai-li-she-zhi/#background","title":"background","text":"<p>As a developer, in a company development environment, it is possible to access the Internet through a corporate agent network. If debugging services depends on online resources, such as directly connecting to public cloud service center, you must configure the agent.</p> <p>Configuration mode, add proxy configuration in microservice.yaml file:</p> <pre><code>servicecomb:\n\u00a0\u00a0proxy:\n\u00a0\u00a0\u00a0\u00a0enable: true #Do you want to enable the proxy?\n\u00a0\u00a0\u00a0\u00a0host: yourproxyaddress #proxy address\n\u00a0\u00a0\u00a0\u00a0port: 80 #proxy port\n\u00a0\u00a0\u00a0\u00a0username: yourname #username\n\u00a0\u00a0\u00a0\u00a0passwd: yourpassword #password\n</code></pre> <p>Configure password using encryption is supported by using SPI. The SPI intrface is org.apache.servicecomb.foundation.common.encrypt.Encryption. Users can implement customer decode interface.</p> <p>**Note: Currently only supports connection service center, configuration center support agent. If you connect other three-party services, you can read this configuration, configure the agent yourself, vertx httpclient supports proxy settings, for example: **</p> <pre><code>\u00a0\u00a0\u00a0\u00a0HttpClientOptions httpClientOptions = new HttpClientOptions();\n\u00a0\u00a0\u00a0\u00a0If (isProxyEnable()) {\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0ProxyOptions proxy = new ProxyOptions();\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0proxy.setHost(\"host\");\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0proxy.setPort(port);\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0proxy.setUsername(\"username\");\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0proxy.setPassword(\"passwd\");\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0httpClientOptions.setProxyOptions(proxy);\n\u00a0\u00a0\u00a0\u00a0}\n</code></pre>"},{"location":"general-development/dnsconfig/","title":"DNS Custom Configuration","text":""},{"location":"general-development/dnsconfig/#scenario","title":"Scenario","text":"<p>When a user uses a domain name to connect to a public cloud or a third-party system, you need to use the domain name resolution DNS system. The DNS used in different systems and different frameworks may be different. Therefore, it is necessary to provide a unified configuration entry so that development and operation personnel can customize the DNS resolution mechanism without being completely subject to system configuration.</p>"},{"location":"general-development/dnsconfig/#dns-configuration","title":"DNS Configuration","text":"<p>The DNS configuration item is written in the microservice.yaml file. It supports the unified development of certificates. It can also add tags for more fine-grained configuration. The tag configuration overrides the global configuration. The configuration format is as follows:</p> <pre><code>addressResolver.[tag].[property]\n</code></pre> <p>The common tags are as follows:</p> Project tag Service Center sc.consumer Configuration Center cc.consumer User Defined self.tag <p>The detailed description of each property (Set Vertx DNS resolution)</p> <pre><code>addressResolver:\n\u00a0\u00a0servers: 8.8.8.8, 8.8.4.4 #corresponds to the nameserver of Linux /etc/resolv.conf, the DNS server address, supports multiple configurations, separated by commas\n\u00a0\u00a0ndots: 1 # corresponds to the options in linux /etc/resolv.conf: ndots, the role is that if the number of points contained in the domain name is less than the threshold, then DNS resolution will be added by default to the value of searchDomains. This must be used in conjunction with searchDomains.  \n\u00a0\u00a0searchDomains: a, b, c # Corresponding to the search in linux /etc/resolv.conf, and ndots, if the number of points in the current domain name is less than the set value, these values will be added to the domain name and parsed together when parsing, for example, the ndots is set to 4. The current domain name is servicecomb.cn-north-1.myhwclouds.com, only three points. Then the servicecomb.cn-north-1.myhwclouds.com.a will be automatically parsed when parsing, not parsed out. Servicecomb.cn-north-1.myhwclouds.com.b until it can be finally parsed\n\u00a0\u00a0optResourceEnabled: true #optional record is automatically included in DNS queries\n\u00a0\u00a0cacheMinTimeToLive: 0 #minimum cache time\n\u00a0\u00a0cacheMaxTimeToLive: 10000 #Maximum cache time\n\u00a0\u00a0cacheNegativeTimeToLive: 0 #DNS resolving failure time after the next retry\n\u00a0\u00a0queryTimeout: 5000 #Query timeout\n\u00a0\u00a0maxQueries: 4 #Query times\n\u00a0\u00a0rdFlag: true #Set DNS recursive query\n\u00a0\u00a0rotateServers: true #Set whether to support polling\n</code></pre>"},{"location":"general-development/dnsconfig/#example","title":"example","text":"<pre><code>VertxOptions vertxOptions = new VertxOptions();\nvertxOptions.setAddressResolverOptions(AddressResolverConfig.getAddressResover(\"self.tag\"));\nVertx vertx = VertxUtils.getOrCreateVertxByName(\"registry\", vertxOptions);\n// this has to set the client options\nHttpClientOptions httpClientOptions = createHttpClientOptions();\nClientPoolManager&lt;HttpClientWithContext&gt; clientMgr = new ClientPoolManager&lt;&gt;(vertx, new HttpClientPoolFactory(httpClientOptions));\nclientMgr.findThreadBindClientPool().runOnContext(httpClient -&gt; {\n\u00a0\u00a0\u00a0\u00a0// do some http request\n});\n</code></pre>"},{"location":"general-development/error-handling/","title":"Handle exceptions","text":"<p>ServiceComb has three categories of exceptions\uff1a * User Defined Exceptions\uff1aExceptions defined in API. These exceptions are generated to swagger.</p> <ul> <li>Control Messages Exceptions\uff1aMost of them are thrown by handlers. e.g. Flow control throws TOO_MANY_REQUESTS_STATUS.</li> </ul> <p><code>java   CommonExceptionData errorData = new CommonExceptionData(\"rejected by qps flowcontrol\");   asyncResp.producerFail(new InvocationException(QpsConst.TOO_MANY_REQUESTS_STATUS, errorData));</code></p> <ul> <li>Unknown Exceptions\uff1aUnkown exceptions may throw by service implementation like NullPointerException or network SocketException. These exceptions will be caught by ServiceComb and return 490, 590 like error code. e.g.</li> </ul> <p><code>java   CommonExceptionData errorData = new CommonExceptionData(cause.getMessage());   asyncResp.producerFail(new InvocationException(590, errorData)</code>   or   <code>java   asyncResp.consumerFail(new InvocationException(490, errorData)</code></p>"},{"location":"general-development/error-handling/#user-defined-exceptions","title":"User Defined Exceptions","text":"<p>Users can use @ApiResonse to define different types of exceptions. e.g.</p> <pre><code>  @Path(\"/errorCode\")\n  @POST\n  @ApiResponses({\n      @ApiResponse(code = 200, response = MultiResponse200.class, message = \"\"),\n      @ApiResponse(code = 400, response = MultiResponse400.class, message = \"\"),\n      @ApiResponse(code = 500, response = MultiResponse500.class, message = \"\")})\n  public MultiResponse200 errorCode(MultiRequest request) {\n    if (request.getCode() == 400) {\n      MultiResponse400 r = new MultiResponse400();\n      r.setCode(400);\n      r.setMessage(\"bad request\");\n      throw new InvocationException(javax.ws.rs.core.Response.Status.BAD_REQUEST, r);\n    } else if (request.getCode() == 500) {\n      MultiResponse500 r = new MultiResponse500();\n      r.setCode(500);\n      r.setMessage(\"internal error\");\n      throw new InvocationException(javax.ws.rs.core.Response.Status.INTERNAL_SERVER_ERROR, r);\n    } else {\n      MultiResponse200 r = new MultiResponse200();\n      r.setCode(200);\n      r.setMessage(\"success result\");\n      return r;\n    }\n  }\n</code></pre> <p>and client code know exception type.</p> <pre><code>    MultiRequest request = new MultiRequest();\n\n    request.setCode(200);\n    ResponseEntity&lt;MultiResponse200&gt; result = template\n        .postForEntity(SERVER + \"/MultiErrorCodeService/errorCode\", request, MultiResponse200.class);\n    TestMgr.check(result.getStatusCode(), 200);\n    TestMgr.check(result.getBody().getMessage(), \"success result\");\n\n    request.setCode(400);\n    MultiResponse400 t400 = null;\n    try {\n      template.postForEntity(SERVER + \"/MultiErrorCodeService/errorCode\", request, MultiResponse400.class);\n    } catch (InvocationException e) {\n      t400 = (MultiResponse400) e.getErrorData();\n    }\n    TestMgr.check(t400.getCode(), 400);\n    TestMgr.check(t400.getMessage(), \"bad request\");\n\n    request.setCode(500);\n    MultiResponse500 t500 = null;\n    try {\n      template.postForEntity(SERVER + \"/MultiErrorCodeService/errorCode\", request, MultiResponse400.class);\n    } catch (InvocationException e) {\n      t500 = (MultiResponse500) e.getErrorData();\n    }\n    TestMgr.check(t500.getCode(), 500);\n    TestMgr.check(t500.getMessage(), \"internal error\");\n</code></pre>"},{"location":"general-development/error-handling/#control-messages-exceptions","title":"Control Messages Exceptions","text":"<p>Control message exceptions not defined in swagger and the type is unknown for serializers. Client code use raw type to process it.</p> <pre><code>    JsonObject requestJson = new JsonObject();\n    requestJson.put(\"code\", 400);\n    requestJson.put(\"message\", \"test message\");\n\n    try {\n      template\n          .postForEntity(SERVER + \"/MultiErrorCodeService/noClientErrorCode\", requestJson, Object.class);\n    } catch (InvocationException e) {\n      TestMgr.check(e.getStatusCode(), 400);\n      mapResult = RestObjectMapperFactory.getRestObjectMapper().convertValue(e.getErrorData(), Map.class);\n      TestMgr.check(mapResult.get(\"message\"), \"test message\");\n      TestMgr.check(mapResult.get(\"code\"), 400);\n      TestMgr.check(mapResult.get(\"t400\"), 400);\n    }\n</code></pre> <p>The above code assume the type of exception data is unknown and convert it to map. Usually, ServiceComb throws its control messages exception with CommonExceptionData.</p>"},{"location":"general-development/error-handling/#unknown-exceptions","title":"Unknown Exceptions","text":"<p>Unknown exceptions are wrapped to 490 and 590 error code, and type is CommonExceptionData.</p>"},{"location":"general-development/error-handling/#customize-exceptions-type","title":"Customize exceptions type","text":"<p>We can define actual types for error code and convert one type of exception to another.</p> <ul> <li>define actual types for error code</li> </ul> <p>Define actual types for error code can make consumer code easier, and do not to use raw types. Users can implement a SPI interface org.apache.servicecomb.swagger.invocation.response.ResponseMetaMapper to specify the target exception type for specific error code.   ```java     private final static Map CODES = new HashMap&lt;&gt;(1); <pre><code>static {\n  ResponseMeta meta = new ResponseMeta();\n  meta.setJavaType(SimpleType.constructUnsafe(IllegalStateErrorData.class));\n  CODES.put(500, meta);\n}\n\n@Override\npublic Map&lt;Integer, ResponseMeta&gt; getMapper() {\n  return CODES;\n}\n</code></pre> <p>```</p> <ul> <li>convert one type of exception to another</li> </ul> <p>ServiceComb will serialize <code>InvocationException</code> data to response, and when the exception type is not <code>InvocationException</code>, a wrapped InvocationException with error code 490, 590 is created. Implement SPI interface <code>org.apache.servicecomb.swagger.invocation.exception.ExceptionToProducerResponseConverter</code> can convert one type of exception to another. Here is the description about <code>ExceptionToProducerResponseConverter</code>:   - the method <code>getExceptionClass()</code> indicates which type of exception this converter handles. The converter whose <code>getExceptionClass()</code> method returns <code>null</code> will be taken as default converter.   - in the method <code>Response convert(SwaggerInvocation swaggerInvocation, T e)</code>, the exception is processed and <code>Response</code> is returned. The returned <code>Response</code> determines the status code, resposne body of the HTTP response.   - the method <code>getOrder()</code> determines the priority of a converter. The less the returned value is, the higher the priority is. If the converter does not implement this method, the default return value is <code>0</code>. For a certain type of exception, only the converter with the highest priority will take effect.   - When an exception comes, the converters will be selected according to its type. If no converter is selected, then the type of its parent class is used to select the converter. Such process will continue until the <code>Throwable</code> type is used to select converter. If there is still no converter for this exception, the default converter will be selected to process this type of exception.</p> <p>```java   public class CustomExceptionToProducerResponseConverter implements ExceptionToProducerResponseConverter {     @Override     public Class getExceptionClass() {       // The return value indicates that this converter handles IllegalStateException       return IllegalStateException.class;     } <pre><code>@Override\npublic int getOrder() {\n  // The less the returned value is, the higher the priority is\n  return 100;\n}\n\n@Override\npublic Response convert(SwaggerInvocation swaggerInvocation, IllegalStateException e) {\n  // Here the exception is processed\n  IllegalStateErrorData data = new IllegalStateErrorData();\n  data.setId(500);\n  data.setMessage(e.getMessage());\n  data.setState(e.getMessage());\n  InvocationException state = new InvocationException(Status.INTERNAL_SERVER_ERROR, data);\n  return Response.failResp(state);\n}\n</code></pre> <p>}   ```</p>"},{"location":"general-development/file-download/","title":"File Downloading","text":"<p>File downloads are currently available in the vertx rest channel and servlet rest.</p>"},{"location":"general-development/file-download/#first-producer","title":"First, producer","text":""},{"location":"general-development/file-download/#1-download-normal-files","title":"1. Download normal files","text":"<pre><code>return new File(......);\n</code></pre>"},{"location":"general-development/file-download/#2-download-temporary-files","title":"2. Download temporary files","text":"<p>In this scenario, you need to create temporary files based on the request parameters dynamically. After the download is complete, you need to delete the temporary files.</p> <pre><code>return new FilePart(file).setDeleteAfterFinished(true);\n</code></pre>"},{"location":"general-development/file-download/#3-download-orgspringframeworkcoreioresource","title":"3. Download org.springframework.core.io.Resource","text":"<p>Because the resource does not necessarily mean file download, you need to identify this file download scenario by swagger annotation (@ApiResponse).</p> <p>Take ByteArrayResource as an example:</p> <pre><code>@GetMapping(path = \"/resource\")\n@ApiResponses({\n  @ApiResponse(code = 200, response = File.class, message = \"\")\n})\npublic Resource resource() {\n\u00a0\u00a0......\n  return new ByteArrayResource(bytes) {\n    @Override\n    public String getFilename() {\n      return \"resource.txt\";\n    }\n  };\n}\n</code></pre> <p>In the above example, because ByteArrayResource does not have the concept of a file name, you need to implement the resource's getFilename method, or you can wrap it with ResponseEntity:</p> <pre><code>@GetMapping(path = \"/resource\")\n@ApiResponses({\n  @ApiResponse(code = 200, response = File.class, message = \"\")\n})\npublic ResponseEntity&lt;Resource&gt; resource() {\n\u00a0\u00a0......\n  return ResponseEntity\n      .ok()\n      .header(HttpHeaders.CONTENT_TYPE, MediaType.TEXT_PLAIN_VALUE)\n      .header(HttpHeaders.CONTENT_DISPOSITION, \"attachment;filename=resource.txt\")\n      .body(resource);\n}\n</code></pre>"},{"location":"general-development/file-download/#4download-inputstream","title":"4.Download InputStream","text":"<p>Because InputStream does not mean file downloading for sure, it needs to be annotated by 'swagger annotation' (@ApiResponse). This is a file download scenario.</p> <p>In some scenarios, resources are not stored locally.</p> <pre><code>return ResponseEntity\n    .ok()\n    .header(HttpHeaders.CONTENT_TYPE, MediaType.TEXT_PLAIN_VALUE)\n    .header(HttpHeaders.CONTENT_DISPOSITION, \"attachment;filename=resource.txt\")\n    .body(stream);\n</code></pre> <p>After the download is complete, ServiceComb will automatically close the stream, and developers don't have to pay attention</p>"},{"location":"general-development/file-download/#5-file-type-determination","title":"5. File type determination","text":"<p>As long as the HttpHeaders.CONTENT_TYPE is not set directly via ResponseEntity, ServiceComb will try to automatically determine the file name suffix in File, Part, and Resource.</p> <p>ServiceComb uses java's mime type mechanism for file type determination. If the file suffix in the business scenario cannot be identified, ServiceComb will default to application/octet-stream.</p> <p>If this does not meet the requirements, assuming the file suffix is, and the expected file type is application/file-xyz, any of the following methods can be resolved:</p>"},{"location":"general-development/file-download/#1-extend-via-javas-mime-type-mechanism","title":"1) Extend via Java's mime type mechanism","text":"<p>In the META-INF directory, create a mime.  Types file with the contents:</p> <pre><code>application/file-xyz xyz\n</code></pre>"},{"location":"general-development/file-download/#2-specify-by-part-in-the-business-code","title":"2) Specify by Part in the business code","text":"<pre><code>return new FilePart(null, file).contentType(\"application/file-xyz\");\n</code></pre>"},{"location":"general-development/file-download/#3-specified-in-the-business-code-by-responseentity","title":"3) specified in the business code by ResponseEntity","text":"<pre><code>return ResponseEntity\n    .ok()\n    .header(HttpHeaders.CONTENT_TYPE, \"application/file-xyz\")\n    .body(\u2026\u2026);\n\u00a0\u00a0\u00a0\u00a0.body(...);\n</code></pre>"},{"location":"general-development/file-download/#6file-name","title":"6.File name","text":"<p>As long as HttpHeaders.CONTENT_DISPOSITION is not set directly via ResponseEntity, ServiceComb will try to generate HttpHeaders.CONTENT_DISPOSITION through the file names in File, Part, and Resource. Assuming the file name is file.txt, the generated data is as follows:</p> <pre><code>Content-Disposition: attachment;filename=file.txt;filename*=utf-8\u2019\u2019file.txt\n</code></pre> <p>Not only the filename is generated, but also filename* is generated. This is because if there is Chinese, space, and filename correctly in the file name, i.e., chrome is fine, but firefox directly treats the string after the encoding as a text. The name of the item is used directly. Firefox only decodes filename* according to [https://tools.ietf.org/html/rtf6266] (https://tools.ietf.org/html/rtf6266).</p> <p>If Content-Disposition is set directly in the business code, you need to handle the problems supported by multiple browsers.</p>"},{"location":"general-development/file-download/#second-consumer","title":"Second, Consumer","text":"<p>The consumer side uses org.apache.servicecomb.foundation.vertx.http.ReadStreamPart to process file downloads.</p>"},{"location":"general-development/file-download/#1-transparent-rpc","title":"1. Transparent RPC","text":"<pre><code>public interface ......{\n\u00a0\u00a0ReadStreamPart download1(...);\n\u00a0\u00a0ReadStreamPart download2(...);\n}\n</code></pre>"},{"location":"general-development/file-download/#2resttemplate","title":"2.RestTemplate","text":"<p>Take get as an example:</p> <pre><code>ReadStreamPart part = restTemplate.getForObject(url, ReadStreamPart.class);\n</code></pre>"},{"location":"general-development/file-download/#3-read-data-from-readstreampart","title":"3. Read data from ReadStreamPart","text":"<p>ReadStreamPart provides a set of methods to save the data stream as local data:</p> <pre><code>org.apache.servicecomb.foundation.vertx.http.ReadStreamPart.saveAsBytes()\norg.apache.servicecomb.foundation.vertx.http.ReadStreamPart.saveAsString()\norg.apache.servicecomb.foundation.vertx.http.ReadStreamPart.saveToFile(String)\norg.apache.servicecomb.foundation.vertx.http.ReadStreamPart.saveToFile(File, OpenOptions)\n</code></pre> <p>note:</p> <ul> <li> <p>When the ReadStreamPart instance is obtained, the file content is not downloaded. The save or other methods is called to start reading the file data from the network.</p> </li> <li> <p>If you use saveAsBytes, saveAsString, the data is directly stored in the memory; if the downloaded file is large, there will be a risk of memory explosion.</p> </li> <li> <p>The save series method returns all CompletableFuture objects:</p> </li> </ul> <p>* If you want to block waiting for the download to complete, you can use future.get() \u00a0\u00a0* If asynchronous callback processing is performed through future.whenComplete, be aware that callbacks occur in network threads, and you must follow the reactive thread rules.</p>"},{"location":"general-development/file-upload/","title":"File Uploading","text":"<p>File upload, currently supported in vertx rest channel and servlet rest.</p> <p>File uploads use the standard http form format, which can directly upload the file from the browser.</p>"},{"location":"general-development/file-upload/#producer","title":"Producer:","text":"<p>Support jaxrs and springmvc development mode</p> <p>Jaxrs development model: * javax.servlet.http.Part type that supports servlet definitions</p> <ul> <li>You can directly use @FormParam to pass file types and common parameters</li> </ul> <p>Springmvc development mode:</p> <ul> <li> <p>Supports servlet-defined javax.servlet.http.Part type, also supports org.springframework.web.multipart.MultipartFile type</p> </li> <li> <p>The two datatype functions are consistent, and MultipartFile is also base on Part type</p> </li> <li> <p>Two data types can be mixed, for example, the first parameter is Part and the second parameter is MultipartFile</p> </li> <li> <p>You can directly use @RequestPart to pass file types and common parameters</p> </li> </ul> <p>note:</p> <ul> <li> <p>First file upload temporary directory, the default is null does not support file upload, file upload request Content-Type must be multipart/form-data</p> </li> <li> <p>The same name parameter only supports one file</p> </li> <li> <p>Supports transferring files with multiple different parameter names at one time</p> </li> <li> <p>After opening the stream through MultipartFile or Part, remember to close it. Otherwise the uploaded temporary file will not be deleted, and eventually, the upload temporary directory will be exploded.</p> </li> </ul> <p>Sample code in Springmvc mode:</p> <pre><code>@PostMapping(path = \"/upload\", consumes = MediaType.MULTIPART_FORM_DATA)\npublic String fileUpload(@RequestPart(name = \"file1\") MultipartFile file1, @RequestPart(name = \"file2\") Part file2, @RequestPart String param1) {\n\u00a0\u00a0......\n}\n</code></pre>"},{"location":"general-development/file-upload/#configuration-instructions","title":"Configuration instructions:","text":"<p>| Configuration Item | Default Value | Range of Value | | :--- | :--- | :--- | :--- | | servicecomb.uploads.directory | null | | In which directory the uploaded temporary file is saved, default value null means file upload is not supported | | servicecomb.uploads.maxSize | -1 | | The maximum allowable size of http body in bytes. the default value of -1 means unlimited |</p>"},{"location":"general-development/file-upload/#consumer","title":"Consumer:","text":"<p>The following data types are supported:</p> <ul> <li> <p>java.io.File</p> </li> <li> <p>javax.servlet.http.Part</p> </li> <li> <p>java.io.InputStream</p> </li> <li> <p>org.springframework.core.io.Resource</p> </li> </ul> <p>When using InputStream, because it is a stream, there is no concept of client file name at this time, so the producer will get the client file name will get null.</p> <p>If you want to use both memory data and the producer to get the client file name, you can use the resource type, inherit org.springframework.core.io.ByteArrayResource, and override getFilename.</p>"},{"location":"general-development/file-upload/#transparent-rpc-code-sample","title":"Transparent RPC Code Sample:","text":"<pre><code>interface UploadIntf {\n  String upload(File file);\n}\n</code></pre> <p>After getting the interface reference, you can call it directly:</p> <pre><code>String result = uploadIntf.upload(file);\n</code></pre>"},{"location":"general-development/file-upload/#resttemplate-code-example","title":"RestTemplate code example:","text":"<pre><code>Map&lt;String, Object&gt; map = new HashMap&lt;&gt;();\nmap.put(\"file\", new FileSystemResource(\"a file path!\"));\nmap.put(\"param1\", \"test\");\nHttpHeaders headers = new HttpHeaders();\nheaders.setContentType(org.springframework.http.MediaType.MULTIPART_FORM_DATA);\nHttpEntity&lt;Map&lt;String, Object&gt;&gt; entry = new HttpEntity&lt;&gt;(map, headers);\n\nString reseult = template.postForObject(\n    url,\n    entry,\n    String.class);\n</code></pre>"},{"location":"general-development/http-filter/","title":"Http Filter","text":"<p>In some scenarios, the service uses http instead of https as the network transmission channel. To prevent the falsification or tampering request, consumer and the producer must be provided a method to signature the http stream.</p> <p>The signature method is carried using the org.apache.servicecomb.common.rest.filter.HttpClientFilter and org.apache.servicecomb.common.rest.filter.HttpServerFilter interfaces. It is recommended that the http stream related logic use the Filter mechanism here, and the contract The parameter related logic uses the Handler mechanism.</p> <p>About the use of the Filter interface, please reference [demo-signature] (https://github.com/ServiceComb/ServiceComb-Java-Chassis/tree/master/demo/demo-signature).</p>"},{"location":"general-development/http-filter/#1-overview","title":"1 Overview","text":"<p>The Filter mechanism is loaded using the Java standard SPI mechanism.</p> <p>Both HttpClientFilter and HttpServerFilter allow multiple loads:</p> <ul> <li> <p>The order of execution between instances is determined by the return value of getOrder</p> </li> <li> <p>If getOrder returns the same value, the corresponding instance order is randomly determined</p> </li> </ul> <p>Whether it is request or response, read the body stream, use getBodyBytes\\ (), the return value may be null (such as scenario of getting an invocation), if not null, the corresponding stream length, Obtain through getBodyBytesLength\\ (\\ ).</p> <p>Tips:  The beforeSendRequest of HttpClientFilter is executed in the current thread of the interface call, and the afterReceiveResponse is executed in the business thread pool.</p> <p>The afterReceiveRequest of HttpServerFilter is executed in the business thread pool, beforeSendResponse and beforeSendResponseAsync may be executed in the business thread pool or the network thread pool. Make sure that blocking operations can not occur.</p> <p>The bottom layer of Java Chassis is an asynchronous framework, with frequent thread switching. When the business extends Filter, if it involves obtaining the thread context through ThreadLocal, the acquisition may be empty. For this scenario, it is recommended to use InhritableThreadLocal instead of ThreadLocal to store data, or to use extended Handler instead of Filter.</p>"},{"location":"general-development/http-filter/#2httpclientfilter","title":"2.HttpClientFilter","text":"<p>The system has two built-in HttpClientFilter. Note that the order value does not conflict when extending the function:</p> <ul> <li> <p>org.apache.servicecomb.provider.springmvc.reference.RestTemplateCopyHeaderFilter, order value is Integer.MIN_VALUE</p> </li> <li> <p>org.apache.servicecomb.transport.rest.client.http.DefaultHttpClientFilter, order value is Integer.MAX_VALUE</p> </li> </ul>"},{"location":"general-development/http-filter/#21-prototype","title":"2.1 Prototype","text":"<pre><code>public interface HttpClientFilter {\n  int getOrder();\n\n  void beforeSendRequest(Invocation invocation, HttpServletRequestEx requestEx);\n\n  // if finished, then return a none null response\n  // if return a null response, then sdk will call next filter.afterReceive\n  Response afterReceiveResponse(Invocation invocation, HttpServletResponseEx responseEx);\n}\n</code></pre>"},{"location":"general-development/http-filter/#22-beforesendrequest","title":"2.2 beforeSendRequest","text":"<p>Used to send a request after the stream has been generated calculate the signature based on url, header, query, and stream then set to the header \\ (requestEx.setHeader).</p> <p>From the invocation, you can get the various metadata and the object parameters of this call (the stream is generated according to these parameters).</p>"},{"location":"general-development/http-filter/#23-afterreceiveresponse","title":"2.3 afterReceiveResponse","text":"<p>Used to calculate the signature according to the header and the stream after receiving the response from the network, and compare it with the signature in the header. If the signature is incorrect, directly construct a Response.</p> <p>As a return value, the framework will interrupt calls to other HttpClientFilters as long as it does not return NULL.</p>"},{"location":"general-development/http-filter/#3-httpserverfilter","title":"3 HttpServerFilter","text":""},{"location":"general-development/http-filter/#31-prototype","title":"3.1 Prototype","text":"<pre><code>public interface HttpServerFilter {\n  int getOrder();\n\n  default boolean needCacheRequest(OperationMeta operationMeta) {\n    return false;\n  }\n\n  // if finished, then return a none null response\n  // if return a null response, then sdk will call next filter.afterReceiveRequest\n  Response afterReceiveRequest(Invocation invocation, HttpServletRequestEx requestEx);\n\n  // invocation maybe null\n  void beforeSendResponse(Invocation invocation, HttpServletResponseEx responseEx);\n}\n</code></pre>"},{"location":"general-development/http-filter/#32-needcacherequest","title":"3.2 needCacheRequest","text":"<p>Unlike HttpClientFilter, the ability to decide whether to cache requests is added.</p> <p>This is because ServiceComb can not only run in standalone mode but also run in web container (such as Tomcat). In the implementation of a servlet, request stream can only be read once, and does not necessarily support reset (such as Tomcat), RESTful The framework needs to perform deserialization. It needs to read the body stream. The signature logic also needs to read the body stream. If the default processing is used, one of the functions cannot be implemented.</p> <p>So when running in a web container scenario, all HttpServerFilters, as long as there is a return request that needs to be cached, the body stream will be copied and saved to support repeated reads.</p> <p>The input parameter is the metadata corresponding to the request, and the service can decide whether the cache request is needed for the request.</p>"},{"location":"general-development/http-filter/#33-afterreceiverequest","title":"3.3 afterReceiveRequest","text":"<p>After receiving the request, the signature is calculated according to the URL, header, query, and code stream, and compared with the signature in the header. If the signature is incorrect, a Response is directly constructed as the return value. As long as the NULL is not returned, the framework will interrupt the other HttpClientFilter Call.</p>"},{"location":"general-development/http-filter/#34-beforesendresponse","title":"3.4 beforeSendResponse","text":"<p>Before sending a response, the signature is calculated according to the header and the stream and set to the header.</p> <p>Because the invocation has not yet been constructed, the call flow has gone wrong, so the invocation may be null.</p>"},{"location":"general-development/local-develop-test/","title":"Local Development and Test","text":""},{"location":"general-development/local-develop-test/#concept-description","title":"Concept Description","text":"<p>This section describes how developers can locally develop and commission consumer and provider applications. Both service providers and consumers need to connect to the remote service center. Two methods of building Local  ServiceCenter for local microservice commissioning are as follows:</p> <ul> <li> <p>Starting Local Service Center.</p> </li> <li> <p>Starting Local Service Center Mock mechanism.</p> </li> </ul>"},{"location":"general-development/local-develop-test/#local-debugging-by-setting-up-environmental-information","title":"Local debugging by setting up environmental information","text":"<p>The Service Center is an important component in the microservice architecture, this is used in managing and handle: registering and discovering, for service metadata and service instance metadata. The logic relationship between the service center and microservice provider/consumer is as follows:</p>"},{"location":"general-development/local-develop-test/#starting-local-servicecenter","title":"Starting Local ServiceCenter","text":"<ul> <li> <p>Step 1 Starting local service center</p> </li> <li> <p>run in executable files  </p> </li> </ul> <ul> <li>Windows</li> <li>Linux</li> </ul>  \u00a0\u00a0\u00a0 (1) Download the [Service Registry Executable Compressor] (http://apache.org/dyn/closer.cgi/incubator/servicecomb/incubator-servicecomb-service-center/1.0.0-m1/apache-servicecomb- Incubating-service-center-1.0.0-m1-windows-amd64.tar.gz)   \u00a0\u00a0\u00a0 (2) Extract to the current folder   \u00a0\u00a0\u00a0 (3) Go to the unzipped directory and double-click to run the **start-service-center.bat** file.    \u00a0\u00a0\u00a0\u00a0\u00a0   \u00a0\u00a0\u00a0 1) Download the Service Registry executable file archive and extract it      ```bash    wget http://apache.org/dyn/closer.cgi/incubator/servicecomb/incubator-servicecomb-service-center/1.0.0-m1/apache-servicecomb-incubating-service-center-1.0.0-m1-linux-amd64.tar.gz    tar xvf apache-servicecomb-incubating-service-center-1.0.0-m1-linux-amd64.tar.gz   ```   \u00a0\u00a0\u00a02) Run the service registry   \u00a0\u00a0\u00a0```bash \u00a0\u00a0\u00a0Bash apache-servicecomb-incubating-service-center-1.0.0-m1-linux-amd64/start-service-center.sh \u00a0\u00a0\u00a0```   \u00a0\u00a0\u00a0 \u00a0\u00a0\u00a0\u00a0Note: The frontend (frontend) will be bound to the ipv6 address by default in the Linux environment, causing the browser to report an error. The repair method is: first modify the httpaddr in conf/app.conf to the external reachable network card ip, and then modify the app/appList/apiList. .js `ip : 'http://127.0.0.1'` for the corresponding ip, and finally restart ServiceCenter. \u00a0\u00a0 \u00a0\u00a0\u00a0\u00a0 <p>Note: Both Windows and Linux versions only support 64-bit systems.  </p> <ol> <li>Run as Docker  </li> </ol> <p><code>bash Docker pull servicecomb/service-center Docker run -d -p 30100:30100 servicecomb/service-center:latest</code></p> <ul> <li>**Step 2 ** After starting the local service center, configure the ServerCenter address and port in the service provider/consumer's microservice.yaml file. Example code:</li> </ul> <p><code>yaml Servicecomb: \u00a0\u00a0Service: \u00a0\u00a0\u00a0\u00a0Registry: \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0Address: \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0#Service Center address and port \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0Http://127.0.0.1:30100</code></p> <ul> <li>Step 3 Development service provider/consumer, launch microservices for local testing.</li> </ul> <p>----End</p>"},{"location":"general-development/local-develop-test/#mock-mechanism-start-service-center","title":"Mock mechanism start service center","text":"<p>Simulate a service center that can only be used by this process in the process memory, which is generally used in the test scenario. * ### In-process call Just declare it before starting the ServiceComb engine to enable it:</p> <pre><code>System.setProperty(\"local.registry.file\", \"notExistJustForceLocal\");\n</code></pre> <ul> <li> <p>Step 1 Create a new local service center definition file, assuming the name is registry.yaml, the content example is as follows:  </p> </li> <li> <p>Step 1 Create a new local service center definition file, assuming the name is registry.yaml, the content example is as follows:</p> </li> </ul> <p><code>yaml localserv:   - id: \"100\"     version: \"0.0.1\"     appid: localservreg     schemaIds:       - hello     instances:       - endpoints:         - rest://localhost:8080         - highway://localhost:7070</code> * Step 2consumer local deployment contract file</p> <p>Reference: [Define Service Contract] (https://docs.servicecomb.io/java-chassis/zh_CN/build-provider/define-contract.html) * Step 3 In the consumer main function, declare the ServiceComb engine before starting:</p> <p><code>java \u3000\u3000System.setProperty(\"local.registry.file\", \"/path/registry.yaml\");</code></p> <p>The second parameter of setProperty fills in the absolute path of the registry.yaml system on the disk, pay attention to distinguish the corresponding path separator in different systems.</p>"},{"location":"general-development/local-develop-test/#cross-process-call","title":"Cross-process call","text":"<p>If the deployment is simple and the deployment information is static, you can use this mock mechanism even if you have a cross-process call. The producer end is still declared like \"in-process call\" However, because the Mock does not work across processes, the Mock on the consumer side needs to provide a local configuration file that describes the details of the call target, including the name, version, address, schema id, etc. Similarly, because the Mock cannot cross processes, the consumer cannot dynamically obtain the contract information of the producer. Therefore, the contract file needs to be provided locally. (This scenario, using the Mock Service Center, is much more costly than using a standalone service center, not recommended)</p>"},{"location":"general-development/local-develop-test/#local-debugging-by-setting-environment-information","title":"Local debugging by setting environment information","text":"<p>The java chassis is strictly dependent on the contract when designing, so usually the version of the microservice has to change when the contract updated. However, if the development mode is still in progress, it is normal to modify the interface.  If you need to change the version every time, it is very unfriendly to the user, so an environment setting is added for this case. If the microservice is configured as a development environment, the interface is modified (the schema has changed), and the restart can be registered to the service center without modifying the version number. However, if  consumer client has already called the service before the restart, the consumer client needs to be restarted to get the latest schema. For example, A -&gt; B, B interface has been modified and restarted, then A is still using B last schema at this time, the call may be wrong, so as to avoid unknown exceptions, A also needs to restart. There are three ways to set it up, Recommended method 1  </p> <ul> <li> <p>Method 1: Set by the JVM startup parameter  -Dservice_description.environment=development</p> </li> <li> <p>Method 2: Specify by microservice.yaml configuration file</p> </li> </ul> <pre><code>service_description:\n  environment: development\n</code></pre> <ul> <li>Method 3: Specify by environment variable (only for Windows system), such as the following settings under Eclipse </li> </ul>"},{"location":"general-development/metrics/","title":"First, the introduction of Metrics","text":"<ol> <li>Based on netflix spectator</li> <li>Foundation-metrics loads all MetricsInitializer implementations via the SPI mechanism. Implementers can use the getOrder in the MetricsInitializer to plan the execution order. The smaller the order number, the earlier it will be executed.</li> <li>Metrics-core implements 3 types of MetricsInitializer:</li> <li>DefaultRegistryInitializer: Instantiate and register spectator-reg-servo, set a smaller order, and ensure that it is executed before the following two types of MetricsInitializer</li> <li>Meters Initializer: Statistics of data such as TPS, delay, thread pool, jvm resources, etc.</li> <li>Publisher: Output statistics, built-in log output, and output via RESTful interface</li> <li>Metrics-prometheus provides the ability to interface with prometheus</li> </ol>"},{"location":"general-development/metrics/#second-how-to-use","title":"Second, how to use.","text":""},{"location":"general-development/metrics/#1maven-dependence","title":"1.Maven dependence.","text":"<pre><code>&lt;dependency&gt;\n  &lt;groupId&gt;org.apache.servicecomb&lt;/groupId&gt;\n  &lt;artifactId&gt;metrics-core&lt;/artifactId&gt;\n&lt;/dependency&gt;\n</code></pre> <p>If integrate with prometheus, also need to add dependencies.</p> <pre><code>&lt;dependency&gt;\n  &lt;groupId&gt;org.apache.servicecomb&lt;/groupId&gt;\n  &lt;artifactId&gt;metrics-prometheus&lt;/artifactId&gt;\n&lt;/dependency&gt;\n</code></pre> <p>Note: Please change the version field to the actual version number; if the version number has been declared in the dependencyManagement, then you do not have to write the version number here</p>"},{"location":"general-development/metrics/#2-configuration-instructions","title":"2. Configuration instructions","text":"Configuration Item Default Meaning servicecomb.metrics.window_time 60000 Statistical period, in millisecondsTPS, delay, etc. Periodic data, updated once per cycle, the value obtained in the cycle, actually the value of the previous cycle servicecomb.metrics.invocation.latencyDistribution The latency distribution time period definition in millisecondsfor example:0,1,10,100,1000indicates that the following latency scopes are defined: [0, 1),[1, 10),[10, 100),[100, 1000),[1000, ) servicecomb.metrics.Consumer.invocation.slow.enabled false Whether to enable slow call detection on the Consumer sideLevel 4 priority definitions can be supported by adding the suffix .${service}.${schema}.${operation} servicecomb.metrics.Consumer.invocation.slow.msTime 1000 If the latency exceeds the configured value, the log will be output immediately, and the time consumption information of the stage called this time will be recorded.Level 4 priority definitions can be supported by adding the suffix .${service}.${schema}.${operation} servicecomb.metrics.Provider.invocation.slow.enabled false Whether to enable slow call detection on the Provider sideLevel 4 priority definitions can be supported by adding the suffix .${service}.${schema}.${operation} servicecomb.metrics.Provider.invocation.slow.msTime 1000 If the latency exceeds the configured value, the log will be output immediately, and the time consumption information of the stage called this time will be recorded.Level 4 priority definitions can be supported by adding the suffix .${service}.${schema}.${operation} servicecomb.metrics.prometheus.address 0.0.0.0:9696 prometheus listen address servicecomb.metrics.publisher.defaultLog.enabled false Whether to output the default statistics log servicecomb.metrics.publisher.defaultLog.endpoints.client.detail.enabled false Whether to output each client endpoint statistics log, because it is related to the target ip:port number, there may be a lot of data, so the default is not output"},{"location":"general-development/metrics/#3-slow-call-detection","title":"3. Slow call detection","text":"<p>After slow call detection is enabled, if there is a slow call, the corresponding log will be output immediately:</p> <pre><code>2019-04-02 23:01:09,103\\[WARN]\\[pool-7-thread-74]\\[5ca37935c00ff2c7-350076] - slow(40 ms) invocation, CONSUMER highway perf1.impl.syncQuery\n  http method: GET\n  url        : /v1/syncQuery/{id}/\n  server     : highway://192.168.0.152:7070?login=true\n  status code: 200\n  total      : 50.760 ms\n    prepare                : 0.0 ms\n    handlers request       : 0.0 ms\n    client filters request : 0.0 ms\n    send request           : 0.5 ms\n    get connection         : 0.0 ms\n    write to buf           : 0.5 ms\n    wait response          : 50.727 ms\n    wake consumer          : 0.23 ms\n    client filters response: 0.2 ms\n    handlers response      : 0.0 ms (SlowInvocationLogger.java:121)\n</code></pre> <p>Where 5ca37935c00ff2c7-350076 is the structure of ${traceId}-${invocationId}, referenced by %marker in the output format of log4j2 or logback</p>"},{"location":"general-development/metrics/#4-access-via-restful","title":"4. Access via RESTful","text":"<p>As long as the microservices open the rest port, use a browser to access http://ip:port/metrics. will get json data in the following format:</p> <pre><code>{\n  \"servicecomb.vertx.endpoints(address=192.168.0.124:7070,statistic=connectCount,type=client)\": 0.0,\n  \"servicecomb.vertx.endpoints(address=192.168.0.124:7070,statistic=disconnectCount,type=client)\": 0.0,\n  \"servicecomb.vertx.endpoints(address=192.168.0.124:7070,statistic=connections,type=client)\": 1.0,\n  \"servicecomb.vertx.endpoints(address=192.168.0.124:7070,statistic=bytesRead,type=client)\": 508011.0,\n  \"servicecomb.vertx.endpoints(address=192.168.0.124:7070,statistic=bytesWritten,type=client)\": 542163.0,\n  \"servicecomb.vertx.endpoints(address=192.168.0.124:7070,statistic=queueCount,type=client)\": 0.0,\n\n  \"servicecomb.vertx.endpoints(address=0.0.0.0:7070,statistic=connectCount,type=server)\": 0.0,\n  \"servicecomb.vertx.endpoints(address=0.0.0.0:7070,statistic=disconnectCount,type=server)\": 0.0,\n  \"servicecomb.vertx.endpoints(address=0.0.0.0:7070,statistic=connections,type=server)\": 1.0,\n  \"servicecomb.vertx.endpoints(address=0.0.0.0:7070,statistic=bytesRead,type=server)\": 542163.0,\n  \"servicecomb.vertx.endpoints(address=0.0.0.0:7070,statistic=bytesWritten,type=server)\": 508011.0,\n  \"servicecomb.vertx.endpoints(address=0.0.0.0:7070,statistic=rejectByConnectionLimit,type=server)\": 0.0,\n  \"servicecomb.vertx.endpoints(address=localhost:8080,statistic=connectCount,type=server)\": 0.0,\n  \"servicecomb.vertx.endpoints(address=localhost:8080,statistic=disconnectCount,type=server)\": 0.0,\n  \"servicecomb.vertx.endpoints(address=localhost:8080,statistic=connections,type=server)\": 0.0,\n  \"servicecomb.vertx.endpoints(address=localhost:8080,statistic=bytesRead,type=server)\": 0.0,\n  \"servicecomb.vertx.endpoints(address=localhost:8080,statistic=bytesWritten,type=server)\": 0.0,\n  \"servicecomb.vertx.endpoints(address=localhost:8080,statistic=rejectByConnectionLimit,type=server)\": 0.0,\n\n  \"threadpool.completedTaskCount(id=cse.executor.groupThreadPool-group0)\": 4320.0,\n  \"threadpool.rejectedCount(id=cse.executor.groupThreadPool-group0)\": 0.0,\n  \"threadpool.taskCount(id=cse.executor.groupThreadPool-group0)\": 4320.0,\n  \"threadpool.currentThreadsBusy(id=cse.executor.groupThreadPool-group0)\": 0.0,\n  \"threadpool.poolSize(id=cse.executor.groupThreadPool-group0)\": 4.0,\n  \"threadpool.maxThreads(id=cse.executor.groupThreadPool-group0)\": 10.0,\n  \"threadpool.queueSize(id=cse.executor.groupThreadPool-group0)\": 0.0,\n  \"threadpool.corePoolSize(id=cse.executor.groupThreadPool-group0)\": 4.0,\n\n  \"servicecomb.invocation(operation=perf1.impl.syncQuery,role=CONSUMER,scope=[0,1),status=200,transport=highway,type=latencyDistribution)\": 4269.0,\n  \"servicecomb.invocation(operation=perf1.impl.syncQuery,role=CONSUMER,scope=[1,3),status=200,transport=highway,type=latencyDistribution)\": 0.0,\n  \"servicecomb.invocation(operation=perf1.impl.syncQuery,role=CONSUMER,scope=[3,10),status=200,transport=highway,type=latencyDistribution)\": 0.0,\n  \"servicecomb.invocation(operation=perf1.impl.syncQuery,role=CONSUMER,scope=[10,100),status=200,transport=highway,type=latencyDistribution)\": 0.0,\n  \"servicecomb.invocation(operation=perf1.impl.syncQuery,role=CONSUMER,scope=[100,),status=200,transport=highway,type=latencyDistribution)\": 0.0,\n\n  \"servicecomb.invocation(operation=perf1.impl.syncQuery,role=PRODUCER,scope=[0,1),status=200,transport=highway,type=latencyDistribution)\": 4269.0,\n  \"servicecomb.invocation(operation=perf1.impl.syncQuery,role=PRODUCER,scope=[1,3),status=200,transport=highway,type=latencyDistribution)\": 0.0,\n  \"servicecomb.invocation(operation=perf1.impl.syncQuery,role=PRODUCER,scope=[3,10),status=200,transport=highway,type=latencyDistribution)\": 0.0,\n  \"servicecomb.invocation(operation=perf1.impl.syncQuery,role=PRODUCER,scope=[10,100),status=200,transport=highway,type=latencyDistribution)\": 0.0,\n  \"servicecomb.invocation(operation=perf1.impl.syncQuery,role=PRODUCER,scope=[100,),status=200,transport=highway,type=latencyDistribution)\": 0.0,\n\n  \"servicecomb.invocation(operation=perf1.impl.syncQuery,role=PRODUCER,stage=total,statistic=count,status=200,transport=highway,type=stage)\": 4269.0,\n  \"servicecomb.invocation(operation=perf1.impl.syncQuery,role=PRODUCER,stage=total,statistic=totalTime,status=200,transport=highway,type=stage)\": 0.25269420000000004,\n  \"servicecomb.invocation(operation=perf1.impl.syncQuery,role=PRODUCER,stage=total,statistic=max,status=200,transport=highway,type=stage)\": 2.7110000000000003E-4,\n  \"servicecomb.invocation(operation=perf1.impl.syncQuery,role=PRODUCER,stage=handlers_request,statistic=count,status=200,transport=highway,type=stage)\": 4269.0,\n  \"servicecomb.invocation(operation=perf1.impl.syncQuery,role=PRODUCER,stage=handlers_request,statistic=totalTime,status=200,transport=highway,type=stage)\": 0.0079627,\n  \"servicecomb.invocation(operation=perf1.impl.syncQuery,role=PRODUCER,stage=handlers_request,statistic=max,status=200,transport=highway,type=stage)\": 1.74E-5,\n  \"servicecomb.invocation(operation=perf1.impl.syncQuery,role=PRODUCER,stage=handlers_response,statistic=count,status=200,transport=highway,type=stage)\": 4269.0,\n  \"servicecomb.invocation(operation=perf1.impl.syncQuery,role=PRODUCER,stage=handlers_response,statistic=totalTime,status=200,transport=highway,type=stage)\": 0.0060666,\n  \"servicecomb.invocation(operation=perf1.impl.syncQuery,role=PRODUCER,stage=handlers_response,statistic=max,status=200,transport=highway,type=stage)\": 1.08E-5,\n  \"servicecomb.invocation(operation=perf1.impl.syncQuery,role=PRODUCER,stage=prepare,statistic=count,status=200,transport=highway,type=stage)\": 4269.0,\n  \"servicecomb.invocation(operation=perf1.impl.syncQuery,role=PRODUCER,stage=prepare,statistic=totalTime,status=200,transport=highway,type=stage)\": 0.016679600000000003,\n  \"servicecomb.invocation(operation=perf1.impl.syncQuery,role=PRODUCER,stage=prepare,statistic=max,status=200,transport=highway,type=stage)\": 2.68E-5,\n  \"servicecomb.invocation(operation=perf1.impl.syncQuery,role=PRODUCER,stage=queue,statistic=count,status=200,transport=highway,type=stage)\": 4269.0,\n  \"servicecomb.invocation(operation=perf1.impl.syncQuery,role=PRODUCER,stage=queue,statistic=totalTime,status=200,transport=highway,type=stage)\": 0.08155480000000001,\n  \"servicecomb.invocation(operation=perf1.impl.syncQuery,role=PRODUCER,stage=queue,statistic=max,status=200,transport=highway,type=stage)\": 2.1470000000000001E-4,\n  \"servicecomb.invocation(operation=perf1.impl.syncQuery,role=PRODUCER,stage=execution,statistic=count,status=200,transport=highway,type=stage)\": 4269.0,\n  \"servicecomb.invocation(operation=perf1.impl.syncQuery,role=PRODUCER,stage=execution,statistic=totalTime,status=200,transport=highway,type=stage)\": 0.0098285,\n  \"servicecomb.invocation(operation=perf1.impl.syncQuery,role=PRODUCER,stage=execution,statistic=max,status=200,transport=highway,type=stage)\": 4.3100000000000004E-5,\n  \"servicecomb.invocation(operation=perf1.impl.syncQuery,role=PRODUCER,stage=server_filters_request,statistic=count,status=200,transport=highway,type=stage)\": 4269.0,\n  \"servicecomb.invocation(operation=perf1.impl.syncQuery,role=PRODUCER,stage=server_filters_request,statistic=totalTime,status=200,transport=highway,type=stage)\": 0.0170669,\n  \"servicecomb.invocation(operation=perf1.impl.syncQuery,role=PRODUCER,stage=server_filters_request,statistic=max,status=200,transport=highway,type=stage)\": 3.6400000000000004E-5,\n  \"servicecomb.invocation(operation=perf1.impl.syncQuery,role=PRODUCER,stage=server_filters_response,statistic=count,status=200,transport=highway,type=stage)\": 4269.0,\n  \"servicecomb.invocation(operation=perf1.impl.syncQuery,role=PRODUCER,stage=server_filters_response,statistic=totalTime,status=200,transport=highway,type=stage)\": 0.0196985,\n  \"servicecomb.invocation(operation=perf1.impl.syncQuery,role=PRODUCER,stage=server_filters_response,statistic=max,status=200,transport=highway,type=stage)\": 4.8100000000000004E-5,\n  \"servicecomb.invocation(operation=perf1.impl.syncQuery,role=PRODUCER,stage=producer_send_response,statistic=count,status=200,transport=highway,type=stage)\": 4269.0,\n  \"servicecomb.invocation(operation=perf1.impl.syncQuery,role=PRODUCER,stage=producer_send_response,statistic=totalTime,status=200,transport=highway,type=stage)\": 0.0880885,\n  \"servicecomb.invocation(operation=perf1.impl.syncQuery,role=PRODUCER,stage=producer_send_response,statistic=max,status=200,transport=highway,type=stage)\": 1.049E-4,\n  \"servicecomb.invocation(operation=perf1.impl.syncQuery,role=CONSUMER,stage=total,statistic=count,status=200,transport=highway,type=stage)\": 4269.0,\n  \"servicecomb.invocation(operation=perf1.impl.syncQuery,role=CONSUMER,stage=total,statistic=totalTime,status=200,transport=highway,type=stage)\": 0.9796976000000001,\n  \"servicecomb.invocation(operation=perf1.impl.syncQuery,role=CONSUMER,stage=total,statistic=max,status=200,transport=highway,type=stage)\": 6.720000000000001E-4,\n  \"servicecomb.invocation(operation=perf1.impl.syncQuery,role=CONSUMER,stage=handlers_request,statistic=count,status=200,transport=highway,type=stage)\": 4269.0,\n  \"servicecomb.invocation(operation=perf1.impl.syncQuery,role=CONSUMER,stage=handlers_request,statistic=totalTime,status=200,transport=highway,type=stage)\": 0.012601500000000002,\n  \"servicecomb.invocation(operation=perf1.impl.syncQuery,role=CONSUMER,stage=handlers_request,statistic=max,status=200,transport=highway,type=stage)\": 3.5000000000000004E-5,\n  \"servicecomb.invocation(operation=perf1.impl.syncQuery,role=CONSUMER,stage=handlers_response,statistic=count,status=200,transport=highway,type=stage)\": 4269.0,\n  \"servicecomb.invocation(operation=perf1.impl.syncQuery,role=CONSUMER,stage=handlers_response,statistic=totalTime,status=200,transport=highway,type=stage)\": 0.0066785,\n  \"servicecomb.invocation(operation=perf1.impl.syncQuery,role=CONSUMER,stage=handlers_response,statistic=max,status=200,transport=highway,type=stage)\": 3.21E-5,\n  \"servicecomb.invocation(operation=perf1.impl.syncQuery,role=CONSUMER,stage=prepare,statistic=count,status=200,transport=highway,type=stage)\": 4269.0,\n  \"servicecomb.invocation(operation=perf1.impl.syncQuery,role=CONSUMER,stage=prepare,statistic=totalTime,status=200,transport=highway,type=stage)\": 0.010363800000000001,\n  \"servicecomb.invocation(operation=perf1.impl.syncQuery,role=CONSUMER,stage=prepare,statistic=max,status=200,transport=highway,type=stage)\": 2.85E-5,\n  \"servicecomb.invocation(operation=perf1.impl.syncQuery,role=CONSUMER,stage=client_filters_request,statistic=count,status=200,transport=highway,type=stage)\": 4269.0,\n  \"servicecomb.invocation(operation=perf1.impl.syncQuery,role=CONSUMER,stage=client_filters_request,statistic=totalTime,status=200,transport=highway,type=stage)\": 0.0060282,\n  \"servicecomb.invocation(operation=perf1.impl.syncQuery,role=CONSUMER,stage=client_filters_request,statistic=max,status=200,transport=highway,type=stage)\": 9.2E-6,\n  \"servicecomb.invocation(operation=perf1.impl.syncQuery,role=CONSUMER,stage=consumer_send_request,statistic=count,status=200,transport=highway,type=stage)\": 4269.0,\n  \"servicecomb.invocation(operation=perf1.impl.syncQuery,role=CONSUMER,stage=consumer_send_request,statistic=totalTime,status=200,transport=highway,type=stage)\": 0.099984,\n  \"servicecomb.invocation(operation=perf1.impl.syncQuery,role=CONSUMER,stage=consumer_send_request,statistic=max,status=200,transport=highway,type=stage)\": 1.1740000000000001E-4,\n  \"servicecomb.invocation(operation=perf1.impl.syncQuery,role=CONSUMER,stage=consumer_get_connection,statistic=count,status=200,transport=highway,type=stage)\": 4269.0,\n  \"servicecomb.invocation(operation=perf1.impl.syncQuery,role=CONSUMER,stage=consumer_get_connection,statistic=totalTime,status=200,transport=highway,type=stage)\": 0.006916800000000001,\n  \"servicecomb.invocation(operation=perf1.impl.syncQuery,role=CONSUMER,stage=consumer_get_connection,statistic=max,status=200,transport=highway,type=stage)\": 5.83E-5,\n  \"servicecomb.invocation(operation=perf1.impl.syncQuery,role=CONSUMER,stage=consumer_write_to_buf,statistic=count,status=200,transport=highway,type=stage)\": 4269.0,\n  \"servicecomb.invocation(operation=perf1.impl.syncQuery,role=CONSUMER,stage=consumer_write_to_buf,statistic=totalTime,status=200,transport=highway,type=stage)\": 0.0930672,\n  \"servicecomb.invocation(operation=perf1.impl.syncQuery,role=CONSUMER,stage=consumer_write_to_buf,statistic=max,status=200,transport=highway,type=stage)\": 1.1580000000000001E-4,\n  \"servicecomb.invocation(operation=perf1.impl.syncQuery,role=CONSUMER,stage=consumer_wait_response,statistic=count,status=200,transport=highway,type=stage)\": 4269.0,\n  \"servicecomb.invocation(operation=perf1.impl.syncQuery,role=CONSUMER,stage=consumer_wait_response,statistic=totalTime,status=200,transport=highway,type=stage)\": 0.7654931,\n  \"servicecomb.invocation(operation=perf1.impl.syncQuery,role=CONSUMER,stage=consumer_wait_response,statistic=max,status=200,transport=highway,type=stage)\": 5.547E-4,\n  \"servicecomb.invocation(operation=perf1.impl.syncQuery,role=CONSUMER,stage=consumer_wake_consumer,statistic=count,status=200,transport=highway,type=stage)\": 4269.0,\n  \"servicecomb.invocation(operation=perf1.impl.syncQuery,role=CONSUMER,stage=consumer_wake_consumer,statistic=totalTime,status=200,transport=highway,type=stage)\": 0.0502085,\n  \"servicecomb.invocation(operation=perf1.impl.syncQuery,role=CONSUMER,stage=consumer_wake_consumer,statistic=max,status=200,transport=highway,type=stage)\": 3.7370000000000003E-4,\n  \"servicecomb.invocation(operation=perf1.impl.syncQuery,role=CONSUMER,stage=client_filters_response,statistic=count,status=200,transport=highway,type=stage)\": 4269.0,\n  \"servicecomb.invocation(operation=perf1.impl.syncQuery,role=CONSUMER,stage=client_filters_response,statistic=totalTime,status=200,transport=highway,type=stage)\": 0.0227188,\n  \"servicecomb.invocation(operation=perf1.impl.syncQuery,role=CONSUMER,stage=client_filters_response,statistic=max,status=200,transport=highway,type=stage)\": 4.0E-5\n}\n</code></pre>"},{"location":"general-development/metrics/#third-the-summary-of-statistical-items","title":"Third, the summary of statistical items","text":""},{"location":"general-development/metrics/#1-cpu","title":"1. CPU","text":"Name Tag keys Tag values Description os type cpu System CPU usage in the current period, Solaris mode processCpu Microservice process CPU usage in the current period, IRIX mode         processCpu divided by cpu is equal to the number of system CPUs"},{"location":"general-development/metrics/#2-net","title":"2. NET","text":"Name Tag keys Tag values Description os type net statistic send Average number of bytes sent per second during the current period (Bps) receive Average number of bytes received per second during the current period (Bps) sendPackets Average number of packets sent per second (pps) during the current period receivePackets Average number of packets received per second (pps) during the current period interface net dev name"},{"location":"general-development/metrics/#3-vertx-client-endpoints","title":"3. vertx client endpoints","text":"Name Tag keys Tag values Description servicecomb.vertx.endpoints type client address ${ip}:${port} server ip:port statistic connectCount Number of connections have been initiated in the current period disconnectCount Number of disconnections in the current period queueCount The number of requests in the http connection pool that are waiting to get a connection connections Current connection number bytesRead Average number of bytes received per second during the current period (Bps)         Business layer statistics, relative to the data obtained from the network card, the data here does not include the size of the header         For http messages, does not include http header size bytesWritten Average number of bytes sent per second during the current period (Bps)         Business layer statistics, relative to the data obtained from the network card, the data here does not include the size of the header         For http messages, does not include http header size"},{"location":"general-development/metrics/#4-vertx-server-endpoints","title":"4. vertx server endpoints","text":"Name Tag keys Tag values Description servicecomb.vertx.endpoints type server address ${ip}:${port} listen ip:port statistic connectCount Number of connections are connected in the current period disconnectCount Number of disconnections in the current period rejectByConnectionLimit Number of active disconnections due to exceeding the number of connections in the current period connections Current connection number bytesRead Average number of bytes sent per second during the current period (Bps)         Business layer statistics, relative to the data obtained from the network card, the data here does not include the size of the header         For http messages, does not include http header size bytesWritten Average number of bytes received per second during the current period (Bps)         Business layer statistics, relative to the data obtained from the network card, the data here does not include the size of the header         For http messages, does not include http header size"},{"location":"general-development/metrics/#5-invocation-latency-distribution","title":"5. Invocation latency distribution","text":"Name Tag keys Tag values Description servicecomb.invocation role CONSUMER\u3001PRODUCER\u3001EDGE Is the CONSUMER, PRODUCER or EDGE side statistics operation ${microserviceName}.${schemaId}.${operationName} Method name called transport highway or rest On which transmission channel the call is made status http status code type latencyDistribution invocation latency distribution scope [${min}, ${max}) The call count in the current period that latency is greater than or equal to min, less than max         [${min},) means max is infinite"},{"location":"general-development/metrics/#6-invocation-consumer-stage-latency","title":"6. invocation consumer stage latency","text":"Name Tag keys Tag values Description servicecomb.invocation role CONSUMER Statistics on the CONSUMER side operation ${microserviceName}.${schemaId}.${operationName} Method name called transport highway or rest On which transmission channel the call is made status http status code type stage stage latency stage total The whole process prepare handlers_request Handler chain request process client_filters_request Http client filter chain request process         Only the rest transport has this stage. consumer_send_request Send request stage, including consumer_get_connection and consumer_write_to_buf consumer_get_connection Get a connection from the connection pool consumer_write_to_buf Write data to the network buffer consumer_wait_response Waiting for the server to answer consumer_wake_consumer In the synchronization process, after receiving the response, it takes time from waking up the waiting thread to waiting for the thread to start processing the response. client_filters_response Http client filter chain response process handlers_response Handler chain response process statistic count Average number of calls per second (TPS)         Count=Number of calls/period in the statistical period (seconds) totalTime In seconds         totalTime=The total duration of the call in the current period (seconds)         totalTime divided by count to get the average latency max In seconds         Maximum latency in the current period"},{"location":"general-development/metrics/#7-invocation-producer-stage-latency","title":"7. invocation producer stage latency","text":"Name Tag keys Tag values Description servicecomb.invocation role PRODUCER Statistics on the PRODUCER side operation ${microserviceName}.${schemaId}.${operationName} Method name called transport highway or rest On which transmission channel the call is made status http status code type stage stage latency stage total The whole process prepare queue Meaning only when using a thread pool         Indicates the length of time the call is queued in the thread pool server_filters_request Http server filter chain request process         Only the rest transport has this stage. handlers_request Handler chain request process execution Business method handlers_response Handler chain response process server_filters_response Http server filter chain response process producer_send_response Send a response statistic count Average number of calls per second (TPS)         Count=Number of calls/period in the statistical period (seconds) totalTime In seconds         totalTime=The total duration of the call in the current period (seconds)         AverageTime divided by count to get the average latency max In seconds         Maximum latency in the current period"},{"location":"general-development/metrics/#8-invocation-edge-stage-latency","title":"8. invocation edge stage latency","text":"Name Tag keys Tag values Description servicecomb.invocation role EDGE EDGE statistics operation ${microserviceName}.${schemaId}.${operationName} Method name called transport highway or rest On which transmission channel the call is made status http status code type stage stage latency stage total The whole process prepare queue Meaning only when using a thread pool         Indicates the length of time the call is queued in the thread pool server_filters_request Http server filter chain request process handlers_request Handler chain request process client_filters_request Http client filter chain request process consumer_send_request Send request stage, including consumer_get_connection and consumer_write_to_buf consumer_get_connection Get a connection from the connection pool consumer_write_to_buf Write data to the network buffer consumer_wait_response Waiting for the server to answer consumer_wake_consumer In the synchronization process, after receiving the response, it takes time from waking up the waiting thread to waiting for the thread to start processing the response. client_filters_response Http client filter chain response process handlers_response Handler chain response process server_filters_response Http server filter chain response process producer_send_response Send a response statistic count Average number of calls per second (TPS)         Count=Number of calls/period in the statistical period (seconds) totalTime In seconds         totalTime=The total duration of the call in the current period (seconds)         AverageTime divided by count to get the average latency max In seconds         Maximum latency in the current period"},{"location":"general-development/metrics/#9-threadpool","title":"9. threadpool","text":"Name Tag keys Tag values Description threadpool.corePoolSize   id ${threadPoolName} Minimum number of threads threadpool.maxThreads  Maximum number of threads allowed threadpool.poolSize  Current actual number of threads threadpool.currentThreadsBusy  The current number of active threads, which is the number of tasks currently being executed threadpool.queueSize  Number of tasks currently queued threadpool.rejectedCount  The average number of tasks rejected per second during the current period threadpool.taskCount Average number of tasks submitted per second during the statistical period         taskCount=(completed + queue + active)/period (seconds) threadpool.completedTaskCount  The average number of tasks completed per second during the statistical period         completedTaskCount=completed/period (seconds)"},{"location":"general-development/metrics/#fourth-business-customization","title":"Fourth, business customization","text":"<p>Because ServiceComb has initialized the registry's registry, the business no longer has to create a registry.</p> <p>Implement the MetricsInitializer interface, define the business-level Meters, or implement a custom Publisher, and then declare your implementation through the SPI mechanism.</p>"},{"location":"general-development/metrics/#1meters","title":"1.Meters:","text":"<p>Creating Meters capabilities is provided by spectator, available in the [netflix spectator] (https://github.com/Netflix/spectator) documentation</p>"},{"location":"general-development/metrics/#2publisher","title":"2.Publisher:","text":"<p>Periodically output scenarios, such as log scenarios, subscribe to org.apache.servicecomb.foundation.metrics.PolledEvent via eventBus, PolledEvent.getMeters() is the statistical result of this cycle. Non-periodic output scenarios, such as access through the RESTful interface, the statistical results of this cycle can be obtained through globalRegistry.iterator()</p>"},{"location":"general-development/microservice-invocation-chain/","title":"Microservice invocation chain","text":""},{"location":"general-development/microservice-invocation-chain/#concept-description","title":"Concept Description","text":"<p>The microservices architecture solves the problems of many single applications, but it also requires us to pay extra. Request processing latency due to network instability is one of the costs.</p> <p>In a single application, all modules run in the same process, so there is no inter-module interworking problem. However, in the micro-service architecture, services communicate through the network, so we have to deal with network-related issues such as delays, timeouts, network partitions, and so on.</p> <p>Also, as the business expands its services, it is difficult to see how data flows through a spider-like complex service structure. How can we effectively monitor network latency and visualize data flow in services?</p> <p>Distributed Call Chain Tracking is used to monitor network latency for microservices effectively and visualize data flow in microservices.</p>"},{"location":"general-development/microservice-invocation-chain/#zipkin","title":"Zipkin","text":"<p>[Zipkin] (http://zipkin.io/) is a distributed call chain tracking system. It helps users collect time series data to locate latency issues in microservices, and it also manages the collection and query of trace data. Zipkin's design is based on Google [Dapper paper] (http://research.google.com/pubs/pub36356.html).</p> <p>ServiceComb integrates Zipkin to provide automatic call chain tracking capabilities so that users only need to focus on their business needs.</p>"},{"location":"general-development/microservice-invocation-chain/#steps-for-usage","title":"Steps for usage:","text":""},{"location":"general-development/microservice-invocation-chain/#adding-dependencies","title":"Adding dependencies","text":"<p>Microservices based on ServiceComb Java Chassis only need to add the following dependency to pom.xml:</p> <pre><code>&lt;dependency&gt;\n    &lt;groupId&gt;org.apache.servicecomb&lt;/groupId&gt;\n    &lt;artifactId&gt;handler-tracing-zipkin&lt;/artifactId&gt;\n&lt;/dependency&gt;\n</code></pre> <p>If the microservice is based on Spring Cloud + Zuul's API gateway, such as the manager service in the workshop demo, we also need to add the following additional dependencies:</p> <pre><code>&lt;dependency&gt;\n    &lt;groupId&gt;org.apache.servicecomb&lt;/groupId&gt;\n    &lt;artifactId&gt;spring-cloud-zuul-zipkin&lt;/artifactId&gt;\n&lt;/dependency&gt;\n</code></pre>"},{"location":"general-development/microservice-invocation-chain/#configuring-tracking-processing-and-data-collection-configuration-tracking-processing-and-data-collection","title":"Configuring Tracking Processing and Data Collection {#Configuration Tracking Processing and Data Collection}","text":"<p>Set the tracking processor and data collection service address in the microservice.yaml file</p> <pre><code>  servicecomb:\n    handler:\n      chain:\n        Consumer:\n          default: tracing-consumer\n        Provider:\n          default: tracing-provider\n  servicecomb:\n    tracing:\n      collector:\n        address: http://zipkin.servicecomb.io:9411\n</code></pre> <p>In this way, with the addition of two configuration items and no changes to one line of code, we started the distributed call chain tracking function based on Zipkin and Java chassis.</p> <p>Note If other dependencies in the project also introduce a zipkin (such as Spring Cloud), which may cause the zipkin version to be inconsistent and run incorrectly, you need to declare the zipkin version in the project pom.</p>"},{"location":"general-development/multienvironment/","title":"Multi-environment isolation between microservice instances","text":"<p>When doing service discovery, developers need to understand that the microservice can discover instances of those other services. ServiceComb provides hierarchical instance isolation.</p>"},{"location":"general-development/multienvironment/#microservices-instance-hierarchical-management","title":"Microservices instance hierarchical management","text":"<p>To understand the isolation level between instances, you first need to understand a well-established microservice system structure defined by ServiceComb:</p> <p></p> <p>In the microservice system structure, the top layer is the \u201cproject\u201d, which is divided into multiple tenants under the project. The tenant contains multiple applications, and each application contains multiple environments, that is, the test and production environments can be separated. In a particular environment of a particular application, there are multiple microservices, and one microservice can have multiple versions at the same time. The above is the scope of all static metadata. A specific version of a particular service contains multiple microservice instances registered at runtime, because the information of the service instance is dynamic at runtime because of system scaling, failure, etc. The change, so the routing information of the service instance is again dynamic data. By hierarchically managing these data for microservices, this is natural to achieve logical isolation between instances. * Project corresponds to the project created under each region of Huawei cloud. Different projects are isolated from each other. If there is no new project under the region, it represents the region; for example, create a project named tianjing in North China (cn-north-1), if you want to register the microservice to the project, you can configure it in the microservice.yaml file\uff1a</p> <pre><code>  servicecomb:\n    credentials:\n      project: cn-north-1_tianjing\n</code></pre> <ul> <li> <p>Environment indicates the current environment of the microservice instance. You can configure the current instance environment through service_description.environment in the microservice.yaml file.</p> </li> <li> <p>Application represents a logical entity of a software application, representing a computer software application that has a business function presented to the user. The application name can be configured in the microservice.yaml file via the APPLICATION_ID.</p> </li> <li> <p>Service is a description of the functional objects that are accessed on demand. There are multiple services under one application, and each service calls each other. The service name can be specified in the microservice.yaml file by service_description.name.</p> </li> <li> <p>Version indicates the current service version. There may be multiple versions under one service. The current microservice version can be configured in the microservice.yaml file through service_description.version. When the consumer accesses, the default access is based on the routing rule, which can set by servicecomb.references.[providerName].version-rule in consumer.</p> </li> </ul>"},{"location":"general-development/multienvironment/#typical-scene","title":"Typical scene","text":""},{"location":"general-development/multienvironment/#inter-application-isolation-and-cross-application-calls","title":"Inter-application isolation and cross-application calls","text":""},{"location":"general-development/multienvironment/#function-introduction","title":"Function introduction","text":"<p>In the ServiceComb framework, an application contains multiple microservices. The same microservice instance can be deployed as a public service to multiple applications by specifying a different APPLICATION_ID.</p> <p></p> <p>Different microservice instances, by default, are only allowed to call each other in the same application. When users need to call microservices between different applications, they need to enable cross-application calling.  </p>"},{"location":"general-development/multienvironment/#configuration-instructions","title":"Configuration instructions:","text":"<ol> <li>To enable cross-application calls, you first need to enable cross-application call configuration in the microservice.yaml file on the provider side. The configuration items are as follows:</li> </ol> <pre><code>    service_description:\n      properties:\n        allowCrossApp: true\n</code></pre> <ol> <li>When the Consumer side specifies the microservice name to call the provider, it needs to add the application ID to which the provider belongs. The format changes from [microserviceName] to [appID]:[microserviceName].</li> </ol>"},{"location":"general-development/multienvironment/#code-example","title":"Code example:","text":"<p>Assume that the application to which the consumer belongs is helloApp, the application to which the provider belongs is hellApp2, and the name of the microservice is helloProvider. * RestTemplate call mode When the consumer side develops the microservice consumer in the RestTemplate mode, you need to change [microserviceName] to [appID]:[microserviceName] in the called URL, as follows:</p> <pre><code>RestTemplate restTemplate = RestTemplateBuilder.create();\nResponseEntity&lt;String&gt; responseEntity = restTemplate.getForEntity(\u201ccse://helloApp2:helloProvider/hello/sayHello?name={name}\u201d, String.class, \u201cServiceComb\u201d);\n</code></pre> <ul> <li>RPC call mode When the consumer side develops a microservice consumer in RPC mode, the declared service provider proxy is as follows:</li> </ul> <pre><code>@RpcReference(schemaId = \u201chello\u201d, microserviceName = \u201chelloApp2:helloProvider\u201d)\nprivate Hello hello;\n</code></pre> <p>Cross-application calls are the same as calling microservices under the same application:</p> <pre><code>hello.sayHello(\u201cServiceComb\u201d);\n</code></pre>"},{"location":"general-development/multienvironment/#typical-scene_1","title":"Typical scene","text":""},{"location":"general-development/multienvironment/#development-environment-is-isolated-and-rapidly-developed","title":"Development environment is isolated and rapidly developed","text":""},{"location":"general-development/multienvironment/#function-introduction_1","title":"Function introduction","text":"<p>By setting the environment, the ServiceComb framework can mark microservice instances as development, testing, acceptance, and production environments, and achieve natural isolation at the instance level. When the client looks for a server instance, it can only find server instance under the same environment.</p> <p></p> <p>ServiceComb is strictly dependent on the contract when designing, so under normal circumstances, the contract has changed, you must modify the version of the microservice. However, if current is still development mode, then modify the interface is a very normal situation, when the modification is completed and the current service is started again, the newly generated contract and the old contract saved on the Service Center will conflict and report an error, causing the startup to fail, It is obviously unfriendly to developers by modifying the microservice version number or by deleting the cached data of the service on the Service Center each time. The ServiceComb framework supports rapid debugging of microservices in the development state by configuring the environment as development. When the interface is modified (the schema has changed), restart can be registered to the service center without modifying the version number. But if a consumer has already called the service before the restart, then the consumer side needs to be restarted to get the schema of the latest provider; for example, A-&gt;B, the B interface has been modified and restarted, then A is still using B's previous schema, The call may be in error. to avoid an unknown exception and A needs to be restarted.  </p>"},{"location":"general-development/multienvironment/#configuration-instructions_1","title":"Configuration instructions:","text":"<p>Only the following enumerated values are supported: development, testing, acceptance, production. If not configured, the default value is \"\" (empty).  Method 1: Set by the JVM startup parameter -Dservice_description.environment=development (enumeration value);  Method 2: Specify by microservice.yaml configuration file:</p> <pre><code>  service_description:\n    environment: development\n</code></pre> <ul> <li>Method 3: Specify by environment variable SERVICECOMB_ENV (only for windows system), if it is development state, its value is configured as development;</li> </ul>"},{"location":"general-development/multienvironment/#typical-scene_2","title":"Typical scene","text":""},{"location":"general-development/multienvironment/#three-centers-in-two-places","title":"Three centers in two places","text":""},{"location":"general-development/multienvironment/#function-introduction_2","title":"Function introduction","text":"<p>In the scenario of deploying services across regions in a three centers in two places solution, the same services exists in multiple availableZones. It is necessary to implement the application in the same AZ with priority. If there is a problem with the same AZ, it must be able to access another AZ. To ensure the reliability of the service. ServiceComb provides data center configuration to partition and manage microservices. The data center contains three attributes: servicecomb.datacenter.name, servicecomb.datacenter.region, servicecomb.datacenter.availableZone, data center information does not provide isolation capabilities, and microservices can discover instances of other data centers. However, you can prioritize sending messages to a specified zone or zone by enabling instance affinity.</p> <p></p> <p>When the client is routing, the request will be forwarded to the instance with the same zone/region, and then the instance with the same region but different zones. When they are all different, select one according to the routing rules. Affinity is not logical isolation. As long as the network between the instances is interconnected, it is possible to access it; if the network is unreachable, the access will fail. When the cloud is deployed on the Huawei cloud, the values of the region and the availableZone can be associated with the Huawei cloud region (for example, cn-north-1) and the available region. However, because the different regions on the Huawei cloud do not communicate with each other, the network is not interconnected, so it does not support cross-region access; in addition to the region value corresponding to Huawei cloud, you can also define other values by yourself, and adjust accordingly according to the actual situation, which is very flexible.  </p>"},{"location":"general-development/multienvironment/#configuration-instructions_2","title":"Configuration instructions:","text":"<pre><code>servicecomb:\n  datacenter:\n    name: mydatacenter\n    region: my-Region\n    availableZone: my-Zone\n</code></pre>"},{"location":"general-development/produceprocess/","title":"return value serialization extension","text":""},{"location":"general-development/produceprocess/#concept-description","title":"Concept Description","text":"<p>The current REST channel return value supports both application/json and text/plain formats, supports developer extensions and rewrites, service providers provide serialization capabilities through producer declarations, and service consumers specify return value serialization through the request's Accept header. By default, the data in application/json format is returned.</p>"},{"location":"general-development/produceprocess/#development-instructions","title":"Development Instructions","text":"<ul> <li>extension</li> </ul> <p>Developers can extend the return value serialization method programmatically based on business needs. The implementation steps are as follows, taking the extended support application/xml format as an example:</p> <p>1. Implement the interface <code>ProduceProcessor</code>.</p> <p>&gt; getName() returns the current extended data type name \u00a0\u00a0&gt; \u00a0\u00a0&gt; getOrder() returns the current data type priority. It has multiple implementation classes with the same name. It only loads the highest priority. The smaller the number, the higher the priority. \u00a0\u00a0&gt; \u00a0\u00a0&gt; doEncodeResponse(OutputStream output, Object result) encodes the result object into output, where the logic needs to be implemented by itself. \u00a0\u00a0&gt; \u00a0\u00a0&gt; doDecodeResponse(InputStream input, JavaType type) parses the input into the corresponding object, where the logic needs to be implemented by itself.</p> <p>```java   public class ProduceAppXmlProcessor implements ProduceProcessor {</p> <pre><code>@Override\npublic String getName() {\n  return MediaType.APPLICATION_XML;\n}\n\n@Override\npublic int getOrder() {\n  return 0;\n}\n\n@Override\npublic void doEncodeResponse(OutputStream output, Object result) throws Exception {\n  output.write(JAXBUtils.convertToXml(result).getBytes());\n}\n\n@Override\npublic Object doDecodeResponse(InputStream input, JavaType type) throws Exception {\n  return JAXBUtils.convertToJavaBean(input, type);\n}\n</code></pre> <p>}   ```</p> <p>2. Add a configuration file</p> <p>In the META-INF/services/ folder under resources, create a new file xxx.ProduceProcessor (xxx is the package name of the interface), and fill in the content xxx.ProduceAppXmlProcessor (xxx is the package name of the implementation class).</p> <ul> <li>Rewrite</li> </ul> <p>Developers can rewrite the existing application/json and text/plain implementation logic, or rewrite the self-extended format to rewrite the xml serialization method as an example:</p> <p>1. Create a class named 'ProduceAppXmlProcessor<code>with the same name to implement the interface</code>ProduceProcessor`.</p> <p>2. Rewrite the codec logic in the <code>doEncodeResponse</code> and <code>doDecodeResponse</code> methods</p> <p>3. Change the return value in the getOrder method, which is smaller than the return value of the original method. For example, return -1, the original method return value of application/json and text/plain defaults to 0.</p> <p>4. In the META-INF/services/ folder under resources, create a new file xxx.ProduceProcessor (xxx is the package name of the interface), and fill in the content xxx.ProduceAppXmlProcessor (xxx is the package name of the implementation class).</p> <ul> <li>verification</li> </ul> <p>Service providers provide xml serialization capabilities through producer declarations</p> <p><code>java     @RequestMapping(path = \"/appXml\", method = RequestMethod.POST, produces = MediaType.APPLICATION_XML_VALUE)     public JAXBPerson appXml(@RequestBody JAXBPerson person) {       return person;     }</code></p> <p>The service consumer indicates the return value xml serialization mode through the request's Accept header.</p> <p><code>java     private void testCodeFirstAppXml(RestTemplate template, String cseUrlPrefix) {       JAXBPerson person = new JAXBPerson(\"jake\", 22, \"it\", \"60kg\");       person.setJob(new JAXBJob(\"developer\", \"coding\"));       HttpHeaders headers = new HttpHeaders();       headers.add(\"Accept\", MediaType.APPLICATION_XML_VALUE);       HttpEntity&lt;JAXBPerson&gt; requestEntity = new HttpEntity&lt;&gt;(person, headers);       ResponseEntity&lt;JAXBPerson&gt; resEntity = template.exchange(cseUrlPrefix + \"appXml\",           HttpMethod.POST,           requestEntity,           JAXBPerson.class);       TestMgr.check(person, resEntity.getBody());     }</code></p>"},{"location":"general-development/reactive/","title":"Reactive Programing","text":""},{"location":"general-development/reactive/#simple-synchronization-mode-producer","title":"Simple Synchronization Mode Producer:","text":"<p>Sample code:</p> <pre><code>@GetMapping(path = \"/hello/{name}\")\npublic String hello(@PathVariable(name = \"name\") String name){\n  return \"hello \" + name;\n}\n</code></pre> <p>The corresponding processing flow is as follows:</p> <p></p> <p>This is the traditional typical working model. The core idea is not to block network threads, and to put the business in a separate thread (to simplify the expression, only one thread is drawn in the executor)</p> <p>In general, this mode is not a big problem.</p>"},{"location":"general-development/reactive/#nested-synchronous-call","title":"Nested synchronous call:","text":"<p>Not all services are handled simply, you can respond directly, you may need to call other microservices.</p> <p>Sample code:</p> <pre><code>public interface Intf{\n  String hello(String name);\n}\n\n@GetMapping(path = \"/hello/{name}\")\npublic String hello(@PathVariable(name = \"name\") String name){\n  return \"from remote: hello \" + intf.hello(name);\n}\n</code></pre> <p>The corresponding processing flow is as follows:</p> <p></p> <p>According to the characteristics of this process, you can see the following results:</p> <ul> <li> <p>Because it is a synchronous call, the calling thread of \"Microservice A\" is always in the blocking wait state before \"Other microservices\" is not answered, and does not process any other transactions.</p> </li> <li> <p>When all threads in the Executor are waiting for a remote response, all new requests can only be queued in the Queue and cannot be processed. At this point, the entire system is equivalent to stop working.</p> </li> <li> <p>To increase the processing power, only increase the number of threads in the Executor, and the operating system can not increase the number of threads indefinitely. The benefit of increasing the number of threads is a parabolic model. After a specific critical value, the system handles The ability will drop, and this threshold will not be too big.</p> </li> <li> <p>When the remote synchronization operation is required multiple times in the business logic, the problem will be bigger than before.</p> </li> </ul>"},{"location":"general-development/reactive/#error-optimization-for-nested-synchronous-calls","title":"\"Error\" optimization for nested synchronous calls:","text":"<p>For the previous scenario, someone would think that throwing the \"Invoke producer method\" into another thread pool can solve the problem, including the following:</p> <ul> <li> <p>In the producer method, mark @Async, which is responsible for throwing the call to the method into other thread pools.</p> </li> <li> <p>Transferring threads through business code inside the producer method</p> </li> </ul> <p>Form the following process:</p> <p></p> <p>According to the characteristics of this process, you can see the following results:</p> <ul> <li> <p>\"Invoke producer method\" must be returned immediately, otherwise, the Executor thread will not be released</p> </li> <li> <p>\"Invoke producer method\" must provide a new mechanism to inform the calling process of its return value, not the final return value (currently no such mechanism)</p> </li> <li> <p>Although the Executor thread is released, the Customer Executor is blocked, waiting for the remote response, the blocking state of the entire system has not changed, and there is one more thread switching.</p> </li> <li> <p>The mechanism seems to have the only effect is to release the executor thread, so that the executor thread has the opportunity to process other requests, which is equivalent to the concept of quarantine, the slow processing of the business does not affect other services; but the concept of serviceComb can be directly Supported, you can configure the specified business method to monopolize the new executor, so that the whole process is the same as the \"nested synchronous call\", the process is simpler, and you don't need to do this at the \"Invoke producer method\" level.</p> </li> </ul>"},{"location":"general-development/reactive/#pure-reactive-mechanism","title":"Pure Reactive Mechanism","text":"<p>Sample code:</p> <pre><code>public interface Intf{\n  CompletableFuture&lt;String&gt; hello(String name);\n}\n\n@GetMapping(path = \"/hello/{name}\")\npublic CompletableFuture&lt;String&gt; hello(@PathVariable(name = \"name\") String name){\n  CompletableFuture&lt;String&gt; future = new CompletableFuture&lt;&gt;();\n  intf.hello(name).whenComplete((result, exception) -&gt; {\n    if (exception == null) {\n      future.complete(\"from remote: \" + result);\n      return;\n    }\n\n    future.completeExceptionally(exception);\n  });\n  return future;\n}\n</code></pre> <p>The corresponding processing flow is as follows:</p> <p></p> <ul> <li> <p>Unlike traditional processes, all functions are executed in the eventloop and no thread switching is performed.</p> </li> <li> <p>After the orange arrow is finished, the occupation of this thread is completed, and it will not block waiting for response. The thread can handle other tasks.</p> </li> <li> <p>After receiving the remote response, the network data drive starts to take the red arrow response process</p> </li> <li> <p>As long as there are tasks, the thread will not stop, the task will be executed all the time, you can make full use of the cpu resources, and will not generate redundant thread switching, to consume the CPU unnecessarily.</p> </li> </ul> <p>Because in synchronous mode, a large number of threads are needed to increase the degree of concurrency, and a large number of threads bring additional consumption of thread switching.</p> <p>The test data shows that the reactive mode only needs to consume less than half of the CPU of the synchronous mode. And can reach or exceed the tps of the synchronous mode, and the delay is lower.</p>"},{"location":"general-development/reactive/#hybrid-reactive-mechanism","title":"Hybrid Reactive Mechanism","text":"<p>Reactive requires that all logic executed in the eventloop does not allow any blocking actions, including not limited to wait, sleep, large loops, synchronous query DB, and so on.</p> <p>The bottom of serviceComb is based on vertx. The vertx ecosystem has reactive drivers for various rich components such as JDBC, MQ, zooKeeper, etc. Under normal circumstances, it can meet the requirements.</p> <p>However, in some scenarios, there are indeed some synchronization operations that cannot be avoided, such as:</p> <ul> <li> <p>Private security hardened redis, only provides synchronous drive</p> </li> <li> <p>More complex business operations</p> </li> <li> <p>......</p> </li> </ul> <p>At this point, the logic of these synchronizations can be extracted and placed in the thread pool for processing, while other parts still use the reactive process.</p>"},{"location":"general-development/reactive/#some-notes-about-reactive","title":"Some notes about reactive:","text":"<ul> <li>Producer:</li> </ul> <p>* Whether the producer uses reactive and consumer to call, there is no connection</p> <p>* When the operation return value is the CompletableFuture type, the default operation is in reactive mode. If you need to force this operation to work in thread pool mode, you need to configure it in microservice.yaml explicitly. If an operation, its schemaId is sid, operationId For asyncQuery, you need to do the following:</p> <pre><code>servicecomb:\n  executors:\n    Provider:\n      sid.asyncQuery: cse.executor.groupThreadPool\n</code></pre> <p>The cse.executor.groupThreadPool here is the default thread pool built into serviceComb, which can be arbitrarily specified by the user as its custom thread pool.</p> <ul> <li>Consumer:</li> </ul> <p>* Whether the consumer uses reactive and producer how to implement, there is no connection</p> <p>* Currently only supports transparent RPC mode, using JDK native CompletableFuture to carry this function</p> <p>completableFuture's when, then, etc. can be used directly</p> <p>However, the async series of completableFuture is another thread pool to perform functions. It is not recommended.</p> <p>Support for RxJava Observable will be added later.</p> <p>Support for AsyncRestTemplate will be added later.</p>"},{"location":"general-development/report-framework-version/","title":"Report framework version","text":""},{"location":"general-development/report-framework-version/#concept-description","title":"Concept Description","text":"<p>To facilitate the management, using ServiceComb for development, the currently used ServiceComb version number will be reported to the service center, and the version number of other frameworks will be reported when other frameworks integrate ServiceComb.</p>"},{"location":"general-development/report-framework-version/#sample-code","title":"Sample Code","text":"<p>Step 1 First, implement the Versions interface of the open source framework ServiceComb, implement the loadVersion method under the interface, and return the version name and version number as key-value pairs.</p> <pre><code>public class MyVersion implements Versions{\n\u00a0\u00a0@override\n\u00a0\u00a0public Map&lt;String, String&gt; loadVersion() {\n\u00a0\u00a0\u00a0\u00a0Map&lt;String, String&gt; map = new HashMap&lt;&gt;();\n\u00a0\u00a0\u00a0\u00a0map.put(\"My\", this.getClass().getPackage().getImplementationVersion());\n\u00a0\u00a0\u00a0\u00a0return map;\n\u00a0\u00a0}\n}\n</code></pre> <p>Step 2 To use the SPI mechanism to make the returned object read by ServiceComb, you need to add the services folder in META-INF and add a file to it, with the name of the interface xxxVersions\\ (with package name). Take the concrete implementation class xxxCseVersion\\ (with package name) as the content</p> <p>When the service is registered to the ServiceCenter, it will carry all version number information.</p> <pre><code>{\n\u00a0\u00a0\"serviceId\": \"xxx\",\n\u00a0\u00a0\"appId\": \"xxx\",\n\u00a0\u00a0\"registerBy\": \"SDK\",\n\u00a0\u00a0\"framework\": {\n\u00a0\u00a0\u00a0\u00a0\"name\": \"servicecomb-java-chassis\",\n\u00a0\u00a0\u00a0\u00a0\"version\": \"My:x.x.x;ServiceComb:x.x.x\"\n\u00a0\u00a0}\n}\n</code></pre> <ul> <li>Remarks</li> </ul> <p>The reported version number can be customized, or it can be read from the MANIFEST.MF of the pom or jar package. If you use .class.getPackage().getImplementationVersion() to get the version number from MANIFEST.MF, you need to Set the maven-jar-plugin archive elements addDefaultImplementationEntries and addDefaultSpecificationEntries to true in the pom file.</p> <pre><code>&lt;plugin&gt;\n\u00a0\u00a0&lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;\n\u00a0\u00a0&lt;artifactId&gt;maven-jar-plugin&lt;/artifactId&gt;\n\u00a0\u00a0&lt;configuration&gt;\n\u00a0\u00a0\u00a0\u00a0&lt;archive&gt;\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0&lt;manifest&gt;\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0&lt;addDefaultImplementationEntries&gt;true&lt;/addDefaultImplementationEntries&gt;\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0&lt;addDefaultSpecificationEntries&gt;true&lt;/addDefaultSpecificationEntries&gt;\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0&lt;/manifest&gt;\n\u00a0\u00a0\u00a0\u00a0&lt;/archive&gt;\n\u00a0\u00a0&lt;/configuration&gt;\n&lt;/plugin&gt;\n</code></pre>"},{"location":"general-development/secret-field/","title":"Customized serialization and deserialization","text":""},{"location":"general-development/secret-field/#scenario","title":"Scenario","text":"<p>Due to the non-security of the HTTP protocol, data transmitted over the network can be easily monitored by various packet capture tools. In practical applications, services have high security requirements for sensitive data transmitted between applications or services. Such data requires special encryption protection (different services have different algorithm requirements) so that even if the content is intercepted, it can protect. Sensitive data is not easily obtained.</p>"},{"location":"general-development/secret-field/#solution","title":"Solution","text":"<p>The communication between services leaves unserialized and deserialized. For the above scenario, the @JsonSerialize and @JsonDeserialize annotation functions provided by the jackson class library are used to customize the serialization and deserialization methods for sensitive data, and in a customized method. Implement encryption and decryption functions.</p> <p>Annotation descriptive reference: Find the corresponding version of Javadocs in [https://github.com/FasterXML/jackson-databind/wiki] (https://github.com/FasterXML/jackson-databind/wiki)</p>"},{"location":"general-development/secret-field/#example","title":"example","text":"<ol> <li>Use the specific serialization and deserialization methods for annotations by setting the name property in the Person object. Note: This shows how to use it, not related to encryption and decryption.</li> </ol> <pre><code>public class Person {\n  private int usrId;\n\n\u00a0\u00a0// Specify data name using a specific serialization and deserialization method\n  @JsonSerialize(using = SecretSerialize.class)\n  @JsonDeserialize(using = SecretDeserialize.class)\n  private String name;\n\n  public int getUsrId() {\n    return usrId;\n  }\n\n  public void setUsrId(int usrId) {\n    this.usrId = usrId;\n  }\n\n  public String getName() {\n    return name;\n  }\n\n  public void setName(String name) {\n    this.name = name;\n  }\n\n  @Override\n  public String toString() {\n    return \"Person{\" +\n        \"usrId=\" + usrId +\n        \", name='\" + name + '\\'' +\n        '}';\n  }\n}\n</code></pre> <ol> <li>Define the SecretSerialize class and the SecretDeserialize class and override their methods</li> </ol> <pre><code>public class SecretSerialize extends JsonSerializer&lt;String&gt; {\n\n\u00a0\u00a0// Rewrite the serialization method of a name, where you can implement custom encryption or decryption or other operations\n  @Override\n  public void serialize(String value, JsonGenerator gen, SerializerProvider serializers)\n      throws IOException, JsonProcessingException {\n\u00a0\u00a0\u00a0\u00a0// Add 4 specific characters after the data name\n    value = value + \" &amp;#@\";\n\n\u00a0\u00a0\u00a0\u00a0// Perform serialization operations\n    gen.writeString(value);\n  }\n}\n\npublic class SecretDeserialize extends JsonDeserializer&lt;String&gt; {\n\n\u00a0\u00a0// Rewrite the deserialization method of a name, match the serialize serialization method, get the real data according to the rules customized by the user\n  @Override\n  public String deserialize(JsonParser p, DeserializationContext ctxt) throws IOException, JsonProcessingException {\n\u00a0\u00a0\u00a0\u00a0// Get the deserialized data, remove 4 specific characters, get the real name\n    String value = p.getValueAsString();\n    value = value.substring(0, value.length() - 4);\n    return value;\n  }\n}\n</code></pre>"},{"location":"general-development/service-information-printer/","title":"Printing Service Information","text":""},{"location":"general-development/service-information-printer/#conception-illustration","title":"Conception Illustration","text":"<p>In order make it easier and faster for users to gather the service information, those data are collected and printed on the log.</p>"},{"location":"general-development/service-information-printer/#effect","title":"effect","text":"<p>How the printing looks like: No matter the initialization of the service succeeded or not, the service information will be printed at the end of the log, users can search by \"Service Information is shown below\" to locate it</p> <pre><code>2019-08-21 16:37:14,859 [INFO] Service information is shown below:\nservice center: [http://127.0.0.1:30100]\nconfig center: [http://127.0.0.1:30113]\nAppID: Restful-Service-HelloWorld\nServiceName: restful_provider\nVersion: 0.0.1\nEnvironment: production\nServiceID: a3344e9ad4557f883b36d7f53e33306fbc0a54ad\nInstanceID; e0765a8ec3ee11e9910d0255ac105780\n org.apache.servicecomb.core.SCBEngine$1.afterRegistryInstance(SCBEngine.java:243)\n</code></pre>"},{"location":"general-development/service-information-printer/#extension","title":"extension","text":""},{"location":"general-development/service-information-printer/#related-interfaces-and-classes","title":"related interfaces and classes","text":"<ol> <li>interface: BootUpInformationCollector <p>collect(): return a string\uff0cwhich is the information that should be printed on the log getOrder():return the priority of the implementation classes of BootUpInformationCollector, the smaller the number, the higher the priority.  </p> </li> </ol>"},{"location":"general-development/service-information-printer/#how-users-implement-extension","title":"how users implement extension","text":"<p>to make extension of the printing service, user need to: 1. Create new classes that implements Interface BootUpInformationCollector, and set the appropriate order. 2. Create SPI file.</p>"},{"location":"general-development/service-information-printer/#example","title":"example","text":"<ol> <li>Create a new implementation class HelloCollector.</li> </ol> <pre><code>public class HelloCollector implements BootUpInformationCollector {\n  @Override\n  public String collect() {\n    return \"Hello!\";\n  }\n\n  @Override\n  public int getOrder() {\n    return 5;\n  }\n}\n</code></pre> <p>because the order of this class is 5, it will be printed between the address information(order 0) and service information(order 200) 2. Create SPI file create new SPI file under directory resources/META-INF/services name of the file: org.apache.servicecomb.core.bootup.BootUpInformationCollector content: the class name of HelloCollector 3. printing effect</p> <pre><code>   2019-08-21 16:37:14,859 [INFO] Service information is shown below:\n   service center: [http://127.0.0.1:30100]\n   config center: [http://127.0.0.1:30113]\n   Hello!\n   AppID: Restful-Service-HelloWorld\n   ServiceName: restful_provider\n   Version: 0.0.1\n   Environment: production\n   ServiceID: a3344e9ad4557f883b36d7f53e33306fbc0a54ad\n   InstanceID; e0765a8ec3ee11e9910d0255ac105780\n    org.apache.servicecomb.core.SCBEngine$1.afterRegistryInstance(SCBEngine.java:243)\n</code></pre>"},{"location":"general-development/shutdown/","title":"Shutdown gracefully","text":"<p>ServiceComb achieve graceful shutdown through JDK's ShutdownHook.</p>"},{"location":"general-development/shutdown/#scenes","title":"Scenes","text":"<p>Graceful shutdown can solve the following scenes: * KILL PID * Application automatically exits unexpectedly\uff08System.exit(n)\uff09</p> <p>Graceful shutdown can't solve the following scenes: * KILL -9 PID or taskkill /f /pid</p>"},{"location":"general-development/shutdown/#effect","title":"Effect","text":"<p>When triggering graceful shutdown: * Provider:   * Mark the current service status as STOPPING, do not accept new client requests, the new request will report error directly on the client, and the client cooperates with the retry mechanism to retry other instances;   * Wait for the currently running thread to finish executing. If the provider side has set timeout, will be forced to close after timeout; * consumer:   * Mark the current service state as STOPPING, do not send a new call request;   * Waiting for the response of the currently sent request, if it exceeds the timeout period for the client to receive the response (default 30 seconds), it is forcibly closed;</p>"},{"location":"general-development/shutdown/#principle","title":"Principle","text":"<p>When an graceful shutdown is triggered, the following steps are performed in sequence: 1. Send a BEFORE_CLOSE event to all listeners, and notify the listener to handle the corresponding event; 2. Mark the current service status as STOPPING; 3. Log out the current microservice instance from the service center and close the vertx corresponding registry; 4. Waiting for all currently existing invocation calls to complete; 5. Close the vertx corresponding to config-center and transport; 6. Send an AFTER_CLOSE event to all listeners, and notify the listener to handle the corresponding event; 7. Mark the current service status as DOWN; graceful shutdown ends;</p>"},{"location":"general-development/thread-model/","title":"Threading model","text":""},{"location":"general-development/thread-model/#threading-model-in-synchronous-mode","title":"Threading model in synchronous mode","text":""},{"location":"general-development/thread-model/#threading-model-in-reactive-mode","title":"Threading model in reactive mode","text":"<p>Thread related configuration\uff1a  </p> <ul> <li>REST over Vertx</li> <li>Highway</li> <li>Server business thread pool in synchronous mode</li> </ul>"},{"location":"general-development/visit-sc/","title":"Access Service Center","text":""},{"location":"general-development/visit-sc/#concept-description","title":"Concept Description","text":"<p>The system realizes the discovery between services through the service center . During the service startup process, the service center is registered. When calling other services, the service center will query the instance information of other services, such as the access address, the protocol used, and other parameters. The service center supports the use of PULL and PUSH modes to notify instance changes.</p> <p>Developers can configure service center clusters addresses, connection parameters, heartbeat management and so on. </p>"},{"location":"general-development/visit-sc/#configuration-instructions","title":"Configuration instructions","text":""},{"location":"general-development/visit-sc/#table-1-1-accessing-common-configuration-items-in-the-configuration-center","title":"Table 1-1 Accessing Common Configuration Items in the Configuration Center","text":"Configuration Item Reference / Default Value Range Required Meaning servicecomb.service.registry.address http://127.0.0.1:30100 Yes Service center address information, you can configure multiple, separated by commas. servicecomb.service.registry.instance. Watch true No Whether to monitor instance changes in PUSH mode. When it is false, it means using PULL mode. servicecomb.service.registry. Autodiscovery false No Whether to automatically discover the address of the service center. This configuration is enabled when a partial address needs to be configured, and other addresses are discovered by the configured service center instance. servicecomb.service.registry.instance.healthCheck.interval 30 No Heartbeat interval. servicecomb.service.registry.instance.healthCheck.times 3 No Number of allowed heartbeat failures. If there is (times + 1) continuous heartbeat failures, this instance will be automatically logged off by service-center, i.e. interval * (times + 1) determines when the instance is automatically logged off. If the service center waits for such a long time and does not receive a heartbeat, the instance will be logged off. servicecomb.service.registry.instance.empty.protection true No When service center gives empty server list, will not remove local address cache when true. servicecomb.service.registry.client.timeout.connection 30000 Connection timeout in milliseconds servicecomb.service.registry.client.timeout.request 30000 Request timeout in milliseconds servicecomb.service.registry.client.timeout.idle 60 Connection idle timeout in milliseconds servicecomb.service.registry.client.timeout.heartbeat 3000 Heartbeat request timeout in milliseconds servicecomb.service.registry.client.instances 1 No the account of verticle instances that Service Registry Client had been deployed servicecomb.service.registry.client.eventLoopPoolSize 4 No the size of Service Registry client Event Loop pool servicecomb.service.registry.client.workerPoolSize 4 No the size of Service Registry client worker pool"},{"location":"packaging/standalone/","title":"Standalone mode","text":""},{"location":"packaging/standalone/#concept-description","title":"Concept Description","text":"<p>A Standalone container that loads Spring with a simple Main, because the service usually does not require the properties of a Web container such as Tomcat/JBoss, and there is no need to use the Web container to load the service. The microframework provides a standalone deployment run mode. The service container is just a simple Main method and loads a simple Spring container to expose the service.</p>"},{"location":"packaging/standalone/#operation-steps","title":"Operation steps","text":"<ul> <li>Step 1 Write the Main function, initialize the log and load the service configuration as follows:</li> </ul> <pre><code>import org.apache.servicecomb.foundation.common.utils.BeanUtils;\nimport org.apache.servicecomb.foundation.common.utils.Log4jUtils;\n\npublic class MainServer {\npublic static void main(String[] args) throws Exception {\n\u3000Log4jUtils.init(); # Log initialization\n\u3000BeanUtils.init();  # Spring bean initialization\n }\n}\n</code></pre> <ul> <li>Step 2 Run the MainServer to start the microservice process and expose the service.</li> </ul>"},{"location":"packaging/standalone/#notes","title":"Notes","text":"<p>If you are using the rest network channel, you need to change the transport in the pom to use the cse-transport-rest-vertx package.</p>"},{"location":"packaging/web-container/","title":"WEB container mode","text":""},{"location":"packaging/web-container/#concept-description","title":"Concept Description","text":"<p>If you need to load the microservice into the web container to start the runtime, you need to create a new servlet project wrapper, the servlet project, you just need to write few lines of code</p>"},{"location":"packaging/web-container/#development-example","title":"Development example","text":"<p>Refer to the \"Development Service Provider\" -&gt; \"Communication Protocol\" -&gt; \"REST over Servlet\" chapter.</p>"},{"location":"packaging/web-container/#notes","title":"Notes","text":"<p>Restful calls should be isolated from other static resource calls (such as html, js, etc.) in the web container, so there should be a layer of keywords in the post after webroot, such as the example in web.xml above (/test/rest) In the rest.</p> <p>Take tomcat as an example. By default, each war package has a different webroot. This webroot needs to be a basePath prefix. For example, if webroot is testing, all the contracts of the microservice must start with /test.</p> <p>When the microservice is loaded in the web container and directly uses the http and https ports opened by the web container, it is necessary to satisfy the rules of the web container because it is the communication channel of the web container used.</p>"},{"location":"packaging/web-container/#_1","title":"WEB container mode","text":""},{"location":"question-and-answer/faq/","title":"FAQ","text":"<ol> <li>**Q: What is the relationship between ServiceComb and SpringCloud, and what is ServiceComb specific application scenarios? **</li> </ol> <p>A: ServiceComb is a set of microservice development frameworks based on large-scale IT system practices. It encapsulates a set of microservices running models based on best practices in development. These capabilities are completely transparent to users,it can be integrated and adjusted by configuration. In the operation and maintenance phase, microservices operation and maintenance have been fully considered, providing rich monitoring indicators and dynamic governance capabilities. \u00a0\u00a0\u00a0 B: ServiceComb's capabilities can be used as a separate development framework, in a scenario that requires a lightweight microservice solution, or on SpringCloud, working with other components provided by SpringCloud, in heavyweight The scene together with SpringCloud produces a '1+1&gt;2' effect.</p> <ol> <li> <p>**Q: Do we have a problem with IntelliJ's free version? ** \u00a0\u00a0\u00a0 A: No problem, use IntelliJ development, refer to [Setup Developer Environment] (/cn/developers/setup-develop-environment/) for the corresponding environment configuration.</p> </li> <li> <p>Q: What need to be cautious when using Java-Chassis?</p> </li> </ol> <p>A: There are a few restrictions when using Java-Chassis:    * Before version 0.3.0-SNAPSHOT, it does not support annotations like <code>@GetMapping</code>.    * When using the same HTTP request method, e.g. GET, the method name need to be unique as it will become operation ID when swagger generates contracts.    * Class and method name need to be public.</p> <ol> <li>**Q: Contract generation will report error: 'Caused by: java.lang.Error: OperationId must be unique', does not support function overriding? **</li> </ol> <p>A: We support function overriding, plus the <code>@ApiOperation</code> tag. There are examples in demo-pojo. Each interface must have a unique operation id.</p> <ol> <li>Q: When using the spring-boot-starter-provider dependency, property like <code>spring.main.web-environment</code> not working in application.yml file.</li> </ol> <p>A: When you need both the starter provider dependency and the servlet, you need to declare <code>spring.main.web-environment</code> in application.properties file or declare it in application.yml file and create an empty application.properties file.</p> <ol> <li>Q: What's the dependency differences between gateway and other microservices?</li> </ol> <p><code>xml    &lt;groupId&gt;org.apache.servicecomb&lt;/groupId&gt;    &lt;artifactId&gt;spring-boot-starter-provider&lt;/artifactId&gt;</code></p> <p>A: Gateway depends on not only the <code>spring-boot-starter-provider</code>, but also the <code>spring-boot-starter-discovery</code>. This can refer to the manger implementation of LinuxCon-Beijing-Workshop.</p> <ol> <li>Q: Do gateway need to configure assembly like the other microservices? Is /maven/gateway the default path of the docker maven plugin?</li> </ol> <p>A: Yes. Docker maven plugin relies on the assembly files to generate docker image. /maven is the default path of docker maven plugin and /gateway is the path defined in the assembly file.</p> <ol> <li>Q: Are there any restrictions of the return type of our API? Should it be the type of ResponseEntity?</li> </ol> <p>A: No, examples can refer to the implementation of integration-test in java-chassis.</p> <ol> <li>**Q: After the microservice is started, the interface cannot be called correctly, or is there no error returned? **</li> </ol> <p>A: Please check that the calling path is exactly the same as the path published in the Producer implementation code. The boot log on the Producer side can see the output of the map path, for example:</p> <p><code>[INFO] Swagger mapped \"{[/hello/], method=[GET], produces=[application/json]}\"</code></p> <p>For different programming styles (models) to implement Producer documentation and notes, please see: Jaxrs SpringMVC Pojo Spring Boot . \u00a0\u00a0\u00a0  10. **Q: The port number under the microservice.yaml configuration file has been modified via eclipse. After starting the program, the port number does not work? **</p> <p>A: You need to import the sample project alone. If you import the entire ServiceComb-Java-Chassis project, the IDE will not compile the sample because the sample directory is not in the ServiceComb-Java-Chassis module. There is no error message under eclipse. Prompt message. Therefore, eclipse starts the demo of the sample and will find that the modified port does not work. \u00a0\u00a0\u00a0  12. ** Q: How do I customize the HTTP status code in the REST interface for a Java method? **</p> <p>A: For normal return values, you can do this with SwaggerAnnotation, for example:</p> <p><code>java    @ApiResponse(code = 300, response = String.class, message = \"\")    public int test(int x) {      return 100;    }</code></p> <p>For the return value of the exception, you can do this by throwing a custom InvocationException, for example:</p> <p>```java    public String testException(int code) {      String strCode = String.valueOf(code);        switch (code) {          case 200:            return strCode;          case 456:            throw new InvocationException(code, strCode, strCode + \" error\");          case 556:            throw new InvocationException(code, strCode, Arrays.asList(strCode + \" error\"));          case 557:            throw new InvocationException(code, strCode, Arrays.asList(Arrays.asList(strCode + \" error\")));          default:            break;        }</p> <pre><code> return \"not expected\";\n</code></pre> <p>}   ```</p> <ol> <li>Q: How to customize the log configuration of your own microservice?</li> </ol> <p>A: ServiceComb does not bind the logger, just uses slf4j, users can freely choose log4j/log4j2/logback and so on. ServiceComb provides a log4j extension that supports incremental configuration of log4j's properties files on a standard log4j basis. \u00a0\u00a0\u00a0 * By default, the configuration file is loaded by the rule: \"classpath*:config/log4j.properties\" \u00a0\u00a0\u00a0 * Actually search all the <code>config/log4j.properties and config/log4j.*.properties</code> in the classpath, and cut out the <code>\\*</code> from the searched file to perform alpha. Sort, then load in order, and the final synthesized file is used as the log4j configuration file. \u00a0\u00a0\u00a0 \u00a0\u00a0\u00a0 * If you want to use ServiceComb's log4j extension, you need to call Log4jUtils.init, otherwise it will be used according to the rules of the standard logger.</p> <ol> <li>**Q: When the service is configured with multiple transports, how do you choose which transport to use at runtime? **</li> </ol> <p>A: \u00a0\u00a0\u00a0* ServiceComb's consumer, transport, handler, and producer are decoupled, and each function works together through contract definitions, namely: \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0Consumer use transparent rpc, or springmvc development and use of highway, or RESTful transmission on the network does not matter with the producer is to use transparent rpc, or jaxrs, or springmvc development, there is no relationship between the receiver is not perceived, business development methods and transmission methods</p> <p>* Consumer access to the producer, at the runtime's transport selection, the general rule is: \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0The consumer's transport and the producer's endpoint take the intersection. If there are multiple transports after the intersection, they are used in turn.</p> <p>Decomposed, there are the following scenarios:</p> <p>* When a microservice producer opens both the highway and the RESTful endpoint \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0* Only the highway transport jar is deployed in the consumer process, only the producer's highway endpoint is accessed. \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0* Only the RESTful transport jar is deployed in the consumer process, only the RESTful endpoint of the producer is accessed. \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0* In the consumer process, both the highway and RESTful transport jars are deployed, and the producer's highway and RESTful endpoints are accessed in turn.</p> <p>If, at this time, the consumer wants to use a transport to access the producer, it can be configured in the microservice.yaml of the consumer process, specifying the name of the transport:</p> <p><code>yaml \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0Servicecomb: \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0References: \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0&lt;service_name&gt;: \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0Transport: highway</code></p> <p>* When a microservice producer only opens the endpoint of the highway \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0* The consumer process only deploys the highway transport jar, then the highway access is normally used. \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0*The consumer process only deploys RESTful transport jars and cannot be accessed \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0* The consumer process deploys both the highway and the RESTful transport jar, and the highway access is normally used.</p> <p>* When a microservice producer only opens RESTful endpoints \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0*The consumer process only deploys the highway transport jar and cannot access it. \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0* The consumer process only deploys RESTful transport jars, which normally uses RESTful access. \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0* The consumer process deploys both the highway and the RESTful transport jar, and the RESTful access is normally used.</p> <ol> <li>Q: The swagger body parameter type is incorrectly defined, causing the content registered in the service center to have no type information</li> </ol> <p>Symptom:</p> <p>Define the following interface, put the parameters into the body to pass</p> <p><code>yaml    /testInherate:        Post:          operationId: \"testInherate\"          Parameters:          - in: \"body\"            Name: \"xxxxx\"            Required: false            Type: string          Responses:            200:              Description: \"response of 200\"              Schema:                $ref: \"#/definitions/ResponseImpl\"</code></p> <p>Define the interface in the above way. After the service is registered, the interface type: string that is queried from the service center is lost and becomes:</p> <p><code>yaml    /testInherate:        Post:          operationId: \"testInherate\"          Parameters:          - in: \"body\"            Name: \"xxxxx\"            Required: false          Responses:            200:              Description: \"response of 200\"              Schema:                $ref: \"#/definitions/ResponseImpl\"</code></p> <p>If the client does not place a swagger, the following exception is also reported:</p> <p><code>text       Caused by: java.lang.ClassFormatError: Method \"testInherate\" in class ? has illegal signature \"</code></p> <p>A: When defining the type of the body parameter, you need to use the schema. You cannot use type directly.</p> <p><code>yaml    /testInherate:        Post:          operationId: \"testInherate\"          Parameters:          - in: \"body\"            Name: \"request\"            Required: false            Schema:              Type: string          Responses:            200:              Description: \"response of 200\"              Schema:                $ref: \"#/definitions/ResponseImpl\"</code></p> <ol> <li>Q: Does the ServiceComb microservices framework service innovate via long connection?</li> </ol> <p>A: http request via a long connection (with a timeout), and the highway mode also via a long connection (all the time).</p> <ol> <li>Q: Is the service disconnected service center registration information automatically deleted?</li> </ol> <p>A: The service center heartbeat detects that the service instance is unavailable, only the service instance information is removed, and the static data of the service is not removed.</p> <ol> <li>Q: How to implement service registration if you use the tomcat method to integrate the ServiceComb microservices framework</li> </ol> <p>A: If you use the ServiceComb sdk servlet method (using the transport-rest-servlet dependency) to deploy to the tomcat as a war package, you need to ensure that the rest port configuration in the service description file (microservice.yaml) is consistent with the external container to implement the service. Register correctly. Otherwise, the tomcat open port cannot be perceived.</p> <ol> <li>Q: If you use the tomcat method to integrate the ServiceComb microservices framework, how to register the context of the war package deployment to the service center when the service is registered</li> </ol> <p>A: When publishing the service interface, you need to put the context of the war package deployment at the front of the baseurl, so that the path registered to the service center is the complete path (including the context). Example:</p> <p><code>java \u00a0\u00a0\u00a0 @path(/{context}/xxx) \u00a0\u00a0\u00a0 Class ServiceA</code></p> <ol> <li>Q: How does the ServiceComb microservices framework implement data transparent transmission between multiple microservices</li> </ol> <p>A: \u00a0\u00a0\u00a0 Transmitting data into:</p> <p><code>java \u00a0\u00a0\u00a0 CseHttpEntity&lt;xxxx.class&gt; httpEntity = new CseHttpEntity&lt;&gt;(xxx); \u00a0\u00a0\u00a0 / / Transparent content \u00a0\u00a0\u00a0 httpEntity.addContext(\"contextKey\",\"contextValue\"); \u00a0\u00a0\u00a0 ResponseEntity&lt;String&gt; responseEntity = RestTemplateBuilder.create().exchange(\"cse://springmvc/springmvchello/sayhello\",HttpMethod.POST, httpEntity, String.class);</code></p> <p>Transparent data acquisition:</p> <p><code>java \u00a0\u00a0\u00a0 @Override \u00a0\u00a0\u00a0 @RequestMapping(path=\"/sayhello\",method = RequestMethod.POST) \u00a0\u00a0\u00a0 Public String sayHello(@RequestBody Person person, InvocationContext context){ \u00a0\u00a0\u00a0\u00a0\u00a0 / / Transparent data acquisition \u00a0\u00a0\u00a0\u00a0\u00a0 context.getContext(); \u00a0\u00a0\u00a0\u00a0\u00a0 Return \"Hello person \" + person.getName(); \u00a0\u00a0\u00a0 }</code></p> <ol> <li>Q: How does the ServiceComb microservices framework service customize the return status code?</li> </ol> <p>A: \u00a0\u00a0\u00a0 <code>java \u00a0\u00a0\u00a0 @Override \u00a0\u00a0\u00a0 @RequestMapping(path = \"/sayhello\",method = RequestMethod.POST) \u00a0\u00a0\u00a0 Public String sayHello(@RequestBody Person person){ \u00a0\u00a0\u00a0\u00a0\u00a0 InvocationContext context = ContextUtils.getInvocationContext(); \u00a0\u00a0\u00a0\u00a0\u00a0 / / Custom status code \u00a0\u00a0\u00a0\u00a0\u00a0 context.setStatus(Status.CREATED); \u00a0\u00a0\u00a0\u00a0\u00a0 Return \"Hello person \"+person.getName(); \u00a0\u00a0\u00a0 }</code></p> <ol> <li>Q: Partial exposure of ServiceComb body Model</li> </ol> <p>A: There may be some attributes in the body object corresponding to an interface. You don't want to open it. Do not bring it out when generating the schema. Use:</p> <p><code>java \u00a0\u00a0\u00a0 @ApiModelProperty(hidden = true)</code></p> <ol> <li>Q: ServiceComb framework gets the address of the remote consumer</li> </ol> <p>A: If you use the http rest method (using the transport-rest-vertx dependency) you can get it in the following way:</p> <p><code>java \u00a0\u00a0\u00a0 AbstractProducerContextArgMapper httpRequestCreator = (AbstractProducerContextArgMapper)invocation.getHandlerContext().get(RestConst.HTTP_REQUEST_CREATOR); \u00a0\u00a0\u00a0 If(httpRequestCreator != null){ \u00a0\u00a0\u00a0\u00a0\u00a0 HttpServletRequest req = (HttpServletRequest)httpRequestCreator.createContextArg(invocation); \u00a0\u00a0\u00a0\u00a0\u00a0 System.out.println(req.getRemoteHost()); \u00a0\u00a0\u00a0 }</code></p> <p>The actual scenario is to take the outermost address, so LB should be passed to edgeservice, and edgeService should be passed outside the context.</p> <ol> <li>Q: ServiceComb describes the handler</li> </ol> <p>A: The consumer default handler is simpleLB. When there is no configuration, the handler chain will use this. If the handler is configured, it must contain the lb handler. Otherwise, the call error is reported in the document.</p> <ol> <li>Q: ServiceComb log replacement</li> </ol> <p>A: CSE java-chassis log recommendation method is to use Log4jUtils.init() at startup, directly use the recommended Log4j for log management, but some scenarios do not want to use log4j, such as want to use log4j2 or logback, below log4j2 Take a brief introduction to the next step:</p> <p>1. Do not use Log4jUtils.init() in the code; \u00a0\u00a0\u00a02. Remove the log4j configuration file (it doesn't matter if you don't delete it, because it won't be used); \u00a0\u00a0\u00a03. Exclude the log4j introduced by the CSE framework, for example: \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0<code>xml \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0&lt;dependency&gt; \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0&lt;groupId&gt;org.apache.servicecomb&lt;/groupId&gt; \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0&lt;artifactId&gt;provider-springmvc&lt;/artifactId&gt; \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0&lt;exclusions&gt; \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0&lt;exclusion&gt; \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0&lt;groupId&gt;log4j&lt;/groupId&gt; \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0&lt;artifactId&gt;log4j&lt;/artifactId&gt; \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0&lt;/exclusion&gt; \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0&lt;/exclusions&gt; \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0&lt;/dependency&gt;</code> \u00a0\u00a0\u00a04. Introducing the dependency of log4j2</p> <p><code>xml \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0&lt;dependency&gt; \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0&lt;groupId&gt;org.apache.logging.log4j&lt;/groupId&gt; \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0&lt;artifactId&gt;log4j-slf4j-impl&lt;/artifactId&gt; \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0&lt;/dependency&gt; \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0&lt;dependency&gt; \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0&lt;groupId&gt;org.apache.logging.log4j&lt;/groupId&gt; \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0&lt;artifactId&gt;log4j-api&lt;/artifactId&gt; \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0&lt;/dependency&gt; \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0&lt;dependency&gt; \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0&lt;groupId&gt;org.apache.logging.log4j&lt;/groupId&gt; \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0&lt;artifactId&gt;log4j-core&lt;/artifactId&gt; \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0&lt;/dependency&gt;</code></p> <p>If there is no version dependency management, you need to fill in the version number.</p> <p>5. Add the log4j2 configuration file log4j2.xml. Please check the official description for this, for example:</p> <p><code>xml \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0&lt;!--Log level and priority ordering: OFF &gt; FATAL &gt; ERROR &gt; WARN &gt; INFO &gt; DEBUG &gt; TRACE &gt; ALL --&gt; \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0&lt;!--Configuration behind the configuration, this is used to set the internal information output of log4j2, can not be set, when set to trace, you will see various detailed output inside log4j2 --&gt; \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0&lt;!--monitorInterval: Log4j can automatically detect the modified configuration file and reconfigure itself, set the interval seconds --&gt; \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0&lt;configuration status=\"WARN\" monitorInterval=\"30\"&gt; \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0&lt;!--First define all appender--&gt; \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0&lt;appenders&gt; \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0&lt;!--This output console configuration --&gt; \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0&lt;console name=\"Console\" target=\"SYSTEM_OUT\"&gt; \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0&lt;!--Format of output log --&gt; \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0&lt;PatternLayout pattern=\"[%d{HH:mm:ss:SSS}] [%p] - %l - %m%n\"/&gt; \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0&lt;/console&gt; \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0&lt;!--The file will print out all the information, this log will be automatically cleared every time the program is run, determined by the append attribute, this is also very useful, suitable for temporary testing --&gt; \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0&lt;File name=\"log\" fileName=\"log/test.log\" append=\"false\"&gt; \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0&lt;PatternLayout pattern=\"%d{HH:mm:ss.SSS} %-5level %class{36} %L %M - %msg%xEx%n\"/&gt; \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0&lt;/File&gt; \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0&lt;!-- This will print out all info and the following level information. Each time the size exceeds the size, the size of the log will be automatically saved under the folder created by the year-month and compressed, as an archive --&gt; \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0&lt;RollingFile name=\"RollingFileInfo\" fileName=\"${sys:user.home}/logs/info.log\" \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0filePattern=\"${sys:user.home}/logs/$${date:yyyy-MM}/info-%d{yyyy-MM-dd}-%i.log\"&gt; \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0&lt;!--The console only outputs level and above information (onMatch), other direct rejection (onMismatch) --&gt; \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0&lt;ThresholdFilter level=\"info\" onMatch=\"ACCEPT\" onMismatch=\"DENY\"/&gt; \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0&lt;PatternLayout pattern=\"[%d{HH:mm:ss:SSS}] [%p] - %l - %m%n\"/&gt; \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0&lt;Policies&gt; \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0&lt;TimeBasedTriggeringPolicy/&gt; \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0&lt;SizeBasedTriggeringPolicy size=\"100 MB\"/&gt; \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0&lt;/Policies&gt; \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0&lt;/RollingFile&gt; \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0&lt;RollingFile name=\"RollingFileWarn\" fileName=\"${sys:user.home}/logs/warn.log\" \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0filePattern=\"${sys:user.home}/logs/$${date:yyyy-MM}/warn-%d{yyyy-MM-dd}-%i.log\"&gt; \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0&lt;ThresholdFilter level=\"warn\" onMatch=\"ACCEPT\" onMismatch=\"DENY\"/&gt; \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0&lt;PatternLayout pattern=\"[%d{HH:mm:ss:SSS}] [%p] - %l - %m%n\"/&gt; \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0&lt;Policies&gt; \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0&lt;TimeBasedTriggeringPolicy/&gt; \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0&lt;SizeBasedTriggeringPolicy size=\"100 MB\"/&gt; \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0&lt;/Policies&gt; \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0&lt;!-- DefaultRolloverStrategy property is not set, the default is up to 7 files in the same folder, here set 20 --&gt; \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0&lt;DefaultRolloverStrategy max=\"20\"/&gt; \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0&lt;/RollingFile&gt; \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0&lt;RollingFile name=\"RollingFileError\" fileName=\"${sys:user.home}/logs/error.log\" \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0filePattern=\"${sys:user.home}/logs/$${date:yyyy-MM}/error-%d{yyyy-MM-dd}-%i.log\"&gt; \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0&lt;ThresholdFilter level=\"error\" onMatch=\"ACCEPT\" onMismatch=\"DENY\"/&gt; \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0&lt;PatternLayout pattern=\"[%d{HH:mm:ss:SSS}] [%p] - %l - %m%n\"/&gt; \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0&lt;Policies&gt; \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0&lt;TimeBasedTriggeringPolicy/&gt; \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0&lt;SizeBasedTriggeringPolicy size=\"100 MB\"/&gt; \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0&lt;/Policies&gt; \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0&lt;/RollingFile&gt; \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0&lt;/appenders&gt; \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0&lt;!-- Then define the logger, the appender will only take effect if the appender is defined and imported -&gt; \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0&lt;loggers&gt; \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0&lt;!--Filter out some useless DEBUG information from spring and mybatis --&gt; \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0&lt;logger name=\"org.springframework\" level=\"INFO\"&gt;&lt;/logger&gt; \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0&lt;logger name=\"org.mybatis\" level=\"INFO\"&gt;&lt;/logger&gt; \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0&lt;root level=\"all\"&gt; \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0&lt;appender-ref ref=\"Console\"/&gt; \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0&lt;appender-ref ref=\"RollingFileInfo\"/&gt; \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0&lt;appender-ref ref=\"RollingFileWarn\"/&gt; \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0&lt;appender-ref ref=\"RollingFileError\"/&gt; \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0&lt;/root&gt; \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0&lt;/loggers&gt; \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0&lt;/configuration&gt;</code> 6. Start the service for verification</p> <ol> <li>Q: Service timeout setting</li> </ol> <p>A: Add the following configuration to the microservice description file (microservice.yaml): \u00a0\u00a0\u00a0     <code>yaml    servicecomb:      request:        timeout: 30000</code></p> <ol> <li>**Q: The URL address can be uniquely located. Why do you want to add a schema? **</li> </ol> <p>A: \u00a0\u00a0\u00a0 1. The schema is used to match the service contract. It is used to ensure that the server and the consumer contract are compatible. Each contract needs a unique ID and is stored in the service center. \u00a0\u00a0\u00a0 2. Schema maps to the interface concept of java. When the consumer uses the transparent rpc mode to develop, it can find which operation in the micro service. The method names between schemas are not unique. \u00a0\u00a0\u00a0 \u00a0\u00a0\u00a0 3. operation qualified name is the key of the governance, and the URL cannot be directly searched because of the existence of the path parameter, and the qualified name will not change. Governance does not distinguish between transmissions. If governance goes by URL, then when highway is called in, it has to construct the url according to the parameters, and then the regular expression matches, which is too tossing. \u00a0\u00a0\u00a0 \u00a0\u00a0\u00a0 4. http is just a transport channel, and there are other transport channels that do not need to be mapped to URLs.</p> <ol> <li>**Q: When the Rest client is invocating, it only takes the service name and URL, and does not need to specify the schema id. In fact, according to this URL, the specific contract can also be found. So what is the role of the specified schema id? **</li> </ol> <p>A: Since transparent rpc is an interface call and does not have a URL, the internal is actually normalized to the operation to describe, so that it can be uniquely mapped to the specific request processing in conjunction with the schema id. \u00a0\u00a0\u00a0 </p> <ol> <li>**Q: What is the concept of Transport? What is it used for? **</li> </ol> <p>A: The Transport is responsible for codec, and transmission. The communication model has two kinds of Rest and Highway. The Highway corresponds to the private protocol, which uses protobuf encoding, and the Rest uses json. Highway and Rest are based on vertx, and vertx is based on netty.</p> <ol> <li>**Q: Is there be multiple appIDs and microservices in a service provider? What scenario will this happen? **</li> </ol> <p>A: Yes, what is expressed here is a concept of merge. The microservice.yaml file, which may exist in both jars, disks, and command line arguments, specifies that they are merged by priority and are used for added flexibility. In the jar is the default value, in addition to the environment variables, command line parameters, configuration center coverage, providing multiple layers of customization.</p> <ul> <li>Q: How does ServiceComb interact with the service center?</li> </ul> <p>A: Take the rest, mainly responsible for registration, taking data and heartbeat, etc.; 'watch event' via websocket, watch event is to observe whether the service center instance information has changed.</p> <ul> <li>**Q: Is there a governance center like dubbo? **</li> </ul> <p>A: bizkeeper is a handler, one of the contents of governance. Governance can be extended by handlers.</p> <ul> <li>**Q: How to understand the service path? **</li> </ul> <p>A: Each microservice has a servicePathManager, and each schema registers its own path.</p> <ul> <li>**Q: Can the browser directly access the microservice Endpoint? **</li> </ul> <p>A: Yes, the restful microservice Endpoint can be used to access the service that provides the get method directly in the browser using HTTP plus service path. If it is to access the services provided by other Http methods, it is recommended to install and use.(https://www.sap.com/developer/tutorials/api-tools-postman-install.html)</p> <ul> <li>**Q: When the contract is generated, do you have to add the version number and language? **</li> </ul> <p>A: The contract belongs to the microservice. The microservice has a version, but the language should not be accompanied by the version number. Contractual requirements should be independent of language. The contract \"no version\", the version of the contract is embodied in the microservice, the instance can find the version of the microservice to which it belongs, and a certain contract can be found.</p> <ul> <li>**Q: The design code in ServiceRegistry is similar to Eureka? **</li> </ul> <p>A: Our first version was built on the basis of Spring Cloud. Later, when we found that it was not enough to use it, we gradually made our own set, so it was designed after fully referring to Eureka.</p> <ul> <li>**Q: Some rpc is netty calling redis implementation, what is the advantage over direct netty forwarding? **</li> </ul> <p>A: Maybe I want to use Redis to solve the subscription release. But this is not a big deal. I tried it before, but later I changed it to ServiceComb. \u00a0\u00a0\u00a0 </p> <ul> <li>**Q: If you introduce the <code>transport-rest-servlet</code> and <code>transport-rest-vertx</code> dependencies at the same time, how does it decide which one to use? **</li> </ul> <p>A: If the port is not occupied, use vertx; if it is occupied, use servlet.</p> <ul> <li>**Q: What is the scenario for qps flow control design? **</li> </ul> <p>A: Rate limit has two main functions. First, it guarantees the service effect to some key services by restricting different consumers, and the second is to prevent the avalanche effect. The thickness of the water pipe can be determined according to the importance of the service. ServiceComb supports two types of current limiting methods, namely, consumer-side current limiting and server-side current limiting. The consumer-side current limiting can achieve relatively fine control.</p> <ul> <li>**Q: If the server is a chain call, that is, a-&gt;b-&gt;c, then does the QPS flow control cause flow pipe uneven and unbalanced? **</li> </ul> <p>A: The general mode is to measure and then set. The qps settings are ultimately tuned in conjunction with the overall business needs, rather than setting them up on a single node.</p> <ul> <li>Q: The service failed to be invoked via cse://serviceName/appPath, error: java.lang.Error:not support def type:class io.swagger.models.properties xxx</li> </ul> <p>A: Check whether the version of java-chassis that the consumer and provider depend on are consistent. If they are inconsistent, please modify and use the newer version.</p> <ul> <li>Q: When sending a rest request, the following error is reported: Bad Request, description: http:request body too large</li> </ul> <p>A: Check if the Service Center is older version, and if so, upgrade to the latest version.</p> <ul> <li>**Q: How to ignore the attributes specified in the contract DTO? **</li> </ul> <p>A: If you are using 'rest transport', because it is Json serialization, you can use @JsonIgnore annotations to mark attributes that need to be ignored; 'highway transport' is not currently supported. Note that you need to update the version of the microservice after the modification, for example:</p> <p><code>java   public class OutputForTest{   @JsonIgnore   private String outputId = null;   private String inputId = null;   ...   }</code></p> <ul> <li>Q: How to get the value of a field in the header in a user-defined handler   \u00a0\u00a0\u00a0 A: Use the @ApiImplicitParams annotation declaration in the user-defined handler and the invocation.getArgs() to get the value of the header. E.g:   <code>java   public class MyHandler implements Handler {     @ApiImplicitParams({@ApiImplicitParam(name = \"tester\", dataType = \"string\", paramType = \"header\")})     @Override     public void handle(Invocation invocation, AsyncResponse asyncResp) throws Exception {       Object[] args = invocation.getArgs();       System.out.println(args);     }   }</code></li> <li>**Q: The exception is thrown when the microservices runtime: <code>java.lang.Error:not support def type:calss io.swagger.models.properties BaseIntegerProperty</code>? **</li> </ul> <p>A: Service Center can be upgraded to version 4.0.0+ to solve [Service Center latest version portal] (http://apache.org/dyn/closer.cgi/incubator/servicecomb/incubator-servicecomb-service-center /1.0.0-m1/).</p> <ul> <li>Q: Our API can not be accessed after microservices are up. It just returns 404 Not Found. The codes we use is as follows:</li> </ul> <p><code>java    @RestController    @RestSchema(schemaId = \"worker\")    public class WorkerController {      @RequestMapping(value=\"/count\", method=RequestMethod.GET)      public int getWorkerNumbers() {        ...      }    }</code></p> <p>A: Without specifying the base path, ServiceComb will use the classname as the base path. Hence, the path should be <code>/WorkerController/count</code> in the previous code. If you want to access path like <code>/count</code>, you need to specify base path as <code>/</code> as follows:    <code>java    @RequestMapping(value = \"/\")    public class WorkerController {}</code></p> <ul> <li>Q: What\\'s the default base path if I have not declared the value of RequestMapping annotation?</li> </ul> <p>A: Supposed the class name of your controller is HelloController, the base path is /HelloController.</p> <ul> <li> <p>Q: How to use the function of compressed data transmission\uff1f</p> </li> <li> <p>A: To enable the response data compression transmission capability on the server, the following configuration is required:</p> </li> </ul> <p><code>yaml   servicecomb:     rest:       server:         compression: true</code></p> <p>At the same time, the consumer side needs to synchronize the activation of configuration items:</p> <p><code>yaml   servicecomb:     rest:      client:        connection:          compression: true</code>   When the consumer sets the Accept Encoding: gzip, deflate field in the request header, the server will compress the response data based on the algorithm provided in this field and return it.</p>"},{"location":"question-and-answer/interface-compatibility/","title":"Micro Service Interface Compatibility FAQ","text":"<p>In the process of continuous iterative development of microservices, due to the continuous addition of new features, some old features are continually being modified, and interface compatibility issues face enormous challenges, especially in the running environment multi-version coexistence (grayscale release) ). This chapter mainly describes some practical suggestions for interface compatibility management and solutions to compatibility problems during use. Since microservices generally provide services externally through the REST interface, the interface here refers to the REST interface without special instructions.</p>"},{"location":"question-and-answer/interface-compatibility/#practice-of-ensuring-interface-compatibility","title":"Practice of ensuring interface compatibility","text":"<p>To prevent interface compatibility problems, developers are advised to follow the following principles when making interface changes (add, modify, delete, etc.).</p> <ol> <li>Only add interfaces, do not modify or delete interfaces.</li> <li>As a Provider, when adding an interface, the microservice version number is incremented accordingly. For example, change 2.1.2 to 2.1.3.</li> <li>As a Consumer, when using the new interface of the Provider, specify the minimum version number of the Provider. For example: servicecomb.references.[serviceName].version-rule=2.1.3+, The serviceName is the Provider's microservice name.</li> <li>In the service center, regularly clean up the old version of microservice information that is no longer used.</li> </ol> <p>If microservice version number is not changed and when startup, the meta info in service center will not overridden. The Consumers see old meta data. To prevent this happen, ServiceComb will stop boot when incompatible interface change and version is the same. In newly developed project, use development environment to bypass this check. </p> <pre><code>service_description:\n  environment: development\n</code></pre> <p>Please notice that consumer is also need reboot or old interface metadata will be used. </p>"},{"location":"question-and-answer/interface-compatibility/#interface-compatibility-common-problems-and-their-solutions","title":"interface compatibility common problems and their solutions","text":"<p>During the development phase, due to various interface modification, the data of the service center would not be cleaned up, and the interface call fails when debugging. Developers are advised to install and download a [frontend] of the service center (http://apache.org/dyn/closer.cgi/incubator/servicecomb/incubator-servicecomb-service-center/1.0.0-m1/), anytime Clean up service center data.</p> <p>If you use Huawei's public cloud online service center, you can log in directly using the management functions provided by the microservice engine to delete.</p> <p>During the release phase, you need to review the steps of the interface-compatible practices to ensure that interface compatibility issues are not online.</p> <p>If you accidentally miss one of these steps, it may lead to the following interface compatibility issues:</p> <ol> <li>If the interface is modified or deleted: some old Consumers will fail to request the new route of the new Provider.</li> <li>If you forget to modify the microservice version number: some new Consumers will fail to request the route of the old Provider.</li> <li>If you forget to configure the minimum dependent version of the Consumer: when the deployment order is to stop the Consumer first, then start the Consumer, then stop the Provider, and then start the Provider. The Consumer cannot obtain the new interface information, and the old interface is used. When the Provider starts, The Consumer initiates a call to the new interface that fails; or fails to call the new interface before the Provider started.</li> </ol> <p>Workarounds for problems: There are different interface compatibility issues and different handling methods. In extreme cases, you only need to clean up the Provider and Consumer microservices, and then restart the microservice. When the service call relationship is complexed, the interface compatibility problem will be more extensive and clean the Provider, and Consumer data will become complicated. Therefore, it is recommended to follow the above specifications to avoid incompatibility.</p>"},{"location":"question-and-answer/question_answer/","title":"Problem: How to customize the HTTP status code in the REST interface corresponding to a Java method?","text":"<p>Solution:</p> <p>For normal return values, this can be done with SwaggerAnnotation, for example:</p> <pre><code>@ApiResponse(code = 300, response = String.class, message = \"\")\npublic int test(int x) {\n  return 100;\n}\n</code></pre> <p>For the return value of the exception, you can do this by throwing a custom InvocationException, for example:</p> <pre><code>    public String testException(int code) {\n        String strCode = String.valueOf(code);\n        switch (code) {\n            case 200:\n                return strCode;\n            case 456:\n                throw new InvocationException(code, strCode, strCode + \" error\");\n            case 556:\n                throw new InvocationException(code, strCode, Arrays.asList(strCode + \" error\"));\n            case 557:\n                throw new InvocationException(code, strCode, Arrays.asList(Arrays.asList(strCode + \" error\")));\n            default:\n                break;\n        }\n\n        return \"not expected\";\n    }\n</code></pre>"},{"location":"question-and-answer/question_answer/#problem-how-to-customize-the-log-configuration-of-your-own-microservice","title":"Problem: How to customize the log configuration of your own microservice","text":"<p>** Solution:** ServiceComb does not bind the logger, use slf4j, users can freely choose log4j/log4j2/logback and so on. ServiceComb provides a log4j extension that supports incremental configuration of log4j's properties files on a standard log4j basis.</p> <ul> <li>By default, the configuration file is loaded from the path: \"classpath*:config/log4j.properties\"</li> <li>It will actually search all the <code>config/log4j.properties and config/log4j.*.properties</code> in the classpath, cut out the <code>\\*</code> part from the searched file, sort the alpha, then load it in order, and finally compose The file is used as the log4j configuration file.</li> <li>If you want to use ServiceComb's log4j extension, you need to call Log4jUtils.init, otherwise it will be used according to the rules of the standard logger.</li> </ul>"},{"location":"question-and-answer/question_answer/#problem-when-the-service-is-configured-with-multiple-types-of-transport-what-are-the-mechanisms-for-servicecomb-choose-which-transport-to-use-at-runtime","title":"Problem: When the service is configured with multiple types of transport, What are the mechanisms for ServiceComb choose which transport to use at runtime?","text":"<p>** Solution:**</p> <ul> <li> <p>ServiceComb's consumer, transport, handler, and producer are decoupled. The functions work together through contract definitions, that is, whether the consumer uses transparent rpc, or springmvc develops and uses a highway, or RESTful does not transmit on the network. Relationships and producers use transparent rpc, or jaxrs, or springmvc development, and there is no relationship between the receiver and the perception, business development methods and transmission methods.</p> </li> <li> <p>Consumer access producer, in the runtime transport selection, the general rule is: the consumer's transport and producer's endpoint intersection, if there are multiple transports after the intersection, then use in turn</p> </li> </ul> <p>Decomposed, there are the following scenarios:</p> <ul> <li>When a microservice producer provided both the highway and the RESTful endpoint</li> <li>Only the highway transport jar is deployed in the consumer process, only the producer's highway endpoint is accessed. \u00a0 * Only the RESTful transport jar is deployed in the consumer process, only the RESTful endpoint of the producer is accessed. \u00a0 * The consumer process, while deploying the highway and RESTful transport jar, will take turns accessing the producer's highway, RESTful endpoint</li> </ul> <p>If at this time, the consumer wants to use a transport to access the producer, it can be configured in the microservice.yaml of the consumer process, specifying the name of the transport:</p> <pre><code>servicecomb:\n  references:\n    transport: \n      &lt;service_name&gt;: highway\n</code></pre> <ul> <li>When a microservice producer only provided the endpoint of the highway</li> </ul> <p>* The consumer process only deploys the highway transport jar, and normally uses higway endpoint. \u00a0 * The consumer process can only be accessed if only the RESTful transport jar is deployed \u00a0 * The consumer process deploys both the highway and the RESTful transport jar, and the highway access is normally used.</p> <ul> <li>When a microservice producer only provided RESTful endpoints</li> </ul> <p>* The consumer process only deploys the highway transport jar and cannot access it. \u00a0 * The consumer process only deploys RESTful transport jars, which normally use RESTful access \u00a0 * The consumer process deploys both the highway and the RESTful transport jar, and the RESTful access is normally used.</p>"},{"location":"question-and-answer/question_answer/#problem-the-swagger-body-parameter-type-is-incorrectly-defined-resulting-in-no-content-information-for-the-content-registered-by-the-service-center","title":"Problem: The swagger body parameter type is incorrectly defined, resulting in no content information for the content registered by the service center.","text":"<p>Symptom:</p> <p>Define the following interface, put the parameters into the body to pass</p> <pre><code>/testInherate:\n    post:\n      operationId: \"testInherate\"\n      parameters:\n      - in: \"body\"\n        name: \"xxxxx\"\n        required: false\n        type: string\n      responses:\n        200:\n          description: \"response of 200\"\n          schema:\n            $ref: \"#/definitions/ReponseImpl\"\n</code></pre> <p>Define the interface in the above way. After the service is registered, the interface type: a string that is queried from the service center is lost and becomes:</p> <pre><code>/testInherate:\n    post:\n      operationId: \"testInherate\"\n      parameters:\n      - in: \"body\"\n        name: \"xxxxx\"\n        required: false\n      responses:\n        200:\n          description: \"response of 200\"\n          schema:\n            $ref: \"#/definitions/ReponseImpl\"\n</code></pre> <p>If the client does not place a swagger, the following exception is also reported:</p> <p>Caused by: java.lang.ClassFormatError: Method \"testInherate\" in class ? has illegal signature. \"</p> <p>Solution:</p> <p>When defining the type of the body parameter, you can't use type directly instead use the schema.</p> <pre><code>/testInherate:\n    post:\n      operationId: \"testInherate\"\n      parameters:\n      - in: \"body\"\n        name: \"request\"\n        required: false\n        schema:\n          type: string\n      responses:\n        200:\n          description: \"response of 200\"\n          schema:\n            $ref: \"#/definitions/ReponseImpl\"\n</code></pre>"},{"location":"question-and-answer/question_answer/#problem-does-the-microservices-framework-service-call-use-long-live-connection","title":"Problem: Does the microservices framework service call use long live connection?","text":"<p>** Solution:**</p> <p>Http uses a long connection (with a timeout), and the highway mode uses a long connection (always on).</p>"},{"location":"question-and-answer/question_answer/#problem-when-the-service-is-disconnected-from-the-service-center-will-the-registration-information-be-deleted-automatically","title":"Problem: When the service is disconnected from the service center, will the registration information be deleted automatically?","text":"<p>** Solution:**</p> <p>The service center heartbeat detects that the service instance is unavailable, only the service instance information is removed, and the static data of the service is not removed.</p>"},{"location":"question-and-answer/question_answer/#problem-how-does-the-microservices-framework-achieve-transparent-transmission-of-data-between-multiple-microservices","title":"Problem: How does the microservices framework achieve transparent transmission of data between multiple microservices?","text":"<p>** Solution:**</p> <p>Transmitting data into:</p> <pre><code>CseHttpEntity&lt;xxxx.class&gt; httpEntity = new CseHttpEntity&lt;&gt;(xxx);\n//Transmission content\nhttpEntity.addContext(\"contextKey\",\"contextValue\");\nResponseEntity&lt;String&gt; responseEntity = RestTemplateBuilder.create().exchange(\"cse://springmvc/springmvchello/sayhello\",HttpMethod.POST,httpEntity,String.class);\n</code></pre> <p>Transparent data acquisition:</p> <pre><code>@Override\n@RequestMapping(path=\"/sayhello\",method = RequestMethod.POST)\npublic String sayHello(@RequestBody Person person,InvocationContext context){\n    //Transparent data acquisition\n    context.getContext();\n    return \"Hello person \" + person.getName();\n}\n</code></pre>"},{"location":"question-and-answer/question_answer/#problem-how-the-microservices-framework-service-customizes-the-return-status-code","title":"Problem: How the microservices framework service customizes the return status code","text":"<p>** Solution:**</p> <pre><code>@Override\n@RequestMapping(path = \"/sayhello\",method = RequestMethod.POST)\npublic String sayHello(@RequestBody Person person){\n    InvocationContext context = ContextUtils.getInvocationContext();\n    //\u81ea\u5b9a\u4e49\u72b6\u6001\u7801\n    context.setStatus(Status.CREATED);\n    return \"Hello person \"+person.getName();\n}\n</code></pre>"},{"location":"question-and-answer/question_answer/#problem-partial-exposure-of-body-model","title":"Problem: Partial exposure of body Model","text":"<p>** Solution:**</p> <p>In the body object corresponding to an interface, there may be some attributes that are internal. Do not want to open it. Do not bring it out when generating the schema. Use:</p> <pre><code>@ApiModelProperty(hidden = true)\n</code></pre>"},{"location":"question-and-answer/question_answer/#problem-the-framework-obtains-the-address-of-the-remote-consumer","title":"Problem: The framework obtains the address of the remote consumer","text":"<p>** Solution:**</p> <p>If you use the http rest method (using the transport-rest-vertx dependency) you can get it in the following way:</p> <pre><code>HttpServletRequest request = (HttpServletRequest) invocation.getHandlerContext().get(RestConst.REST_REQUEST);\nString host = request.getRemoteHost();\n</code></pre> <p>The actual scene is to take the external address, so it should be LB passed to edgeservice, and edgeService is then passed to the context and passed.</p>"},{"location":"question-and-answer/question_answer/#problem-description-of-the-handler","title":"Problem: Description of the handler","text":"<p>** Solution:**</p> <p>Consumer default handler is simpleLB, and the handler chain will use this when there is no configuration, if the handler is configured, it must contain the lb handler. Otherwise the call error, need to be described in the document.</p>"},{"location":"question-and-answer/question_answer/#problem-netty-version-problem","title":"Problem: Netty version problem","text":"<p>** Solution:**</p> <p>Netty3 and netty4 are completely different tripartites because the coordinates are not the same as the package, so they can coexist, but pay attention to the minor version problem, the version that the small version must use.</p>"},{"location":"question-and-answer/question_answer/#problem-service-timeout-settings","title":"Problem: Service Timeout Settings","text":"<p>** Solution:**</p> <p>Add the following configuration to the microservice description file (microservice.yaml):</p> <pre><code>servicecomb:\n  request:\n    timeout: 30000\n</code></pre>"},{"location":"question-and-answer/question_answer/#problem-is-there-a-required-for-the-processing-chains-sequence-of-service-governance","title":"Problem: Is there a required for the processing chain's sequence of service governance?","text":"<p>Solution:</p> <p>The order of the processing chains is different, and the system works differently. List the common questions below.</p> <p>1, loadbalance and bizkeeper-consumer</p> <p>These two sequences can be combined randomly. But the behavior is different.</p> <p>When loadbalance is in the front, the retry function provided by loadbalance will occur when bizkeeper-consumer throws an exception, such as timeout. But if you have done a fallback policy configuration, such as return null, then loadbalance will not retry.</p> <p>If loadbalance is behind, the retry will extend the timeout. Even if the retry is successful, if the timeout period set by bizkeeper-consumer is not enough, the final call result will also fail.</p> <p>2, tracing-consumer, sla-consumer, tracing-provider, sla-provider</p> <p>These processing chains are recommended to be placed at the very beginning of the processing chain to ensure that the success and failure of the log can be recorded (because the log requires IP and other information, for consumers, can only be placed behind the loadbalance).</p> <p>If you do not need to record the exception returned by the client, you can put it to the end and only pay attention to the error returned by the network layer. However, if the bizkeeper-consumer timeout returns earlier, the log may not be logged.</p> <ol> <li>Suggested order</li> </ol> <p>Consumer: loadbalance, tracing-consumer, sla-consumer, bizkeeper-consumer</p> <p>Provider: tracing-provider, sla-provider, bizkeeper-provider</p> <p>This order is sufficient for most scenarios and is not easy to cause errors.</p>"},{"location":"question-and-answer/question_answer/#problem-the-meaning-of-config-item-servicecombuploadsmaxsize-in-file-uploading","title":"Problem: the meaning of config item servicecomb.uploads.maxSize in file uploading","text":"<p>config item: servicecomb.uploads.maxSize</p> <p>meaning: The maximum allowable size of http body in bytes, the default value of -1 means unlimited.</p>"},{"location":"references-handlers/intruduction/","title":"Intruductions","text":""},{"location":"references-handlers/intruduction/#handlers-reference","title":"Handlers Reference","text":"<p>Handlers are the core components of ServiceComb, which form the basis of service operation and control. ServiceComb handles load balancing, fuse tolerance, flow control, and more through the Handlers.</p>"},{"location":"references-handlers/intruduction/#enable-handlers","title":"Enable Handlers","text":"<p>There are Consumer Handlers and Provider Handlers. Enable handlers in microservice.yaml:</p> <pre><code>servicecomb:\n  handler:\n    chain:\n      Consumer:\n        default: qps-flowcontrol-consumer,loadbalance\n      Provider: \n        default: qps-flowcontrol-provider\n</code></pre> <p>We can also enable different handlers for each microservice, </p> <pre><code>servicecomb:\n  handler:\n    chain:\n      Consumer:\n        default: auth,qps-flowcontrol-consumer,loadbalance\n        service:\n          authentication-server: qps-flowcontrol-consumer,loadbalance\n</code></pre> <p>Requests to authentication-server, auth handler is enabled, and others not. </p>"},{"location":"references-handlers/intruduction/#development-handlers","title":"Development Handlers","text":"<p>The developer's custom handlers consists of the following steps. Since the core component of ServiceComb is the handlers, developers can refer to the implementation of the handlers directory to learn more about the Handlers. Here are a few key steps to summarize:</p> <ul> <li>Implement Handler interface</li> </ul> <pre><code>public class AuthHandler implements Handler {\n  @Override\n  public void handle(Invocation invocation, AsyncResponse asyncResponse) throws Exception {\n    String token = invocation.getContext(Constants.CONTEXT_HEADER_AUTHORIZATION);\n    if (token == null) {\n      asyncResponse.consumerFail(new InvocationException(403, \"forbidden\", \"not authenticated\"));\n      return;\n    }\n    Jwt jwt = JwtHelper.decode(token);\n    try {\n      jwt.verifySignature(BeanUtils.getBean(\"authSigner\"));\n    } catch (InvalidSignatureException e) {\n      asyncResponse.consumerFail(new InvocationException(403, \"forbidden\", \"not authenticated\"));\n      return;\n    }\n    invocation.next(asyncResponse);\n  }\n}\n</code></pre> <ul> <li>Add *.handler.xml file, give handler a name</li> </ul> <pre><code>&lt;config&gt;\n  &lt;handler id=\"auth\"\n    class=\"org.apache.servicecomb.authentication.gateway.AuthHandler\" /&gt;\n&lt;/config&gt;\n</code></pre> <ul> <li>Enable the newly added Handlers in microservice.yaml</li> </ul> <pre><code>servicecomb:\n  handler:\n    chain:\n      Consumer:\n        default: auth,loadbalance\n        service:\n          authentication-server: loadbalance\n</code></pre>"},{"location":"references-handlers/loadbalance/","title":"load balancing","text":""},{"location":"references-handlers/loadbalance/#scenario","title":"Scenario","text":"<p>ServiceComb provides very powerful load balancing capabilities, which consists of two core parts. The first part DiscoveryTree, whose core part is DiscoveryFilter, groups microservice instances by their interface compatibility, data center, status, etc. The second part is the load balancing scheme based on Ribbon, which supports various load balancing policies(IRule) include random, sequential, response time-based weights, and ServerListFilterExt which is based on Invocation state.</p> <p>DiscoveryTree's logic is more complex, its processing progress is as below: </p> <p>Load balancing can be configured in the Consumer processing chain, the handler name is loadbalance, as follows:</p> <pre><code>servicecomb:\n  handler:\n    chain:\n      Consumer:\n        default: loadbalance\n</code></pre> <p>POM dependence:</p> <pre><code> &lt;dependency&gt;\n  &lt;groupId&gt;org.apache.servicecomb&lt;/groupId&gt;\n  &lt;artifactId&gt;handler-loadbalance&lt;/artifactId&gt;\n  &lt;/dependency&gt;\n</code></pre>"},{"location":"references-handlers/loadbalance/#routing-and-forwarding-by-data-center-information","title":"Routing and forwarding by data center information","text":"<p>Service providers and consumers can declare their service center information in microservice.yaml:</p> <pre><code>servicecomb:\n  datacenter:\n    name: mydatacenter\n    region: my-Region\n    availableZone: my-Zone\n</code></pre> <p>Consumers compare their own data center information and providers' information, preferentially forward the request to the provider instance in the same region and availableZone; if the target instance is not available, it forwards request to the instance in the same region; if the target still does not exist, it forwards requests to other instances.</p> <p>The region and availableZone here are general concepts, users can determine their business meanings to apply them to resource-isolated scenarios. See Logical isolation relationships between microservice instances for more details of the isolation.</p> <p>This rule is enabled by default. If it is not needed, set servicecomb.loadbalance.filter.zoneaware.enabled to false. Data center information isolation is implemented in ZoneAwareDiscoveryFilter.</p>"},{"location":"references-handlers/loadbalance/#routing-and-forwarding-by-instance-attributes","title":"Routing and forwarding by instance attributes","text":"<p>Users can specify the properties of microservice instances in microservice.yaml, or by calling service center APIs.</p> <pre><code>instance_description:\n  properties:\n    tags:\n      tag_key: tag_value\n</code></pre> <p>Consumers can specify provider instances' attributes to determine which instances to call.</p> <pre><code>servicecomb:\n  loadbalance:\n    # Here the \"provider\" means the config items below only take effect on the service named \"provider\"\n    # In cross-app invocation, the AppID should be prefixed, like \"AppIDOfProvider:provider\"\n    provider:\n      transactionControl:\n        options:\n          tags:\n            tag_key: expected_tag_value\n</code></pre> <p>The above configuration shows that only the instances of \"provider\" with the tag attribute <code>tag_key:expected_tag_value</code> are called.</p> <p>This rule needs to be configured separately for each service. Global rule for all services is not supported.</p> <p>This rule is enabled by default, it can be disabled by setting <code>servicecomb.loadbalance.filter.instanceProperty.enabled</code> to false. The instance attributes based routing policy is implemented in <code>InstancePropertyDiscoveryFilter</code>.</p>"},{"location":"references-handlers/loadbalance/#routing-and-forwarding-by-instance-attributes-with-hierarchy-value","title":"Routing and forwarding by instance attributes with hierarchy value","text":"<p>This is a extension of the feature above.</p> <p>You can specify the properties of microservice instances in microservice.yaml with hierarchy value, which is separated by <code>.</code> symbol.</p> <pre><code>instance_description:\n  properties:\n    KEY: a.b.c\n</code></pre> <p>Consumer need to specify the key of instance which is used to match provider, the default key is <code>environment</code></p> <pre><code>servicecomb:\n  loadbalance:\n    filter:\n      priorityInstanceProperty:\n        key: KEY\n</code></pre> <p>Assuming there is a consumer instance with property value <code>a.b.c</code>, the match priority of provider will be <code>a.b.c</code>&gt;<code>a.b</code>&gt;<code>a</code>&gt;<code>[empty]</code> and the table shown below gives detail match priority. | consumer | match priority of provider| | :--- | :--- |  |a.b.c|a.b.c&gt;a.b&gt;a&gt;[empty]| |a.b|a.b&gt;a&gt;[empty]| |a|a&gt;[empty]| |[empty]|[empty]|</p> <p>Note that [empty] is represent for the instances which is not set value of this property key</p> <p>This rule is NOT enabled by default, which can be enabled by setting <code>servicecomb.loadbalance.filter.priorityInstanceProperty.enabled</code> to true. The policy is implemented in <code>PriorityInstancePropertyDiscoveryFilter</code>.</p>"},{"location":"references-handlers/loadbalance/#instance-isolation","title":"Instance isolation","text":"<p>Developers can configure instance-isolated parameters to temporarily drop access to the wrong instance, improving system reliability and performance. Below are the configuration items and default values:</p> <pre><code>servicecomb:\n  loadbalance:\n    isolation:\n      enabled: true\n      errorThresholdPercentage: 0\n      enableRequestThreshold: 5\n      singleTestTime: 60000\n      continuousFailureThreshold: 5\n</code></pre> <p>The interval of isolation calculation is 1 minute. According to the above configuration, in 1 minute, if the total number of requests is greater than 5, and more than 2 consecutive  errors occur, the instance is isolated.</p> <p>The default value of errorThresholdPercentage is 0, indicates that the rule is ommited. The item should be a integer less than 100, for example 20, then within 1 minutes, if the total number of request is greater than 5 and [1] error rate is greater than 20% or [2] more than 2 consecutive  errors occur, is instance is isolated.</p> <p>After 60 seconds, the instance will be re-enabled and accessible if it matches the rules of load balancing policy.</p> <p>Notes:</p> <ol> <li>When error rate reaches the threshold, is instance is isolated and the error rate will be calculated again after the interval. Then with the successful accesses, the rate will decrease and become less than the threshold, then instance is available again. Since the rate is calculated by number of requests, if the total requests reaches the threshold and the error rate is much greater than its threshold, the instance would take a long time to recover.</li> <li>ServiceComb starts a thread in the background to detect the instance state, and checks the instance state every 10 seconds (if the instance is accessed within 10 seconds, it is not detected). If the detection fails, the error number is accumulated with 1. The count here also affects instance isolation.</li> </ol> <p>The default instance state detection mechanism is to send a telnet instruction, refer to the implementation of SimpleMicroserviceInstancePing. Users can overwrite the status detection mechanism with the following two steps:</p> <ol> <li>Implement the MicroserviceInstancePing interface</li> <li>Configure SPI: Add META-INF/services/org.apache.servicecomb.serviceregistry.consumer.MicroserviceInstancePing, the content is the full path of the implementation class</li> </ol> <p>Developers can configure different isolation policies for different microservices. Just add a service name to the configuration item, for example:</p> <pre><code>servicecomb:\n  loadbalance:\n    myservice:\n      isolation:\n        enabled: true\n        errorThresholdPercentage: 20\n        enableRequestThreshold: 5\n        singleTestTime: 10000\n        continuousFailureThreshold: 2\n</code></pre> <p>This rule is enabled by default and can be turned off by setting servicecomb.loadbalance.filter.isolation.enabled to false. Data center information isolation is implemented in IsolationDiscoveryFilter.</p>"},{"location":"references-handlers/loadbalance/#configuring-route-rules","title":"Configuring route rules","text":"<p>Developers can specify load balancing policies through configuration items.</p> <pre><code>servicecomb:\n  loadbalance:\n    strategy:\n      name: RoundRobin # Support RoundRobin,Random,WeightedResponse,SessionStickiness\n</code></pre> <p>Developers can configure policies for different microservices by adding a service name, for example:</p> <pre><code>servicecomb:\n  loadbalance:\n    myservice:\n      strategy:\n        name: RoundRobin # Support RoundRobin,Random,WeightedResponse,SessionStickiness\n</code></pre> <p>Each policy has some specific configuration items.</p> <ul> <li>SessionStickiness</li> </ul> <pre><code>servicecomb:\n  loadbalance:\n    SessionStickinessRule:\n      sessionTimeoutInSeconds: 30 # Client idle time, after the limit is exceeded, select the server behind\n      successiveFailedTimes: 5 # The number of client failures will switch after the server is exceeded.\n</code></pre>"},{"location":"references-handlers/loadbalance/#set-retry-strategy","title":"Set retry strategy","text":"<p>The load balancing module also supports the policy retry.</p> <pre><code>servicecomb:\n  loadbalance:\n    retryEnabled: false\n    retryOnNext: 0\n    retryOnSame: 0\n</code></pre> <p>Retry is not enabled by default. Developers can set different strategies for different services:</p> <pre><code>servicecomb:\n  loadbalance:\n    myservice\uff1a\n      retryEnabled: true\n      retryOnNext: 1\n      retryOnSame: 0\n</code></pre> <p>retryOnNext indicates that after the failure, according to the load balancing policy, re-select an instance to retry (may choose the same instance), while retryOnSame means that the last failed instance is still used for retry.</p>"},{"location":"references-handlers/loadbalance/#customization","title":"Customization","text":"<p>The load balancing module provides various configurations that can support most application scenarios. It also provides flexible extension capabilities, including DiscoveryFilter, ServerListFilterExt, ExtensionsFactory (extension IRule, RetryHandler, etc.). The loadbalance module itself contains the implementation of each extension. The brief introduction of extending load balancing module is described below. Developers can download the ServiceComb source code to see the details.</p> <ul> <li>DiscoveryFilter</li> <li>Implement the DiscoveryFilter interface</li> <li> <p>Configure SPI: Add META-INF/services/org.apache.servicecomb.serviceregistry.discovery.DiscoveryFilter file with the full path of the implementation class</p> </li> <li> <p>ServerListFilterExt</p> </li> <li>Implement the ServerListFilterExt interface</li> <li>Configure SPI: Add META-INF/services/org.apache.servicecomb.loadbalance.ServerListFilterExt file, the content is the full pathof the implementation class</li> <li> <p>Note: This instruction applies to version 1.0.0 and later. Earlier versions are extended in a different way.</p> </li> <li> <p>ExtensionsFactory</p> </li> <li>Implement the ExtensionsFactory and publish it as a spring bean using @Component.</li> </ul>"},{"location":"references-handlers/publickey/","title":"public key authentication","text":""},{"location":"references-handlers/publickey/#scene-description","title":"Scene Description","text":"<p>Public key authentication is a simple and efficient authentication mechanism between microservices provided by ServiceComb. Its security is based on the trust between microservices and service centers, namely microservices and service centers. The authentication mechanism must be enabled first. Its basic process is as follows:</p> <ol> <li>When the microservice starts, generate a secret key pair and register the public key to the service center.</li> <li>The consumer signs the message with his or her private key before accessing the provider.</li> <li>The provider obtains the consumer public key from the service center and verifies the signed message.</li> </ol> <p>Public key authentication needs to be enabled for both consumers and providers.</p> <pre><code>servicecomb:\n  handler:\n    chain:\n      Consumer:\n        default: auth-consumer\n      Provider:\n        default: auth-provider\n</code></pre> <p>POM Dependency:</p> <ul> <li>Add dependencies in pom.xml:</li> </ul> <p><code>&lt;dependency&gt;       &lt;groupId&gt;org.apache.servicecomb&lt;/groupId&gt;       &lt;artifactId&gt;handler-publickey-auth&lt;/artifactId&gt;     &lt;/dependency&gt;</code></p>"},{"location":"references-handlers/publickey/#configuring-black-and-white-list","title":"Configuring black and white list","text":"<p>Based on the public key authentication mechanism, ServiceComb provides a black and white list function. Through the black and white list, you can control which other services are allowed to be accessed by the microservice. Currently supported by configuring service attributes, the configuration items are as follows:</p> <pre><code>servicecomb:\n  publicKey:\n    accessControl:\n      black:\n        list01:\n          category: property ## property, fixed value\n          propertyName: serviceName ## property name\n# property value matches expression.\n# only supports prefix match and postfix match and exactly match.\n#, e.g., hacker*, *hacker, hacker\n          rule: hacker\n      white:\n        list02:\n          category: property\n          propertyName: serviceName\n          rule: cust*\n</code></pre> <p>The above rules are configured with black and white rule. includePathPatterns is set the request path that needs auth, and excludePathPatterns is set the request path that not need auth. black/white is microservice black and white rules.</p> <p>IncludePathPatterns, excludePathPatterns Supports three types of matching rules: prefix (xxx/), suffix (/xxx) and exact match.</p> <p>Logic for determining whether the current request requires authentication:</p> <p>1.Check whether the path of current request matches the excludePathPatterns setting rule. If yes, authentication is not required.</p> <p>2.If excludePathPatterns does not match, check whether a rule is configured for includePathPatterns. If no, all requests need to be authenticated; If set, check whether the path of current request matches the rule. If yes, authentication is required. If no, authentication is not required.</p> <p>Microservice black/white determination rules: which do not allow microservice names to be accessed by hackers; whitelists allow access to services with microservice names named cust.</p> <p>ServiceComb provides [trust-sample] (https://github.com/apache/servicecomb-samples/tree/master/java-chassis-samples/trust-sample) to demonstrate the black and white list feature.</p>"},{"location":"security/rsa/","title":"Using RSA certification","text":""},{"location":"security/rsa/#scene-description","title":"Scene Description","text":"<p>Users can enable RSA authentication between services through simple configuration to ensure the security of the service interface.</p> <p>Detailed introduction [public key authentication] (../references-handlers/publickey.md)</p>"},{"location":"security/rsa/#consumer-configuration","title":"Consumer Configuration","text":"<ul> <li>Add dependencies in pom.xml:</li> </ul> <pre><code>   &lt;dependency&gt;\n      &lt;groupId&gt;org.apache.servicecomb&lt;/groupId&gt;\n      &lt;artifactId&gt;handler-publickey-auth&lt;/artifactId&gt;\n    &lt;/dependency&gt;\n</code></pre> <ul> <li>Added to the processing chain in microservice.yaml</li> </ul> <pre><code>servicecomb:\n  handler:\n    chain:\n      Consumer:\n        default: auth-consumer\n</code></pre>"},{"location":"security/rsa/#provider-configuration","title":"Provider Configuration","text":"<ul> <li>Add dependencies in pom.xml:</li> </ul> <pre><code>&lt;dependency&gt; \n  &lt;groupId&gt;org.apache.servicecomb&lt;/groupId&gt; \n  &lt;artifactId&gt;handler-publickey-auth&lt;/artifactId&gt; \n&lt;/dependency&gt;\n</code></pre> <ul> <li>Added to the processing chain in microservice.yaml</li> </ul> <pre><code>servicecomb:\n  handler:\n    chain:\n      Provider:\n        default: auth-provider\n</code></pre>"},{"location":"security/tls/","title":"Using TLS","text":""},{"location":"security/tls/#scene-description","title":"Scene Description","text":"<p>Users can enable TLS communication through simple configuration to ensure data transmission security.</p>"},{"location":"security/tls/#external-service-communication-configuration","title":"External Service Communication Configuration","text":"<p>The configuration related to external service communication is written in the microservice.yaml file.</p> <ul> <li>Service Center, Configuration Center TLS communication configuration \u00a0\u00a0 The connection between the microservices and the service center and the configuration center can be enabled by changing http to https. The configuration example is as follows:</li> </ul> <p><code>yaml   servicecomb:     service:       registry:         address: https://127.0.0.1:30100     config:       client:         serverUri: https://127.0.0.1:30103</code></p> <ul> <li>Service provider enables TLS communication \u00a0\u00a0 When the service provider configures the service listening address, it can open TLS communication by appending <code>?sslEnabled=true</code> to the address. The example is as follows:</li> </ul> <p><code>yaml   servicecomb:     rest:       address: 0.0.0.0:8080?sslEnabled=true     highway:       address: 0.0.0.0:7070?sslEnabled=true</code></p>"},{"location":"security/tls/#certificate-configuration","title":"Certificate Configuration","text":"<p>The certificate configuration item is written in the microservice.yaml file. It supports the unified development of certificates. It can also add tags for finer-grained configuration. The tag configuration overrides the global configuration. The configuration format is as follows:</p> <pre><code>ssl.[tag].[property]\n</code></pre> <p>The common tags are as follows:</p> Project tag Service Center sc.consumer Configuration Center cc.consumer Kanban Center mc.consumer Rest server rest.provider Highway Server highway.provider Rest client rest.consumer Highway Client highway.consumer auth client apiserver.consumer Generally, there is no need to configure tags. The normal situation is divided into three categories: 1. Connecting internal services 2. As a server 3. As a client, if the certificates required by these three types are inconsistent, then you need to use tags to distinguish <p>The certificate configuration items are shown in Table 1. Certificate Configuration Item Description Table. Table 1 Certificate Configuration Item Description Table</p> Configuration Item Default Value Range of Value Required Meaning Caution Ssl.engine jdk - No ssl protocol, provide jdk/openssl options default jdk ssl.protocols TLSv1.2 - No Protocol List separated by comma ssl.ciphers TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH _AES_128_GCM_SHA256 - No List of laws separated by comma ssl.authPeer false - No Whether to authenticate the peer - ssl.checkCN.host false - No Check whether the CN of the certificate is checked. This configuration item is valid only on the Consumer side and is valid using the http protocol. That is, the Consusser side uses the rest channel. Invalid for Provider, highway, etc. The purpose of checking CN is to prevent the server from being phishing, refer to Standard definition: https://tools.ietf.org/html/rfc2818.  ssl.trustStore trust.jks - No Trust certificate file - ssl.trustStoreType JKS - No Trust Certificate Type - ssl.trustStoreValue - - No Trust Certificate Password - ssl.keyStore server.p12 - No Identity Certificate File - ssl.keyStoreType PKCS12 - No Identity Certificate Type - ssl.keyStoreValue - - No Identity Certificate Password - ssl.crl revoke.crl - No Revoked Certificate File - ssl.sslCustomClass - org.apache.servicecomb.foundation.ssl.SSLCustom implementation class No SSLCustom class implementation for developers to convert passwords, file paths, etc. - <p>Description:</p> <ul> <li>The default protocol algorithm is a high-intensity encryption algorithm. The JDK needs to install the corresponding policy file. Reference: http://www.oracle.com/technetwork/java/javase/downloads/jce8-download-2133166.html. You can use a non-high-intensity algorithm in your profile configuration.</li> <li>Microservice consumers, can specify certificates for different providers (current certificates are issued according to HOST, different providers use a certificate storage medium, this medium is also used by the microservice access service center and configuration center ).</li> </ul>"},{"location":"security/tls/#sample-code","title":"Sample Code","text":"<p>An example of a configuration for enabling TLS communication in the microservice.yaml file is as follows:</p> <pre><code>servicecomb:\n  service:\n    registry:\n      address: https://127.0.0.1:30100\n  config:\n    client:\n      serverUri: https://127.0.0.1:30103\n  rest:\n    address: 0.0.0.0:8080?sslEnabled=true\n  highway:\n    address: 0.0.0.0:7070?sslEnabled=true\n\n#########SSL options\nssl.protocols: TLSv1.2\nssl.authPeer: true\nssl.checkCN.host: true\n\n#########certificates config\nssl.trustStore: trust.jks\nssl.trustStoreType: JKS\nssl.trustStoreValue: Changeme_123\nssl.keyStore: server.p12\nssl.keyStoreType: PKCS12\nssl.keyStoreValue: Changeme_123\nssl.crl: revoke.crl\nssl.sslCustomClass: org.apache.servicecomb.demo.DemoSSLCustom\n</code></pre>"},{"location":"start/architecture/","title":"Java Chassis Architecture","text":""},{"location":"start/architecture/#basic-framework","title":"Basic Framework","text":""},{"location":"start/architecture/#purpose","title":"Purpose","text":"<p>1.To decouple the programming model and communication model, so that a programming model can be combined with any communication models as needed. Application developers only need to focus on APIs during development and can flexibly switch communication models during deployment. Services can also be switched over to a legacy system. The developers simply need to modify the configuration file(or annotation) released by the service.</p> <p>Currently, applications can be developed in Spring MVC, JAX-RS, or transparent RPC mode.</p> <ol> <li>Built-in API-first support. Through contract standardize micro-service development,  realizing cross-language communication, and supporting software toolchain (contract generation code, code generation contract, etc.)  development, to construct a complete development ecology.</li> </ol> <p>3.To define common microservice running model, encapsulating fault tolerance methods to process which from service discovery to interaction process of microservices, The running model can be customized or extended.</p>"},{"location":"start/deployment-on-cloud/","title":"Deployment on cloud","text":"<p>\u672c\u7ae0\u8282\u4e3b\u8981\u63cf\u8ff0\u5fae\u670d\u52a1\u53d1\u5e03\u5230\u534e\u4e3a\u516c\u6709\u4e91\u4e0a\u3002\u4e0a\u4e91\u914d\u7f6e\u7684\u57fa\u672c\u539f\u5219\u662f\uff1a\u53ea\u9700\u8981\u5bf9microservice.yaml\u8fdb\u884c\u9002\u5f53\u7684\u914d\u7f6e\uff0c\u4ee5\u53ca\u5728pom\u4e2d\u6dfb\u52a0\u989d\u5916\u7684\u4f9d\u8d56\uff0c\u5c31\u53ef\u4ee5\u4f7f\u7528\u76f8\u5173\u7684\u529f\u80fd\u3002</p>"},{"location":"start/deployment-on-cloud/#_1","title":"\u4e00\u952e\u5f0f\u914d\u7f6e","text":"<p>\u516c\u6709\u4e91\u7248\u672c\u63d0\u4f9b\u4e86\u4e00\u952e\u5f0f\u7b80\u5316\u914d\u7f6e\u7684\u65b9\u5f0f\uff0c\u8ba9\u57fa\u4e8e\u5f00\u6e90\u7248\u672c\u5f00\u53d1\u7684\u5e94\u7528\u5feb\u901f\u5207\u6362\u4e3a\u4e91\u4e0a\u5e94\u7528\uff0c\u76f4\u63a5\u4f7f\u7528\u516c\u6709\u4e91\u63d0\u4f9b\u7684\u7070\u5ea6\u53d1\u5e03\u3001\u670d\u52a1\u6cbb\u7406\u7b49\u529f\u80fd\u3002</p> <ul> <li>\u589e\u52a0\u4f9d\u8d56\u5173\u7cfb(pom.xml)</li> </ul> <pre><code>&lt;dependency&gt; \n  &lt;groupId&gt;com.huawei.paas.cse&lt;/groupId&gt;  \n  &lt;artifactId&gt;cse-solution-service-engine&lt;/artifactId&gt; \n&lt;/dependency&gt;\n</code></pre> <p>\u5f00\u53d1\u8005\u53ea\u9700\u8981\u914d\u7f6e\u5bf9cse-solution-service-engine\u4f9d\u8d56\uff0c\u5c31\u5b8c\u6210\u4e86\u516c\u6709\u4e91\u7684\u6240\u6709\u914d\u7f6e\u3002\u8fd9\u4e2a\u4f9d\u8d56\u5173\u7cfb\u4e3b\u8981\u7ed9\u5f00\u53d1\u8005\u505a\u4e86\u5982\u4e0b\u4e8b\u60c5\uff1a</p> <ul> <li> <p>\u5f15\u5165\u76f8\u5173\u4f9d\u8d56\u7684\u7ec4\u4ef6</p> </li> <li> <p>\u589e\u52a0\u9ed8\u8ba4\u914d\u7f6e\u9879\u3002\u9ed8\u8ba4\u914d\u7f6e\u5305\u542b\u4e86\u5904\u7406\u94fe\u3001\u8d1f\u8f7d\u5747\u8861\u7b56\u7565\u7b49\u3002</p> </li> </ul> <p>\u53ef\u4ee5\u901a\u8fc7\u67e5\u770bpom\u5185\u5bb9\uff0c\u4ee5\u53ca\u8fd9\u4e2ajar\u5305\u91cc\u9762\u7684microservice.yaml\u6587\u4ef6\u67e5\u770b\u5f15\u5165\u7684\u7ec4\u4ef6\u548c\u589e\u52a0\u7684\u914d\u7f6e\u9879\u3002\u5728\u4e0b\u9762\u7684\u7ae0\u8282\u4e2d\uff0c\u8be6\u7ec6\u89e3\u91ca\u4e0a\u4e91\u589e\u52a0\u7684\u7ec4\u4ef6\u4ee5\u53ca\u4ed6\u4eec\u7684\u4f5c\u7528\uff0c\u8ba9\u5f00\u53d1\u8005\u66f4\u52a0\u6df1\u5165\u7684\u4e86\u89e3\u5404\u79cd\u6280\u672f\u7ec6\u8282\u3002</p>"},{"location":"start/deployment-on-cloud/#_2","title":"\u8fde\u63a5\u670d\u52a1\u4e2d\u5fc3","text":""},{"location":"start/deployment-on-cloud/#_3","title":"\u529f\u80fd\u63cf\u8ff0","text":"<p>\u670d\u52a1\u4e2d\u5fc3\u5b9e\u73b0\u6ce8\u518c\u548c\u53d1\u73b0\uff0c\u5728FusionStage/ServiceStage\u67e5\u770b\u5fae\u670d\u52a1\u76ee\u5f55\uff0c\u90fd\u9700\u8981\u5fae\u670d\u52a1\u8fde\u63a5\u4e0a\u670d\u52a1\u4e2d\u5fc3\u3002</p>"},{"location":"start/deployment-on-cloud/#_4","title":"\u914d\u7f6e\u53c2\u8003","text":"<ul> <li>\u589e\u52a0\u4f9d\u8d56\u5173\u7cfb(pom.xml)</li> </ul> <p>\u5982\u679c\u8fde\u63a5\u670d\u52a1\u4e2d\u5fc3\u4f7f\u7528https\u534f\u8bae/AK/SK\u8ba4\u8bc1\uff0c\u8be5jar\u4f9d\u8d56\u5fc5\u9009\u3002\u5982\u679c\u662fhttp\u534f\u8bae\uff0c\u5e76\u4e0d\u5305\u542btoken\u9a8c\u8bc1\uff0c\u5219\u65e0\u9700\u5f15\u5165\u3002</p> <pre><code>&lt;dependency&gt; \n  &lt;groupId&gt;com.huawei.paas.cse&lt;/groupId&gt;  \n  &lt;artifactId&gt;foundation-auth&lt;/artifactId&gt; \n&lt;/dependency&gt;\n</code></pre> <ul> <li>\u914d\u7f6e\u9879(microservice.yaml\uff09</li> </ul> <pre><code>servicecomb:\n service:\n  registry:\n   address: https://servicecomb.cn-north-1.myhwclouds.com:443    #\u6839\u636e\u5b9e\u9645\u5730\u5740\u914d\u7f6e\u670d\u52a1\u4e2d\u5fc3\u5730\u5740\n</code></pre> <p>\u8be5\u914d\u7f6e\u9879\u914d\u7f6e\u4e86\u670d\u52a1\u4e2d\u5fc3\u7684\u5730\u5740\u3002\u5176\u4e2d\uff0caddress\u53ef\u4ee5\u5728\u516c\u6709\u4e91\u201c\u5de5\u5177\u548c\u6848\u4f8b\u201d\u76ee\u5f55\u4e0b\u67e5\u5230\u5bf9\u5e94\u7684\u670d\u52a1\u4e2d\u5fc3\u5730\u5740\uff0c\u4fee\u6539\u534f\u8bae\uff08http/https\uff09\u3001\u4e3b\u673a\u540d\uff08\u53ef\u80fd\u4f7f\u7528\u57df\u540d\uff09\u548c\u7aef\u53e3\u53f7\u3002</p>"},{"location":"start/deployment-on-cloud/#_5","title":"\u8fde\u63a5\u914d\u7f6e\u4e2d\u5fc3","text":""},{"location":"start/deployment-on-cloud/#_6","title":"\u529f\u80fd\u63cf\u8ff0","text":"<p>\u914d\u7f6e\u4e2d\u5fc3\u5b9e\u73b0\u914d\u7f6e\u4e0b\u53d1\uff0c\u8fde\u63a5\u914d\u7f6e\u4e2d\u5fc3\u662f\u4f7f\u7528\u6cbb\u7406\u3001\u7070\u5ea6\u53d1\u5e03\u7b49\u529f\u80fd\u7684\u524d\u53f0\u3002</p>"},{"location":"start/deployment-on-cloud/#_7","title":"\u914d\u7f6e\u53c2\u8003","text":"<ul> <li>\u589e\u52a0\u4f9d\u8d56\u5173\u7cfb(pom.xml)</li> </ul> <p>\u5982\u679c\u8fde\u63a5\u914d\u7f6e\u4e2d\u5fc3\u4f7f\u7528https\u534f\u8bae/AK/SK\u8ba4\u8bc1\uff0c\u8be5jar\u4f9d\u8d56\u5fc5\u9009\u3002\u5982\u679c\u662fhttp\u534f\u8bae\uff0c\u5e76\u4e0d\u5305\u542btoken\u9a8c\u8bc1\uff0c\u5219\u65e0\u9700\u5f15\u5165\u3002</p> <pre><code>&lt;dependency&gt; \n  &lt;groupId&gt;com.huawei.paas.cse&lt;/groupId&gt;  \n  &lt;artifactId&gt;foundation-auth&lt;/artifactId&gt; \n&lt;/dependency&gt;\n</code></pre> <p>\u8fde\u63a5\u914d\u7f6e\u4e2d\u5fc3\u8be5jar\u5fc5\u9009</p> <pre><code>&lt;dependency&gt; \n  &lt;groupId&gt;com.huawei.paas.cse&lt;/groupId&gt;  \n  &lt;artifactId&gt;foundation-config-cc&lt;/artifactId&gt; \n&lt;/dependency&gt;\n</code></pre> <ul> <li>\u542f\u7528\u914d\u7f6e(microservice.yaml\uff09</li> </ul> <pre><code>servicecomb:\n config:\n  client:\n   serverUri: https://servicecomb.cn-north-1.myhwclouds.com:443\n</code></pre> <p>\u8be5\u914d\u7f6e\u9879\u914d\u7f6e\u4e86\u914d\u7f6e\u4e2d\u5fc3\u7684\u5730\u5740\u3002\u5176\u4e2d\uff0caddress\u53ef\u4ee5\u5728\u516c\u6709\u4e91\u201c\u5de5\u5177\u548c\u6848\u4f8b\u201d\u76ee\u5f55\u4e0b\u67e5\u5230\u5bf9\u5e94\u7684\u914d\u7f6e\u4e2d\u5fc3\u5730\u5740\uff0c\u4fee\u6539\u534f\u8bae\uff08http/https\uff09\u3001\u4e3b\u673a\u540d\uff08\u53ef\u80fd\u4f7f\u7528\u57df\u540d\uff09\u548c\u7aef\u53e3\u53f7\u3002</p>"},{"location":"start/deployment-on-cloud/#_8","title":"\u4f7f\u7528\u670d\u52a1\u6cbb\u7406","text":""},{"location":"start/deployment-on-cloud/#_9","title":"\u529f\u80fd\u63cf\u8ff0","text":"<p>\u670d\u52a1\u6cbb\u7406\u4e3b\u8981\u6d89\u53ca\u201c\u9694\u79bb\u201d\u3001\u201c\u7194\u65ad\u201d\u3001\u201c\u5bb9\u9519\u201d\u3001\u201c\u9650\u6d41\u201d\u3001\u201c\u8d1f\u8f7d\u5747\u8861\u201d\u7b49\u3002</p>"},{"location":"start/deployment-on-cloud/#_10","title":"\u914d\u7f6e\u53c2\u8003","text":"<p>\u914d\u7f6e\u9879(microservice.yaml\uff09</p> <p>\u9700\u8981\u589e\u52a0\u4e0b\u9762\u6cbb\u7406\u76f8\u5173\u7684handler\uff0c\u624d\u80fd\u5728\u4ece\u914d\u7f6e\u4e2d\u5fc3\u5b9e\u65f6\u83b7\u53d6\u6cbb\u7406\u6570\u636e\u3002</p> <pre><code>servicecomb:\n handler:\n  chain:\n   Provider:\n    default: bizkeeper-provider,qps-flowcontrol-provider\n   Consumer:\n    default: bizkeeper-consumer,loadbalance,qps-flowcontrol-consumer\n</code></pre>"},{"location":"start/deployment-on-cloud/#_11","title":"\u4f7f\u7528\u6545\u969c\u6ce8\u5165","text":""},{"location":"start/deployment-on-cloud/#_12","title":"\u529f\u80fd\u63cf\u8ff0","text":"<p>\u6545\u969c\u6ce8\u5165\u4e3b\u8981\u63d0\u4f9b\u4e86\u5ef6\u65f6\u3001\u9519\u8bef\u4e24\u79cd\u7c7b\u578b\u6545\u969c\u3002</p>"},{"location":"start/deployment-on-cloud/#_13","title":"\u914d\u7f6e\u53c2\u8003","text":"<p>\u914d\u7f6e\u9879(microservice.yaml\uff09</p> <p>\u9700\u8981\u589e\u52a0\u4e0b\u9762\u6cbb\u7406\u76f8\u5173\u7684handler\u3002</p> <pre><code>servicecomb:\n handler:\n  chain:\n   Consumer:\n    default: loadbalance,fault-injection-consumer\n</code></pre>"},{"location":"start/deployment-on-cloud/#_14","title":"\u4f7f\u7528\u7070\u5ea6\u53d1\u5e03","text":""},{"location":"start/deployment-on-cloud/#_15","title":"\u529f\u80fd\u63cf\u8ff0","text":"<p>\u8be5\u529f\u80fd\u5bf9\u5e94\u4e8e\u5fae\u670d\u52a1\u76ee\u5f55\u7070\u5ea6\u53d1\u5e03\u529f\u80fd\u3002\u7ba1\u7406\u5458\u53ef\u4ee5\u901a\u8fc7\u4e0b\u53d1\u89c4\u5219\uff0c\u5bf9\u670d\u52a1\u8fdb\u884c\u7070\u5ea6\u53d1\u5e03\u7ba1\u7406\u3002</p>"},{"location":"start/deployment-on-cloud/#_16","title":"\u914d\u7f6e\u53c2\u8003","text":"<ul> <li>\u589e\u52a0\u4f9d\u8d56\u5173\u7cfb(pom.xml)</li> </ul> <p>\u5f15\u5165\u5fc5\u8981\u7684jar\u5305\u3002</p> <pre><code>&lt;dependency&gt; \n  &lt;groupId&gt;com.huawei.paas.cse&lt;/groupId&gt;  \n  &lt;artifactId&gt;cse-handler-cloud-extension&lt;/artifactId&gt;\n&lt;/dependency&gt;\n</code></pre> <ul> <li>\u5728Consumer\u7aef\u914d\u7f6e\u8d1f\u8f7d\u5747\u8861(microservice.yaml\uff09</li> </ul> <p>\u5728\u8d1f\u8f7d\u5747\u8861\u6a21\u5757\u542f\u7528\u4e86\u7070\u5ea6\u53d1\u5e03\u7684filter\u3002</p> <pre><code>servicecomb:\n loadbalance:\n  serverListFilters: darklaunch\n  serverListFilter:\n    darklaunch:\n      className: com.huawei.paas.darklaunch.DarklaunchServerListFilter\n</code></pre>"},{"location":"start/deployment-on-cloud/#_17","title":"\u4f7f\u7528\u8c03\u7528\u94fe","text":""},{"location":"start/deployment-on-cloud/#_18","title":"\u529f\u80fd\u63cf\u8ff0","text":"<p>\u534e\u4e3a\u4e91\u63d0\u4f9b\u4e86\u4e1a\u52a1\u65e0\u4fb5\u5165\u7684\u57cb\u70b9\u529f\u80fdAPM\u3002\u53ea\u9700\u8981\u901a\u8fc7\u534e\u4e3a\u4e91\u90e8\u7f72\u5bb9\u5668\u5e94\u7528\uff0c\u5e76\u9009\u62e9\u542f\u7528\u8c03\u7528\u94fe\u76d1\u63a7\u529f\u80fd\uff0c\u5373\u53ef\u4f7f\u7528\u8c03\u7528\u94fe\u670d\u52a1\u3002</p>"},{"location":"start/deployment-on-cloud/#_19","title":"\u5fae\u670d\u52a1\u8fd0\u884c\u6570\u636e\u4e0a\u62a5","text":""},{"location":"start/deployment-on-cloud/#_20","title":"\u529f\u80fd\u63cf\u8ff0","text":"<p>\u5fae\u670d\u52a1\u53ef\u4ee5\u5c06\u81ea\u5df1\u7684\u8fd0\u884c\u6570\u636e\u4e0a\u62a5\u7ed9Dashboard\u670d\u52a1\uff0c\u5728\u516c\u6709\u4e91\u4e0a\u67e5\u770b\u4eea\u8868\u76d8\u6570\u636e\u3001\u5206\u5e03\u5f0f\u4e8b\u52a1\u6570\u636e\u7b49\u3002\u8be5\u7ae0\u8282\u662f\u63cf\u8ff0\u5982\u4f55\u542f\u7528\u5fae\u670d\u52a1\u6570\u636e\u4e0a\u62a5\u529f\u80fd\u3002</p>"},{"location":"start/deployment-on-cloud/#_21","title":"\u914d\u7f6e\u53c2\u8003","text":"<ul> <li>\u589e\u52a0\u4f9d\u8d56\u5173\u7cfb(pom.xml)</li> </ul> <p>\u5f15\u5165\u5fc5\u8981\u7684jar\u5305\u3002</p> <pre><code>&lt;dependency&gt;\n\u3000\u3000&lt;groupId&gt;com.huawei.paas.cse&lt;/groupId&gt;\n\u3000\u3000&lt;artifactId&gt;cse-handler-cloud-extension&lt;/artifactId&gt;\n&lt;/dependency&gt;\n</code></pre> <ul> <li>\u914d\u7f6ehandler</li> </ul> <p>\u4eea\u8868\u76d8\u6570\u636e\u4f9d\u8d56\u4e8e\u4e24\u4e2ahandler\uff0c\u4e00\u4e2abizkeeper-provider\uff08\u5ba2\u6237\u7aef\u4e3abizkeeper-consumer\uff09\uff0c\u4e00\u4e2aperf-stats\uff0c\u6240\u4ee5\u5bf9\u5e94\u7684pom\u4f9d\u8d56\u9700\u8981\u5148\u5f15\u5165\u3002</p> <pre><code>servicecomb:  \n  handler:\n    chain:\n      Provider:\n        default: bizkeeper-provider,perf-stats,tracing-provider,sla-provider\n      Consumer:\n        default: bizkeeper-consumer,loadbalance,perf-stats,tracing-consumer,sla-consumer\n</code></pre> <ul> <li>\u914d\u7f6e\u4e0a\u62a5monitor\u5730\u5740</li> </ul> <p>TenantLB_ADDRESS\u4e3a\u5171\u6709\u4e91\u79df\u6237\u7ba1\u7406\u9762\u63a5\u5165\u5730\u5740\uff0c\u9ed8\u8ba4\u662f100.125.1.34\u3002</p> <pre><code>servicecomb:\n  service:\n    registry:\n      address: https://${TenantLB_ADDRESS}:30100\n  monitor:\n    client:\n      serverUri: https://${TenantLB_ADDRESS}:30109\n</code></pre>"},{"location":"start/deployment-on-cloud/#tcc","title":"\u5206\u5e03\u5f0f\u4e8b\u52a1: TCC","text":""},{"location":"start/deployment-on-cloud/#_22","title":"\u529f\u80fd\u63cf\u8ff0","text":"<p>\u4e3b\u8981\u5b9e\u73b0\u57fa\u4e8eTCC\u534f\u8bae\u7684\u5206\u5e03\u5f0f\u670d\u52a1\u95f4\u7684\u6700\u7ec8\u4e00\u81f4\u6027\u65b9\u6848\uff0c\u4fdd\u969c\u4e00\u822c\u573a\u666f\u4e0b\u7684\u5e94\u7528\u4e00\u81f4\u6027\u9700\u6c42\uff0c\u5e76\u53ef\u4ee5\u5728FusionStage/ServiceStage\u5206\u5e03\u5f0f\u4e8b\u52a1\u754c\u9762\u67e5\u770b\u4e8b\u52a1\u8be6\u7ec6\u4fe1\u606f\u3002</p>"},{"location":"start/deployment-on-cloud/#_23","title":"\u914d\u7f6e\u53c2\u8003","text":"<ul> <li>\u589e\u52a0\u4f9d\u8d56\u5173\u7cfb(pom.xml)</li> </ul> <p>\u5f15\u5165\u5fc5\u8981\u7684jar\u5305</p> <pre><code>&lt;dependency&gt;\n\u3000\u3000&lt;groupId&gt;com.huawei.paas.cse&lt;/groupId&gt;\n\u3000\u3000&lt;artifactId&gt;cse-handler-tcc&lt;/artifactId&gt;\n&lt;/dependency&gt;\n</code></pre> <ul> <li>\u914d\u7f6e\u9879\u53c2\u8003</li> </ul> <p>\u9700\u8981\u589e\u52a0\u4e0b\u9762\u4e8b\u52a1\u76f8\u5173\u7684handler\uff0c\u624d\u80fd\u5728\u4ece\u914d\u7f6e\u4e2d\u5fc3\u5b9e\u65f6\u83b7\u53d6\u6cbb\u7406\u6570\u636e\u3002</p> <pre><code>servicecomb:\n handler:\n  chain:\n   Provider:\n    default: tcc-client,bizkeeper-provider\n   Consumer:\n    default: tcc-server,bizkeeper-consumer,loadbalance\n</code></pre>"},{"location":"start/development-environment/","title":"Prepare the local development environment","text":"<p>JDK, Maven, Eclipse, and IDEA is required. If you already have these development tools installed, skip this section.</p>"},{"location":"start/development-environment/#jdk-version-and-installation-steps","title":"JDK version and installation steps","text":"<p>1.JDK version</p> <p>The JDK version requires 1.8 or higher.</p> <p>2.JDK download</p> <p>Please go to the official address of JDK version 1.8 to download.</p> <p>3.JDK installation</p> <p>After downloading the JDK installation package on the official website, select the appropriate installation path to install the JDK.</p> <p>Here is the windows system as an example:</p> <p>Set the JAVA_HOME environment variable to point to the Java installation directory. Add %JAVA_HOME%\\bin to the system path path. After the environment variable is configured, use the java -version command to verify whether the installation is successful. The windows environment is echoed as follows:</p> <pre><code>C:\\&gt; java -version      \n java version \"1.8.0_121\"      \n Java(TM) SE Runtime Environment (build 1.8.0_121-b13)      \n Java HotSpot(TM) 64-Bit Server VM (build 25.121-b13, mixed mode)\n</code></pre>"},{"location":"start/development-environment/#maven-installation-steps","title":"Maven installation steps","text":"<p>Maven is a development tool that integrates project management, code compilation and more.</p>"},{"location":"start/development-environment/#prerequisites","title":"Prerequisites","text":"<p>The JDK has been installed successfully.</p>"},{"location":"start/development-environment/#installation-steps","title":"installation steps","text":"<ul> <li>Download the Maven installation package at the official address.</li> <li>Unzip the Maven installation package to the native path.</li> <li>Set environment variables\uff1a</li> <li>Set the M2_HOME environment variable to point to the Maven installation directory.</li> <li>Add %M2_HOME%\\bin to the system path path.</li> <li>Verification</li> </ul> <p>Use the mvn -version command to verify that the installation is successful. The windows environment    is echoed as follows:</p> <pre><code>    C:\\&gt;mvn -version        \n    Apache Maven 3.3.9\n</code></pre>"},{"location":"start/development-environment/#eclipse-installation","title":"Eclipse installation","text":""},{"location":"start/development-environment/#prerequisites_1","title":"Prerequisites","text":"<p>a.JDK has been installed.</p> <p>b.Maven is already installed.</p>"},{"location":"start/development-environment/#installation-steps_1","title":"installation steps","text":"<p>a. Download the Eclipse installation package at the official address.</p> <p>b. Install Eclipse to the machine.</p> <p>c. (Optional) Extract the plugin m2eclipse described in the previous Maven installation to the plugins and features directory in the Eclipse installation directory. The latest Eclipse version</p> <p>With the Maven plugin, don't do this</p> <p>d. Start Eclipse, configure jre, maven settings, and the default encoding format is utf-8.</p>"},{"location":"start/development-environment/#idea-installation","title":"IDEA installation","text":""},{"location":"start/development-environment/#prerequisites_2","title":"Prerequisites","text":"<p>a.JDK has been installed.</p> <p>b.Maven is already installed.</p>"},{"location":"start/development-environment/#installation-steps_2","title":"installation steps","text":"<p>a. Download the IDEA installation package on the official website, the paid version or the community version according to individual needs.</p> <p>b. Set the encoding format to utf-8.</p> <p>Open IDEA and select File -&gt; Settings -&gt; Editor -&gt; File Encoding Change project Encoding and default encoding for properties files to utf-8.</p> <p>c. Set up maven configuration</p> <p>Open IDEA and select File -&gt; Settings -&gt; Build, Execution, Deployment -&gt; Bulid Tools -&gt; Maven Note configuring Maven home directory and User settings file</p>"},{"location":"start/first-sample/","title":"Develop the first microservice","text":""},{"location":"start/first-sample/#preparement","title":"Preparement","text":"<p>Before developing the first Java-Chassis microservice, please make sure that your local development environment is prepared. See more details about this in Prepare the local development environment.</p> <p>The Apache Service Center is needed in this show case. About using service center, please refer to Install of ServiceCenter.</p>"},{"location":"start/first-sample/#develop-a-helloworld-microservice","title":"Develop a HelloWorld microservice","text":""},{"location":"start/first-sample/#pom-configurations","title":"pom configurations","text":"<p>First, please to create an empty maven project. It is suggested that the dependencies should be managed by <code>dependencyManagement</code> item, so that only the <code>solution-basic</code> is needed to be imported as dependency:</p> <pre><code>&lt;dependencyManagement&gt;\n  &lt;dependencies&gt;\n    &lt;dependency&gt;\n      &lt;groupId&gt;org.apache.servicecomb&lt;/groupId&gt;\n      &lt;artifactId&gt;java-chassis-dependencies&lt;/artifactId&gt;\n      &lt;version&gt;${java-chassis-dependencies.version}&lt;/version&gt;\n      &lt;type&gt;pom&lt;/type&gt;\n      &lt;scope&gt;import&lt;/scope&gt;\n    &lt;/dependency&gt;\n  &lt;/dependencies&gt;\n&lt;/dependencyManagement&gt;\n&lt;dependencies&gt;\n  &lt;dependency&gt;\n    &lt;groupId&gt;org.apache.servicecomb&lt;/groupId&gt;\n    &lt;artifactId&gt;solution-basic&lt;/artifactId&gt;\n  &lt;/dependency&gt;\n&lt;/dependencies&gt;\n</code></pre> <p><code>solution-basic</code> has contains almost all of the dependencies you need in the common cases.</p> <p>For the version 2.0.0 Java-Chassis, <code>maven-compiler-plugin</code> compilation plugin is also needed, which can make the method argument names preserved during the source project is build into a jar file.</p> <pre><code>&lt;build&gt;\n  &lt;plugins&gt;\n    &lt;plugin&gt;\n      &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;\n      &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt;\n      &lt;version&gt;3.1&lt;/version&gt;\n      &lt;configuration&gt;\n        &lt;compilerArgument&gt;-parameters&lt;/compilerArgument&gt;\n        &lt;encoding&gt;UTF-8&lt;/encoding&gt;\n        &lt;source&gt;1.8&lt;/source&gt;\n        &lt;target&gt;1.8&lt;/target&gt;\n      &lt;/configuration&gt;\n    &lt;/plugin&gt;\n  &lt;/plugins&gt;\n&lt;/build&gt;\n</code></pre>"},{"location":"start/first-sample/#add-microservice-configurations","title":"add microservice configurations","text":"<p>By default, Java-Chassis read configurations from the file named <code>microservice.yaml</code> placed in <code>resources</code> directory.</p> <p>The content of the file is like below.</p> <pre><code>APPLICATION_ID: sample    # this microservice belongs to the sample application\nservice_description:\n  name: helloworld        # this microservice is named \"helloworld\"\n  version: 1.0.0\nservicecomb:\n  service:\n    registry:\n      address: http://127.0.0.1:30100  # this address of the service center\n  rest:\n    address: 0.0.0.0:8080\n</code></pre>"},{"location":"start/first-sample/#main-class","title":"Main class","text":"<p>Add a main class in the project:</p> <pre><code>package org.apache.servicecomb.samples;\n\nimport org.apache.servicecomb.foundation.common.utils.BeanUtils;\n\npublic class AppMain {\n  public static void main(String[] args) {\n    BeanUtils.init();\n  }\n}\n</code></pre> <p>Invoking the <code>org.apache.servicecomb.foundation.common.utils.BeanUtils#init()</code> method will trigger the boot up procedure including configuration loading, Spring application context loading, microservice registration.</p>"},{"location":"start/first-sample/#write-a-rest-service-interface","title":"Write a REST service interface","text":"<p>Add a REST service interface class to declare the request you want to handle.</p> <pre><code>package org.apache.servicecomb.samples.service;\n\nimport org.apache.servicecomb.provider.rest.common.RestSchema;\nimport org.springframework.web.bind.annotation.GetMapping;\nimport org.springframework.web.bind.annotation.RequestMapping;\n\n@RestSchema(schemaId = \"hello\")\n@RequestMapping(\"/\")\npublic class HelloWorldService {\n  @GetMapping(\"/hello\")\n  public String hello() {\n    return \"Hello world!\";\n  }\n}\n</code></pre>"},{"location":"start/first-sample/#add-log-configuration","title":"Add log configuration","text":"<p>The <code>solution-basic</code> module introduces the <code>log4j2</code> module. To enable it, a configuration file is needed. This file should be placed in <code>resources\\log4j2.xml</code> and the content is like below:</p> <pre><code>&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;\n&lt;Configuration status=\"WARN\"&gt;\n  &lt;Appenders&gt;\n    &lt;Console name=\"Console\" target=\"SYSTEM_OUT\"&gt;\n      &lt;PatternLayout pattern=\"%d{HH:mm:ss.SSS} [%t] %-5level %logger{36}[%L] - %msg%n\"/&gt;\n    &lt;/Console&gt;\n  &lt;/Appenders&gt;\n  &lt;Loggers&gt;\n    &lt;Root level=\"info\"&gt;\n      &lt;AppenderRef ref=\"Console\"/&gt;\n    &lt;/Root&gt;\n  &lt;/Loggers&gt;\n&lt;/Configuration&gt;\n</code></pre>"},{"location":"start/first-sample/#start-the-microservice","title":"Start the microservice","text":"<p>After completing the work above, the microservice can be started by running the <code>AppMain</code> class. Please visit the web page of local service center <code>http://127.0.0.1:30103/</code>. If the helloworld microservice instance is found like below, the microservice is started successfully. </p> <p>If you visit the address <code>http://127.0.0.1:8080/hello</code>, you can see the response <code>\"Hello world!\"</code> from helloworld service. Now, your first Java-Chassis microservice is completed!.</p>"},{"location":"start/first-sample/#additional","title":"Additional","text":"<p>The introduction demo is developed in Spring MVC style. And there are currently 3 ways to choose:</p> <ul> <li>Spring MVC</li> <li>JaxRS</li> <li>RPC</li> </ul> <p>Developers can quickly build a project in following ways:</p> <ul> <li> <p>Download the samples project. servicecomb-samples provides many samples in hand.</p> </li> <li> <p>Spring MVC Sample</p> </li> <li>JaxRS Sample</li> <li> <p>POJO Sample</p> </li> <li> <p>Generate projects using archetypes</p> </li> </ul> <p>Maven provide archetypes to generate projects. Java-chassis implements many types of archetypes, see LINK for details.</p> <ul> <li>Generate projects using ServiceComb Spring Initializer</li> </ul> <p>ServiceComb Spring Initializer is an graphic user interface to generate projects. See LINK</p>"},{"location":"start/terminology/","title":"Glossary","text":""},{"location":"start/terminology/#table-1-1-glossary","title":"Table 1-1 Glossary","text":"Abbreviations English Chinese Acronyms MicroServices MicroServices \u5fae\u670d\u52a1 Microservices is a lightweight SOA architecture that is commonly used to describe a loosely coupled distributed architecture that is widely used in cloud applications and Internet applications. Provider Provider \u670d\u52a1\u63d0\u4f9b\u8005 The service of the called party in the microservice invocation relationship. Consumer Consumer \u670d\u52a1\u6d88\u8d39\u8005 The service that invokes the initiator in the microservice invocation relationship. Application Application \u5e94\u7528 A logical entity that represents a software application that represents a computer software application that has business functions presented to the user. An application built with a microservice architecture typically consists of multiple microservices. Instance Instance \u5fae\u670d\u52a1\u5b9e\u4f8b A minimal service and deployment unit for a microservice, usually corresponding to an application process. IAM Identity and Access Management \u8eab\u4efd\u53ca\u6743\u9650\u7ba1\u7406 Responsible for maintaining the management level, user, role, authorization relationship, user organization and other information in the PaaS system. And carry out authorization and authorization checks. AK/SK AK/SK Key AK/SK\u5bc6\u94a5 Access key/Secret key is a set of key pairs used for API authentication and access control. Service Service \u670d\u52a1 A service is a description of a functional object that is accessed on demand. In the application model, the service is generally oriented to the application. The application usage service needs to subscribe to the service first, then bind the service and use it. In some business scenarios, it may also need to pay according to usage. Load Balance Load Balance \u8d1f\u8f7d\u5747\u8861 When an application accesses a microservice with multiple instances, it involves routing load balancing. Load balancing policies can be configured through configuration files to support multiple load balancing routing policies such as random, round-robin, session hold, and response time based weights. Rate limit Rate limit \u9650\u6d41 When a resource becomes a bottleneck, the service framework needs to limit the access request of the consumer and start the flow control protection mechanism. Flow control is available on both the consumer and provider sides. On the service consumer side, the frequency of requests sent to a micro service provider can be limited; on the service provider side, the frequency of requests sent by each microservice consumer can be limited, or the total consumption of the service provider can be determined according to the resource consumption of the service provider. Request frequency limits to prevent services from crashing due to resource exhaustion. Service Degrade Service Degrade \u964d\u7ea7 Service downgrade mainly includes two strategies: masked downgrade and fault tolerant downgrade: shielded downgrade refers to the decision of the operation and maintenance personnel/developers when the trigger condition of the outside world reaches a certain critical value. Or a service is forced to downgrade. Fault-tolerant degradation means that when non-core services are unavailable, business logic can be released for faulty services to ensure the operation of core services. Fault tolarance Fault tolarance \u5bb9\u9519 Fault Tolerance is a processing strategy in the scenario where an exception occurs when a consumer accesses a service. After an exception occurs, the service framework automatically selects a new service route to invoke. Circuit Breaker Circuit Breaker \u7194\u65ad There is usually a dependency between microservices. The service invocation link may contain multiple microservices. If one or more service access delays in the link are too high, the request for the portal service will continue. Stacking, continue to consume more threads, io resources, and eventually the system bottleneck due to resource accumulation, resulting in more services unavailable, resulting in avalanche effect. The fuse mechanism is designed for the above scenario. When a target service responds slowly or a large number of timeouts occur, the service call is blown. For subsequent call requests, the target service is no longer called, directly returned, and resources are quickly released. The target service situation is improved and the call is resumed. Isolation Isolation \u9694\u79bb Service isolation is an anomaly detection mechanism. Common detection methods are request timeout, excessive traffic, and so on. The general setting parameters include the timeout period, the maximum number of concurrent requests, etc. When the timeout period or the maximum number of concurrent requests is exceeded, an exception is recorded and used to calculate the error rate and the number of error requests in the fuse mechanism. Service Mesh Service Mesh \u7f51\u683c\u670d\u52a1 An infrastructure layer service. In the process of micro-service, developers need to solve the problems introduced by applications running in distributed networks, such as fault tolerance, current limiting, load balancing, registration discovery, monitoring, etc. Service Mesh acts as the L4/L7 protocol agent. The application solves the problems caused by micro-services. Legacy Legacy \u9057\u7559\u7cfb\u7edf A legacy system is a software system that is still running and in use, but has entered the aging phase of the software lifecycle."},{"location":"transports/highway-rpc/","title":"Highway","text":""},{"location":"transports/highway-rpc/#concept-description","title":"Concept Description","text":"<p>Highway is ServiceComb's private high-performance protocol, it's suitable for the performance sensitive scenarios.</p>"},{"location":"transports/highway-rpc/#configuration","title":"Configuration","text":"<p>To use the Highway channel, add the following dependencies in the pom.xml file:</p> <pre><code>&lt;dependency&gt; \n  &lt;groupId&gt;org.apache.servicecomb&lt;/groupId&gt;  \n  &lt;artifactId&gt;transport-highway&lt;/artifactId&gt; \n&lt;/dependency&gt;\n</code></pre> <p>The Highway configuration items in the microservice.yaml file are described below:</p> <p>Table 1-1 Highway configuration items</p> Configuration Item Default Value Description servicecomb.highway.address The address that the server listens, empty for not listen, just a highway client servicecomb.highway.server.connection-limit Integer.MAX_VALUE Allow client maximum connections servicecomb.highway.server.thread-count verticle-count highway server verticle instance count(Deprecated) servicecomb.highway.server.verticle-count verticle-count highway server verticle instance count servicecomb.highway.client.thread-count verticle-count highway client verticle instance count(Deprecated) servicecomb.highway.client.verticle-count verticle-count highway client verticle instance count(Deprecated) ## Sample code <p>An example of the Highway configuration in the microservice.yaml:</p> <pre><code>servicecomb:\n  highway:\n    address: 0.0.0.0:7070\n</code></pre>"},{"location":"transports/http2/","title":"Http2","text":""},{"location":"transports/http2/#scenario","title":"Scenario","text":"<p>Users can easily enable Http2 protocol for better performance through configuration.</p>"},{"location":"transports/http2/#external-service-communication-configuration","title":"External Service Communication Configuration","text":"<p>The configuration for external service communication is in the microservice.yaml file.</p> <ul> <li> <p>Enable h2(Http2 + TLS)</p> <p>Append  <code>sslEnabled=true</code> to the listening address to enable  TLS communication on server side. For details, see the section Using TLS Communication. Then add <code>protocol=http2</code> to enable h2 communication. Here is the sample configuration:</p> </li> </ul> <p><code>yaml   servicecomb:     rest:       address: 0.0.0.0:8080?sslEnabled=true&amp;protocol=http2</code></p> <ul> <li> <p>Enable h2c(Http2 without TLS)</p> <p>Simply add <code>protocol=http2</code> to enable h2c communication in the server's configuration:</p> </li> </ul> <p><code>yaml   servicecomb:     rest:       address: 0.0.0.0:8080?protocol=http2</code> * The client will read the server's address configuration from service center, then communicate with the server by http2 protocol.</p> <p>Specific examples can refer to http2-it-tests</p>"},{"location":"transports/http2/#http2-server-configuration","title":"http2 server configuration","text":"configuration default description notice servicecomb.rest.server.http2.useAlpnEnabled true Whether to enable ALPN servicecomb.rest.server.http2.HeaderTableSize 4096 servicecomb.rest.server.http2.pushEnabled true servicecomb.rest.server.http2.initialWindowSize 65535 servicecomb.rest.server.http2.maxFrameSize 16384 servicecomb.rest.server.http2.maxHeaderListSize Integer.MAX_VALUE servicecomb.rest.server.http2.concurrentStreams 100 The maximum stream concurrency supported in a connection The smaller value of the concurrentStreams on the server side and the multiplexingLimit on the client side"},{"location":"transports/http2/#http2-client-configuration","title":"http2 client configuration","text":"configuration default description notice servicecomb.rest.client.http2.useAlpnEnabled true Whether to enable ALPN servicecomb.rest.client.http2.multiplexingLimit -1 The maximum stream concurrency supported in a connection,-1 means no limit The smaller value of the concurrentStreams on the server side and the multiplexingLimit on the client side servicecomb.rest.client.http2.maxPoolSize 1 The maximum number of connections established for each IP:Port in each connection pool servicecomb.rest.client.http2.idleTimeoutInSeconds 0 The timeout period of the idle connection, the connection will be closed after the timeout"},{"location":"transports/rest-over-servlet/","title":"REST over Servlet","text":"<p>The REST over Servlet mode applications runs in web container. You need to create a new servlet project to wrap the microservices, pack them into war packages, and load them into the web container to run.</p>"},{"location":"transports/rest-over-servlet/#path-for-external-access","title":"Path for external access","text":"<p>Not like running as a standalone process, when the microservice runs in the web container, the web root and servlet url pattern will be different.</p> <p>For the traditional development framework, the consumer needs to perceive the complete url of the service; for example, the web root is /mywebapp, the url pattern is /rest, and the business-level path is /application, then consumer must access the service via the url /mywebapp/rest/application.</p> <p>So when the deployment pattern changes, like from web container to a standalone process, the consumer or producer have to modify the code to adapt to the changes.</p> <p>It is recommended to use ServiceComb's deployment decoupling feature. Whether it is a consumer or a producer, the application don't perceive the web root and url pattern in the code, while ServiceComb will automatically adapt them for the producer instance at runtime.</p> <p>For some legacy systems, if users expect to use restTemplate.getForObject(\"cse://serviceName/mywebapp/rest/application\"...) without too many changes, then the path of the interface should be defined as /mywebapp/rest/application:</p> <pre><code>@RestSchema(schemaId = \"test\")\n@RequestMapping(path = \"/mywebapp/rest/application\")\n</code></pre> <p>However, it is still recommended to use a deployment-independent way to write the code, which introduces less code modifications when the deployment pattern changes.</p>"},{"location":"transports/rest-over-servlet/#maven-dependencies","title":"maven dependencies","text":"<pre><code>&lt;dependency&gt;\n    &lt;groupId&gt;org.apache.servicecomb&lt;/groupId&gt;\n    &lt;artifactId&gt;transport-rest-servlet&lt;/artifactId&gt;\n&lt;/dependency&gt;\n</code></pre>"},{"location":"transports/rest-over-servlet/#configurations","title":"Configurations","text":"<p>When integrating with servlet, there are a few concepts involved:</p> <ul> <li> <p>Start spring context   Note the following startup methods cannot be used at the same time, just choose one of them.  </p> </li> <li> <p>Without SpringMVC UI or RestController</p> </li> </ul> <p><code>xml   &lt;web-app xmlns=\"http://java.sun.com/xml/ns/javaee\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"          xsi:schemaLocation=\"http://java.sun.com/xml/ns/javaee http://java.sun.com/xml/ns/javaee/web-app_3_0.xsd\"          version=\"3.0\"&gt;     &lt;context-param&gt;        &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt;        &lt;param-value&gt;classpath*:META-INF/spring/*.bean.xml&lt;/param-value&gt;     &lt;/context-param&gt;     &lt;listener&gt;        &lt;listener-class&gt;org.apache.servicecomb.transport.rest.servlet.RestServletContextListener&lt;/listener-class&gt;     &lt;/listener&gt;   &lt;/web-app&gt;</code></p> <p>The <code>classpath*:META-INF/spring/*.bean.xml</code> configured in contextConfigLocation is optional, because the ServiceComb will ensure that it is included in the load path.</p> <p>This is just an example to indicate that the user can customize the contextConfigLocation.</p> <ul> <li>Use SpringMVC  UI or RestController, and org.apache.servicecomb.transport.rest.servlet.CseDispatcherServlet exists</li> </ul> <p><code>xml   &lt;web-app xmlns=\"http://java.sun.com/xml/ns/javaee\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"          xsi:schemaLocation=\"http://java.sun.com/xml/ns/javaee http://java.sun.com/xml/ns/javaee/web-app_3_0.xsd\"          version=\"3.0\"&gt;     &lt;servlet&gt;       &lt;servlet-name&gt;SpringMVCServlet&lt;/servlet-name&gt;       &lt;servlet-class&gt;org.apache.servicecomb.transport.rest.servlet.CseDispatcherServlet&lt;/servlet-class&gt;       &lt;load-on-startup&gt;1&lt;/load-on-startup&gt;     &lt;/servlet&gt;     &lt;servlet-mapping&gt;       &lt;servlet-name&gt;SpringMVCServlet&lt;/servlet-name&gt;       &lt;url-pattern&gt;yourUrlPattern&lt;/url-pattern&gt;     &lt;/servlet-mapping&gt;   &lt;/web-app&gt;</code></p> <p>Note   This servlet is not the processing entry of ServiceComb, but the processing entry of UI or RestController.</p> <ul> <li> <p>Use SpringMVC's UI or RestController, and there is no org.apache.servicecomb.transport.rest.servlet.CseDispatcherServlet</p> <p>In this case, the application class should inherit SpringMVC's DispatcherServlet, and then configure its implementation classes in CseDispatcherServlet's way.</p> </li> </ul> <p><code>@Override   protected WebApplicationContext createWebApplicationContext(ApplicationContext parent){     setContextClass(CseXmlWebApplicationContext.class);     return super.createWebApplicationContext(parent);   }</code></p> <ul> <li>ServiceComb servlet  </li> </ul> <p>The url pattern can be set according to the business logic. The following <code>/rest/*</code> is just an example, not a fixed value.</p> <p>Url pattern must end with <code>/*</code></p> <p>The following two declarations types can not be used at the same time.</p> <ul> <li>Standard declaration</li> </ul> <p><code>xml   &lt;web-app xmlns=\"http://java.sun.com/xml/ns/javaee\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"          xsi:schemaLocation=\"http://java.sun.com/xml/ns/javaee http://java.sun.com/xml/ns/javaee/web-app_3_0.xsd\"          version=\"3.0\"&gt;     &lt;servlet&gt;         &lt;servlet-name&gt;RestServlet&lt;/servlet-name&gt;         &lt;servlet-class&gt;org.apache.servicecomb.transport.rest.servlet.RestServlet&lt;/servlet-class&gt;         &lt;load-on-startup&gt;1&lt;/load-on-startup&gt;         &lt;async-supported&gt;true&lt;/async-supported&gt;     &lt;/servlet&gt;     &lt;servlet-mapping&gt;         &lt;servlet-name&gt;RestServlet&lt;/servlet-name&gt;         &lt;url-pattern&gt;/rest/*&lt;/url-pattern&gt;     &lt;/servlet-mapping&gt;   &lt;/web-app&gt;</code></p> <ul> <li>Quick declaration </li> </ul> <p><code>yaml   servicecomb.rest.servlet.urlPattern: /rest/*</code></p> <p>Specify urlPattern in the microservice.yaml file. When ServiceComb starts, it will automatically create RestServlet and set the corresponding urlPattern.</p>"},{"location":"transports/rest-over-servlet/#configuration-example-for-typical-scenarios","title":"Configuration example for typical scenarios","text":"<ul> <li>Standard declaration in pure ServiceComb mode</li> </ul> <p>web.xml:  </p> <p><code>xml   &lt;web-app xmlns=\"http://java.sun.com/xml/ns/javaee\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"          xsi:schemaLocation=\"http://java.sun.com/xml/ns/javaee http://java.sun.com/xml/ns/javaee/web-app_3_0.xsd\"          version=\"3.0\"&gt;     &lt;listener&gt;         &lt;listener-class&gt;org.apache.servicecomb.transport.rest.servlet.RestServletContextListener&lt;/listener-class&gt;     &lt;/listener&gt;     &lt;servlet&gt;         &lt;servlet-name&gt;RestServlet&lt;/servlet-name&gt;         &lt;servlet-class&gt;org.apache.servicecomb.transport.rest.servlet.RestServlet&lt;/servlet-class&gt;         &lt;load-on-startup&gt;1&lt;/load-on-startup&gt;         &lt;async-supported&gt;true&lt;/async-supported&gt;     &lt;/servlet&gt;     &lt;servlet-mapping&gt;         &lt;servlet-name&gt;RestServlet&lt;/servlet-name&gt;         &lt;url-pattern&gt;/rest/*&lt;/url-pattern&gt;     &lt;/servlet-mapping&gt;   &lt;/web-app&gt;</code></p> <ul> <li>Quick declaration in pure ServiceComb mode    web.xml\uff1a  </li> </ul> <p><code>xml   &lt;web-app xmlns=\"http://java.sun.com/xml/ns/javaee\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"          xsi:schemaLocation=\"http://java.sun.com/xml/ns/javaee http://java.sun.com/xml/ns/javaee/web-app_3_0.xsd\"          version=\"3.0\"&gt;     &lt;listener&gt;         &lt;listener-class&gt;org.apache.servicecomb.transport.rest.servlet.RestServletContextListener&lt;/listener-class&gt;     &lt;/listener&gt;   &lt;/web-app&gt;</code></p> <p>microservice.yaml\uff1a</p> <p><code>yaml   servicecomb.rest.servlet.urlPattern: /rest/*</code></p> <ul> <li>SpringMVC or RestController provide web services, ServiceComb proxy the requests as consumer</li> </ul> <p>web.xml\uff1a</p> <p><code>xml   &lt;web-app xmlns=\"http://java.sun.com/xml/ns/javaee\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"          xsi:schemaLocation=\"http://java.sun.com/xml/ns/javaee http://java.sun.com/xml/ns/javaee/web-app_3_0.xsd\"          version=\"3.0\"&gt;     &lt;servlet&gt;       &lt;servlet-name&gt;SpringMVCServlet&lt;/servlet-name&gt;       &lt;servlet-class&gt;org.apache.servicecomb.transport.rest.servlet.CseDispatcherServlet&lt;/servlet-class&gt;       &lt;load-on-startup&gt;1&lt;/load-on-startup&gt;     &lt;/servlet&gt;     &lt;servlet-mapping&gt;       &lt;servlet-name&gt;SpringMVCServlet&lt;/servlet-name&gt;       &lt;url-pattern&gt;yourUrlPattern&lt;/url-pattern&gt;     &lt;/servlet-mapping&gt;   &lt;/web-app&gt;</code></p> <p>microservice.yaml\uff1a   Servicecomb.rest.address and servicecomb.rest.servlet.urlPattern are not configured</p> <ul> <li>SpringMVC UI/RestController and ServiceComb provide services at the same time   web.xml\uff1a</li> </ul> <p><code>xml   &lt;web-app xmlns=\"http://java.sun.com/xml/ns/javaee\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"          xsi:schemaLocation=\"http://java.sun.com/xml/ns/javaee http://java.sun.com/xml/ns/javaee/web-app_3_0.xsd\"          version=\"3.0\"&gt;     &lt;servlet&gt;       &lt;servlet-name&gt;SpringMVCServlet&lt;/servlet-name&gt;       &lt;servlet-class&gt;org.apache.servicecomb.transport.rest.servlet.CseDispatcherServlet&lt;/servlet-class&gt;       &lt;load-on-startup&gt;1&lt;/load-on-startup&gt;     &lt;/servlet&gt;     &lt;servlet-mapping&gt;       &lt;servlet-name&gt;SpringMVCServlet&lt;/servlet-name&gt;       &lt;url-pattern&gt;yourUrlPattern&lt;/url-pattern&gt;     &lt;/servlet-mapping&gt;   &lt;/web-app&gt;</code></p> <p>microservice.yaml\uff1a  </p> <p><code>yaml   servicecomb:     rest:       servlet:         urlPattern: /rest/*       address: 0.0.0.0:8080</code></p>"},{"location":"transports/rest-over-servlet/#things-to-notice-with-servlet-filter","title":"Things to notice with servlet filter","text":"<p>RestServlet works in asynchronous mode. According to the servlet 3.0 standard, the entire work chain must be asynchronous. Therefore, the servlet filter should be set to be asynchronous when it's added to the chain:</p> <pre><code>&lt;filter&gt;\n  ......\n  &lt;async-supported&gt;true&lt;/async-supported&gt;\n&lt;/filter&gt;\n</code></pre>"},{"location":"transports/rest-over-servlet/#configuration-items","title":"Configuration items","text":"<p>The related items for REST over Servlet in the microservice.yaml are described below:</p> <p>Table1-1 REST over Servlet Configuration Items</p> Configuration Item Default Value Required Description servicecomb.rest.address 0.0.0.0:8080 No The service listening addressShould be the same with the web container's listening address servicecomb.rest.server.timeout -1 No Server aync servlet timeout in milliseconds, suggest set to -1 servicecomb.rest.server.requestWaitInPoolTimeout 30000 No for sync business logic, timeout in milliseconds for waiting in executor queue servicecomb.rest.servlet.urlPattern No Used to simplify servlet+servlet mapping configThis item is used only when servlet+servlet mapping is not configured in web.xml.The format is:/* or /path/*, where path can be nested"},{"location":"transports/rest-over-vertx/","title":"REST over Vertx","text":""},{"location":"transports/rest-over-vertx/#configuration","title":"Configuration","text":"<p>The REST over Vertx communication channel runs in standalone mode, it can be started in the main function. In the main function, you need to initialize logs and load service configuration. The code is as follow:</p> <pre><code>import org.apache.servicecomb.foundation.common.utils.BeanUtils;\nimport org.apache.servicecomb.foundation.common.utils.Log4jUtils;\n\npublic class MainServer {\n  public static void main(String[] args) throws Exception {\n  \u3000Log4jUtils.init();// Log initialization\n  \u3000BeanUtils.init(); // Spring bean initialization\n  }\n}\n</code></pre> <p>To use the REST over Vertx communication channel, add the following dependencies in the maven pom.xml file:</p> <pre><code>&lt;dependency&gt;\n\u3000\u3000&lt;groupId&gt;org.apache.servicecomb&lt;/groupId&gt;\n\u3000\u3000&lt;artifactId&gt;transport-rest-vertx&lt;/artifactId&gt;\n&lt;/dependency&gt;\n</code></pre> <p>The REST over Vertx related configuration items in the microservice.yaml file are described as follows:</p> <p>Table 1-1 Configuration items for REST over Vertx</p> Configuration Item Default Value Description servicecomb.rest.address listening address, empty for not listen, just a rest client servicecomb.rest.server.connection-limit Integer.MAX_VALUE Max allowed client connections servicecomb.rest.server.thread-count verticle-count rest server verticle instance count(Deprecated) servicecomb.rest.server.verticle-count verticle-count rest server verticle instance count servicecomb.rest.server.connection.idleTimeoutInSeconds 60 Timeout for server's idle connection, The idle connections will be closed servicecomb.rest.server.compression false Wether the server support compression servicecomb.rest.server.maxInitialLineLength 4096 The max initial line length of the request the server can process, unit is Byte servicecomb.rest.server.maxHeaderSize 32768 The max header size of the request the server can process, unit is Byte servicecomb.rest.server.maxFormAttributeSize 2048 The max form attribute size of the request the server can process, unit is Byte servicecomb.rest.server.compressionLevel 6 The gzip/deflate compression level servicecomb.rest.server.maxChunkSize 8192 The max HTTP chunk size, unit is Byte servicecomb.rest.server.decoderInitialBufferSize 128 The max initial buffer size for HttpObjectDecoder, unit is Byte servicecomb.rest.server.http2ConnectionWindowSize -1 HTTP/2 connection window size, unlimited servicecomb.rest.server.decompressionSupported false whether decompression is supported servicecomb.rest.client.thread-count verticle-count rest client verticle instance count(Deprecated) servicecomb.rest.client.verticle-count verticle-count rest client verticle instance count servicecomb.rest.client.connection.maxPoolSize 5 The maximum number of connections in each connection pool for an IP:port combination servicecomb.rest.client.connection.idleTimeoutInSeconds 30 Timeout for client's idle connection, The idle connections will be closed servicecomb.rest.client.connection.keepAlive true Whether to use long connections servicecomb.rest.client.connection.compression false Wether the client support compression servicecomb.rest.client.maxHeaderSize 8192 The max header size of the response the client can process, unit is Byte"},{"location":"transports/rest-over-vertx/#supplementary-explanation","title":"Supplementary Explanation","text":"<ul> <li>The connection amount under extreme condition   Assumption:</li> <li>servicecomb.rest.client.thread-count = 8</li> <li>servicecomb.rest.client.connection.maxPoolSize = 5</li> <li>there are 10 instances of microservice A  </li> </ul> <p>In terms of client side, under the extreme condition:   * for a client instance invoking microservice A, there are up to 400 connections.(<code>8 * 5 * 10 = 400</code>)   * if this client instance is also invoking another microservice B, and there are 10 instances of microservice B, then there are another 400 connections, and 800 connections in total.</p> <p>In terms of server side, under the extreme condition:   * a client instance establishes up to 40 connections to a server instance.(<code>8 * 5 = 40</code>)   * <code>n</code> client instances establish up to <code>40 * n</code> connections to a server instance.</p> <p>To improve performance, larger connection pools are needed. While the larger connection pools means the more connections. When the microservice instance scale reaches hundreds, some instances may handle tens of thousands of connections. Therefore, the developers need to make reasonable planning according to the actual condition.   The planning of HTTP1.1 may be relatively complex, and sometimes there is no proper solution, in which case the http2 is recommended.</p>"},{"location":"transports/rest-over-vertx/#sample-code","title":"Sample Code","text":"<p>An example of the configuration in the microservice.yaml file for REST over Vertx:</p> <pre><code>servicecomb:\n  rest:\n    address: 0.0.0.0:8080\n    thread-count: 1\n  references:\n    hello:\n      transport: rest\n      version-rule: 0.0.1\n</code></pre>"},{"location":"transports/transport/","title":"Communication","text":""},{"location":"transports/transport/#concepts","title":"Concepts","text":"<p>ServiceComb uses two network channels, REST and Highway, both support encrypted Transport Layer Security (TLS) transmission. The REST channel provides services in the standard RESTful form. The consumer can call RESTful APIs with http client.</p>"},{"location":"transports/verticle-count/","title":"verticle-count","text":""},{"location":"transports/verticle-count/#name-and-default-value","title":"name and default value","text":"<ul> <li>Version prior to 1.2.0   Named thread-count, and the default value is 1, which has the following problems:  </li> <li>The name is ambiguous     The underlying ServiceComb is based on vertx. The communication layer logic is hosted by verticle, running in the eventloop thread, and no separate threads are created.     So thread-count actually represents the number of verticle instances created, not the number of threads.</li> <li>The default value is too small     Because there is no best configuration in all scenarios, the old version chose the most conservative default value, which leads to the adjustment of these parameters in most scenarios.</li> <li>1.2.0 and later versions   Renamed to verticle-count   At the same time, the old thread-count is allowed, but the warning log is printed, reminding to switch to the new configuration.   Default rule\uff1a  </li> <li>If the number of CPUs is less than 8, the number of CPUs is taken.</li> <li>8 if the number of CPUs is greater than or equal to 8.</li> </ul>"},{"location":"transports/verticle-count/#the-relationship-between-eventloop-and-verticle-instances","title":"The relationship between Eventloop and verticle instances:","text":"<p>Assuming the CPU is 2, vertx creates 2 * CPU by default, ie 4 Eventloop threads. Assuming the configuration server verticle count and client verticle count are both 3, then:  Because it is not allowed to perform any blocking action in the Eventloop, combined with the above figure, we can know that when the CPU is fully utilized, it is meaningless to add the verticle instance. Users are advised to combine their actual scenarios to test and summarize the appropriate configuration values.</p>"},{"location":"using-java-chassis-in-spring-boot/components-for-spring-boot/","title":"spring boot starter for java-chassis","text":"<p>java-chassis provide different starters for spring boot. </p>"},{"location":"using-java-chassis-in-spring-boot/components-for-spring-boot/#java-chassis-200-and-above-with-spring-boot-20-and-above-example","title":"java-chassis 2.0.0 and above with spring boot 2.0 and above example","text":"<ul> <li>java-chassis-spring-boot-starter-standalone</li> </ul> <p>For standalone applications:</p> <p>POM dependency\uff1a</p> <pre><code>  &lt;dependencies&gt;\n    &lt;dependency&gt;\n      &lt;groupId&gt;org.apache.servicecomb&lt;/groupId&gt;\n      &lt;artifactId&gt;java-chassis-spring-boot-starter-standalone&lt;/artifactId&gt;\n    &lt;/dependency&gt;\n  &lt;/dependencies&gt;\n</code></pre> <ul> <li>java-chassis-spring-boot-starter-servlet</li> </ul> <p>For web applications:</p> <p>POM dependency\uff1a</p> <pre><code>  &lt;dependencies&gt;\n    &lt;dependency&gt;\n      &lt;groupId&gt;org.apache.servicecomb&lt;/groupId&gt;\n      &lt;artifactId&gt;java-chassis-spring-boot-starter-servlet&lt;/artifactId&gt;\n    &lt;/dependency&gt;\n  &lt;/dependencies&gt;\n</code></pre> <p>dependency management for applications\uff1a</p> <pre><code>  &lt;dependencyManagement&gt;\n    &lt;dependencies&gt;\n      &lt;dependency&gt;\n        &lt;groupId&gt;org.apache.servicecomb&lt;/groupId&gt;\n        &lt;artifactId&gt;java-chassis-dependencies&lt;/artifactId&gt;\n        &lt;version&gt;2.0.0-SNAPSHOT&lt;/version&gt;\n        &lt;type&gt;pom&lt;/type&gt;\n        &lt;scope&gt;import&lt;/scope&gt;\n      &lt;/dependency&gt;\n    &lt;/dependencies&gt;\n  &lt;/dependencyManagement&gt;\n</code></pre>"},{"location":"using-java-chassis-in-spring-boot/components-for-spring-boot/#java-chassis-130-and-above-with-spring-boot-20-and-above-example","title":"java-chassis 1.3.0 and above with spring boot 2.0 and above example","text":"<ul> <li>spring-boot2-starter-standalone</li> </ul> <p>For standalone applications:</p> <p>POM dependency\uff1a</p> <pre><code>  &lt;dependencies&gt;\n    &lt;dependency&gt;\n      &lt;groupId&gt;org.apache.servicecomb&lt;/groupId&gt;\n      &lt;artifactId&gt;spring-boot2-starter-standalone&lt;/artifactId&gt;\n    &lt;/dependency&gt;\n  &lt;/dependencies&gt;\n</code></pre> <ul> <li>spring-boot2-starter-servlet</li> </ul> <p>For web applications:</p> <p>POM dependency\uff1a</p> <pre><code>  &lt;dependencies&gt;\n    &lt;dependency&gt;\n      &lt;groupId&gt;org.apache.servicecomb&lt;/groupId&gt;\n      &lt;artifactId&gt;spring-boot2-starter-servlet&lt;/artifactId&gt;\n    &lt;/dependency&gt;\n  &lt;/dependencies&gt;\n</code></pre> <p>dependency management for applications\uff1a</p> <pre><code>  &lt;dependencyManagement&gt;\n    &lt;dependencies&gt;\n      &lt;dependency&gt;\n        &lt;groupId&gt;org.apache.servicecomb&lt;/groupId&gt;\n        &lt;artifactId&gt;java-chassis-dependencies-springboot2&lt;/artifactId&gt;\n        &lt;version&gt;1.3.0&lt;/version&gt;\n        &lt;type&gt;pom&lt;/type&gt;\n        &lt;scope&gt;import&lt;/scope&gt;\n      &lt;/dependency&gt;\n    &lt;/dependencies&gt;\n  &lt;/dependencyManagement&gt;\n</code></pre>"},{"location":"using-java-chassis-in-spring-boot/components-for-spring-boot/#java-chassis-130-and-above-with-spring-boot-10-and-above-example","title":"java-chassis 1.3.0 and above with spring boot 1.0 and above example","text":"<ul> <li>spring-boot-starter-provider</li> </ul> <p>For standalone applications:</p> <p>POM dependency\uff1a</p> <pre><code>  &lt;dependencies&gt;\n    &lt;dependency&gt;\n      &lt;groupId&gt;org.apache.servicecomb&lt;/groupId&gt;\n      &lt;artifactId&gt;spring-boot-starter-provider&lt;/artifactId&gt;\n    &lt;/dependency&gt;\n  &lt;/dependencies&gt;\n</code></pre> <ul> <li>spring-boot-starter-transport</li> </ul> <p>For web applications:</p> <p>POM dependency\uff1a</p> <pre><code>  &lt;dependencies&gt;\n    &lt;dependency&gt;\n      &lt;groupId&gt;org.apache.servicecomb&lt;/groupId&gt;\n      &lt;artifactId&gt;spring-boot-starter-transport&lt;/artifactId&gt;\n    &lt;/dependency&gt;\n  &lt;/dependencies&gt;\n</code></pre> <p>dependency management for applications\uff1a</p> <pre><code>  &lt;dependencyManagement&gt;\n    &lt;dependencies&gt;\n      &lt;dependency&gt;\n        &lt;groupId&gt;org.apache.servicecomb&lt;/groupId&gt;\n        &lt;artifactId&gt;java-chassis-dependencies-springboot1&lt;/artifactId&gt;\n        &lt;version&gt;1.3.0&lt;/version&gt;\n        &lt;type&gt;pom&lt;/type&gt;\n        &lt;scope&gt;import&lt;/scope&gt;\n      &lt;/dependency&gt;\n      &lt;!-- spring boot 1.5.14.RELEASE use a low version of validation-api, must override it --&gt;\n      &lt;dependency&gt;\n        &lt;groupId&gt;javax.validation&lt;/groupId&gt;\n        &lt;artifactId&gt;validation-api&lt;/artifactId&gt;\n        &lt;version&gt;2.0.0.Final&lt;/version&gt;\n      &lt;/dependency&gt;\n    &lt;/dependencies&gt;\n  &lt;/dependencyManagement&gt;\n</code></pre>"},{"location":"using-java-chassis-in-spring-boot/diff-between-java-web/","title":"The difference between JAVA application method and Web development method","text":"<p>Both development methods will enable the full functionality of the java chassis. The JAVA application mode runs on a separate HTTP server (based on vert.x), which has great advantages in performance. The web development method runs on Tomcat or other built-in web servers and receives requests as a servlet. Therefore, during the development process, you can use some functions provided by the web container, such as providing page services and using Filter. When the application only needs to provide REST services, and performance requirements are high, it is recommended to use a JAVA application mode.</p>"},{"location":"using-java-chassis-in-spring-boot/diff-spring-mvc/","title":"The difference in Spring MVC mode","text":"<p>Java chassis supports the use of the label (org.springframework.web.bind.annotation) provided by Spring MVC to declare the REST interface, but the two are independent implementations and have different design goals. The goal of the java chassis is to provide a cross-language framework that supports multiple communication protocols. Therefore, some features of Spring MVC that are not very good for cross-language support are removed, and features that are strongly related to a specific running framework are not supported, such as direct access to the Servlet protocol definition. HttpServletRequest. Here are some notable differences.</p> <ul> <li>Service declaration method</li> </ul> <p>Spring MVC uses @RestController to declare the service, and java chassis uses @RestSchema to declare the service and needs to display the service path using @RequestMapping to distinguish whether the service uses Spring MVC Annotations or JAX RS Annotations.</p> <pre><code>@RestSchema(schemaId = \"hello\")\n@RequestMapping(path = \"/\")\n</code></pre> <p>The schema is the service contract of java chassis, which is the basis of service runtime. Service management, codec and so on are all based on contract. In a cross-language scenario, the contract also defines the parts of the language that can be understood simultaneously.</p> <ul> <li>Data type support</li> </ul> <p>With Spring MVC, you can use multiple data types in a service definition as long as it can be serialized and deserialized by json. Such as:</p> <pre><code>// abstract type\nPublic void postData(@RequestBody Object data)\n// Interface definition\nPublic void postData(@RequestBody IPerson interfaceData)\n//  Generics tpye without specified type\nPublic void postData(@RequestBody Map rawData)\n// specific protocol related types\nPublic void postData(HttpServletRequest request)\n</code></pre> <p>The above types are not supported in the java chassis. Because java chassis will generate contracts according to the interface definition, from the above interface definition, if you do not combine the actual implementation code or additional development documentation, you can not directly generate the contract. That is, standing in the REST perspective of the browser, I don't know how to construct the message content in the body.</p> <p>To support rapid development, the data type restrictions of java chassis are also constantly expanding, such as support for HttpServletRequest, but when they are used, they are different from the semantics of the WEB server, such as the inability to directly manipulate the stream. Therefore, it is recommended that the developer use the type of contract that can be described as much as possible in the usage scenario so that the code is more readable.</p> <p>For more information on java chassis support for data types, please refer to the \"Supported Data Types\" section.</p> <ul> <li>Common Annotation Support</li> </ul> <p>The following is the java chassis support for Spring MVC common annotation.</p> Tag Name Support Description RequestMapping Yes GetMapping Yes PutMapping Yes PostMapping Yes DeleteMapping Yes PatchMapping Yes RequestParam Yes CookieValue Yes PathVariable Yes RequestHeader Yes RequestBody Yes Currently supports application/json,plain/text RequestPart Yes For file upload scenarios, the corresponding tags are Part, MultipartFile ResponseBody No The return value defaults to the body return ResponseStatus No The error code returned can be specified by ApiResponse RequestAttribute No Servlet Protocol Related Tags SessionAttribute No Servlet Protocol Related Tags MatrixVariable No ModelAttribute No ControllerAdvice No CrossOrigin No ExceptionHandler No InitBinder No <ul> <li>Other</li> </ul> <p>Using POJO objects for parameter mapping in GET methods is not supported.</p> <p>For example: public void getOperation(Person p)</p> <p>Do not support the use of Map mapping in the GET method for all possible parameters.</p> <p>For example: public void getOperation(Map&lt;String,String&gt; p)</p>"},{"location":"using-java-chassis-in-spring-boot/java-application/","title":"JAVA application development","text":"<p>Using JAVA integration, an efficient HTTP server and REST development framework has been added for Spring Boot applications. This way of integration is very simple. Just introduce the relevant dependencies into the project and use the @EnableServiceComb annotation.</p> <p>This project [code example] (https://github.com/huaweicse/servicecomb-java-chassis-samples/tree/master/spring-boot-simple)</p> <ul> <li>Introducing dependencies</li> </ul> <p>Add the spring-boot-starter-provider to the dependency to introduce the core functions of the java chassis. The purpose of introducing hibernate-validator is that spring boot will detect the implementation class of validation-api, and it will not start if it is not detected.</p> <pre><code>&lt;dependencyManagement&gt;\n    &lt;dependencies&gt;\n      &lt;dependency&gt;\n        &lt;groupId&gt;org.apache.servicecomb&lt;/groupId&gt;\n        &lt;artifactId&gt;java-chassis-dependencies&lt;/artifactId&gt;\n        &lt;version&gt;1.0.0-m1&lt;/version&gt;\n        &lt;type&gt;pom&lt;/type&gt;\n        &lt;scope&gt;import&lt;/scope&gt;\n      &lt;/dependency&gt;\n    &lt;/dependencies&gt;\n&lt;/dependencyManagement&gt;\n\n&lt;dependencies&gt;\n    &lt;dependency&gt;\n        &lt;groupId&gt;org.apache.servicecomb&lt;/groupId&gt;\n        &lt;artifactId&gt;spring-boot-starter-provider&lt;/artifactId&gt;\n    &lt;/dependency&gt;\n    &lt;dependency&gt;\n        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;\n        &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt;\n    &lt;/dependency&gt;\n    &lt;dependency&gt;\n        &lt;groupId&gt;org.hibernate&lt;/groupId&gt;\n        &lt;artifactId&gt;hibernate-validator&lt;/artifactId&gt;\n    &lt;/dependency&gt;\n&lt;/dependencies&gt;\n</code></pre> <ul> <li>Enable the core functions of java chassis</li> </ul> <p>Add @EnableServiceComb in front of the startup class.</p> <pre><code>@SpringBootApplication\n@EnableServiceComb\npublic class WebsiteMain {\n    public static void main(final String[] args) {\n        SpringApplication.run(WebsiteMain.class, args);\n    }\n}\n</code></pre> <p>With the above configuration, you can fully use all the functions provided by the java chassis, use the java chassis to develop REST services, and open various governance functions.</p> <ul> <li>Configure microservices</li> </ul> <p>The microservice.yaml file allows you to customize the microservice information, including the application id, microservice name, listener address and port.</p> <p>After integrating java chassis, you can develop REST interface through it:</p> <pre><code>@RestSchema(schemaId = \"hello\")\n@RequestMapping(path = \"/\")\npublic class HelloService {\n    @RequestMapping(path = \"hello\", method = RequestMethod.GET)\n    public String sayHello(@RequestParam(name=\"name\") String name) {\n        return \"Hello \" + name;\n    }\n}\n</code></pre> <p>Then you can access it by http://localhost:9093/hello?name=world.</p>"},{"location":"using-java-chassis-in-spring-boot/using-java-chassis-in-spring-boot/","title":"Intruductions","text":"<p>Spring Boot\u53ef\u4ee5\u8ba9\u5f00\u53d1\u8005\u80fd\u591f\u66f4\u52a0\u5feb\u901f\u7684\u6784\u5efaSpring\u5e94\u7528\u3002\u4e3b\u8981\u63d0\u4f9b\u4e86\u5982\u4e0b\u529f\u80fd\uff1a</p> <ol> <li> <p>\u521b\u5efa\u72ec\u7acb\u53ef\u6267\u884c\u7684Spring\u5e94\u7528\u3002\u901a\u8fc7\u5c06\u5e94\u7528\u7a0b\u5e8f\u6253\u5305\u4e3ajar\uff0c\u5c31\u53ef\u4ee5\u901a\u8fc7java -jar\u6765\u6267\u884c\u5e94\u7528\u7a0b\u5e8f\u3002</p> </li> <li> <p>\u5185\u5d4cTomcat, Jetty\u7b49WEB\u670d\u52a1\u5668\uff0c\u800c\u4e0d\u9700\u8981\u5f00\u53d1\u8005\u6253\u5305war\u3002</p> </li> <li> <p>\u63d0\u4f9bstarter\u7b80\u5316maven\u4f9d\u8d56\u5173\u7cfb\u914d\u7f6e\u3002</p> </li> </ol> <p>\u5c06Spring Boot\u7528\u4e8e\u5fae\u670d\u52a1\u5f00\u53d1\uff0c\u53ef\u4ee5\u6781\u5927\u7684\u7b80\u5316\u5f00\u53d1\u8005\u914d\u7f6e\u548c\u90e8\u7f72\u3002java-chassis\u63d0\u4f9b\u4e86\u5b8c\u5584\u7684\u7684\u670d\u52a1\u6cbb\u7406\u80fd\u529b\u3001\u826f\u597d\u7684\u8de8\u8bed\u8a00\u7279\u6027\u548c\u9ad8\u6548\u7684\u5f02\u6b65\u901a\u4fe1\u80fd\u529b\uff0c\u901a\u8fc7\u4f7f\u7528java chassis\uff0c\u53ef\u4ee5\u5feb\u901f\u542f\u7528\u5404\u79cd\u6ee1\u8db3\u5546\u4e1a\u8fd0\u7ef4\u9700\u8981\u7684\u529f\u80fd\u3002</p> <p>\u672c\u6587\u5c06\u4ecb\u7ecd\u5982\u4f55\u5728Spring Boot\u4e2d\u96c6\u6210\u548c\u4f7f\u7528\u3002\u5f00\u53d1\u8005\u901a\u5e38\u4f1a\u4ee5\u5982\u4e0b\u51e0\u79cd\u65b9\u5f0f\u4f7f\u7528Spring Boot\uff1a</p> <ol> <li> <p>JAVA\u5e94\u7528\u65b9\u5f0f\uff1a\u5f15\u5165spring-boot-starter\uff0c\u5f00\u53d1\u666e\u901aJAVA\u5e94\u7528\u3002\u8be5\u5e94\u7528\u4e0d\u4f1a\u542f\u52a8WEB\u670d\u52a1\u5668\u3002</p> </li> <li> <p>Web\u5f00\u53d1\u65b9\u5f0f\uff1a\u5f15\u5165spring-boot-starter-web\uff0c\u5f00\u53d1Web\u5e94\u7528\u3002\u8be5\u5e94\u7528\u4f1a\u5305\u542b\u4e00\u4e2a\u5185\u5d4c\u7684Tomcat\u6216\u8005Jetty\u670d\u52a1\u5668\uff0c\u5e76\u4e14\u4f7f\u7528The Spring Web MVC framework\uff08\u7b80\u79f0Spring MVC\uff09\u5f00\u53d1REST\u63a5\u53e3\u3002</p> </li> </ol> <p>\u5728\u4e24\u79cd\u60c5\u51b5\u4e0b\uff0c\u90fd\u53ef\u4ee5\u96c6\u6210java chassis\uff0c\u539f\u7406\u56fe\u5982\u4e0b\uff1a</p> <ul> <li>JAVA\u5e94\u7528\u65b9\u5f0f</li> </ul> <p></p> <p>\u8fd9\u79cd\u96c6\u6210\u65b9\u5f0f\u76f8\u5bf9\u7b80\u5355\uff0c\u76f8\u5f53\u4e8e\u76f4\u63a5\u5c06java chassis\u901a\u8fc7Spring Boot\u5e94\u7528\u62c9\u8d77\uff0c\u4e0d\u6d89\u53ca\u4efb\u4f55\u6539\u9020\u548c\u53d8\u5316\u3002</p> <ul> <li>Web\u5f00\u53d1\u65b9\u5f0f</li> </ul> <p></p> <p>\u8be5\u96c6\u6210\u65b9\u5f0f\u7684\u672c\u8d28\u662f\u5c06Spring MVC\u7684DispatcherServlet\u66ff\u6362\u4e3ajava chassis\u7684RestServlet\u3002</p>"},{"location":"using-java-chassis-in-spring-boot/web-application/","title":"Web development method development","text":"<p>The development steps of the web development mode and the JAVA application mode are similar.</p> <p>This project [code example] (https://github.com/huaweicse/servicecomb-java-chassis-samples/tree/master/spring-boot-web)</p> <p>Mainly differences:</p> <ul> <li> <p>JAVA application is based on spring-boot-starter, and web development is based on spring-boot-starter-web.</p> </li> <li> <p>JAVA application depends on spring-boot-starter-provider, while web development depends on spring-boot-starter-transport. Spring-boot-starter-web already carries hibernate-validator and does not require additional dependencies.</p> </li> <li> <p>In the startup function, the web development mode can be declared</p> </li> </ul> <pre><code>@SpringBootApplication(exclude=DispatcherServletAutoConfiguration.class)\n</code></pre> <p>To close org.springframework.web.servlet.DispatcherServlet, enable org.apache.servicecomb.transport.rest.servlet.RestServlet via @EnableServiceComb. Although it is not necessary to exclude the DispatcherServlet, it is not a good idea to have multiple REST frameworks in a microservice in most scenarios, which will cause much confusion in use.</p> <ul> <li>Specify the URL root path of the RestServlet in the microservice.yaml file via the configuration item servicecomb.rest.servlet.urlPattern. And the listening port in the configuration item servicecomb.rest.address must be consistent with the port that the tomcat listens on (the default is 8080, which can be modified by adding server.port in application.yml)</li> </ul> <p>After integrating java chassis, you can develop REST interface through it:</p> <pre><code>@RestSchema(schemaId = \"hello\")\n@RequestMapping(path = \"/\")\npublic class HelloService {\n    @RequestMapping(path = \"hello\", method = RequestMethod.GET)\n    public String sayHello(@RequestParam(name=\"name\") String name) {\n        return \"Hello \" + name;\n    }\n}\n</code></pre> <p>Then you can access it by http://localhost:9093/hello?name=world.</p> <p>You can see that the tags used are mostly the same as Spring MVC. But there are also a few different places, such as:</p> <ol> <li> <p>Replace RestController with RestSchema</p> </li> <li> <p>Declare @RequestMapping explicitly.</p> </li> </ol> <p>If the business code is not a new development but based on the development of Spring MVC, now the java chassis is based on the transformation, but also need to pay attention to the disabling of the DispatcherServlet, and its related features will no longer take effect.</p> <p>In the following sections, about web JAVA application mode and web development mode,  we'll introduce some details of the differences in Spring MVC mode.</p>"}]}